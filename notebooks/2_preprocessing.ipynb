{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f717b57",
   "metadata": {},
   "source": [
    "# BiteMe | Preprocessing\n",
    "\n",
    "The purpose of this notebook is to create the image preprocessing pipeline to be used during train/test time. The output will be functions we can include in the `preprocessing.py` script. \n",
    "\n",
    "TODO: \n",
    " - Preprocessing pipeline\n",
    " - Train/test split\n",
    " - Augmentations\n",
    " - Write augmented images into `preprocessed/train/<label>/...` and `preprocessed/test/<label>/...`\n",
    " - Write metadata including processed images. Write images first with augs, then rename images to hash, then create metadata.\n",
    "  - [Histogram Equalization and Adaptive Histogram Equalization (CLAHE)](https://pyimagesearch.com/2021/02/01/opencv-histogram-equalization-and-adaptive-histogram-equalization-clahe/)\n",
    " - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51da9117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from helpers import read_images, get_train_test_split, augs#, get_augs\n",
    "from constants import ROWS, COLS, CHANNELS, SEED, TEST_SIZE, VERBOSE\n",
    "\n",
    "np.random.seed(SEED)\n",
    "ia.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbcacc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7059b14d2aa03ed6c4de11afa32591995181d31c.jpg</td>\n",
       "      <td>../data/cleaned/none/7059b14d2aa03ed6c4de11afa...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea1b100b581fcdb7ddfae52cc62347a99e304ba4.jpg</td>\n",
       "      <td>../data/cleaned/none/ea1b100b581fcdb7ddfae52cc...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a1442990ff143b7560e5757d9f76d37ab007f48.jpg</td>\n",
       "      <td>../data/cleaned/none/1a1442990ff143b7560e5757d...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6eac051b9c45ff6821ec8675216f371711b7cea9.jpg</td>\n",
       "      <td>../data/cleaned/none/6eac051b9c45ff6821ec86752...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fc72767f8520df9b2b83941077dc0ee013eb9399.jpg</td>\n",
       "      <td>../data/cleaned/none/fc72767f8520df9b2b8394107...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       img_name  \\\n",
       "0  7059b14d2aa03ed6c4de11afa32591995181d31c.jpg   \n",
       "1  ea1b100b581fcdb7ddfae52cc62347a99e304ba4.jpg   \n",
       "2  1a1442990ff143b7560e5757d9f76d37ab007f48.jpg   \n",
       "3  6eac051b9c45ff6821ec8675216f371711b7cea9.jpg   \n",
       "4  fc72767f8520df9b2b83941077dc0ee013eb9399.jpg   \n",
       "\n",
       "                                            img_path label  \n",
       "0  ../data/cleaned/none/7059b14d2aa03ed6c4de11afa...  none  \n",
       "1  ../data/cleaned/none/ea1b100b581fcdb7ddfae52cc...  none  \n",
       "2  ../data/cleaned/none/1a1442990ff143b7560e5757d...  none  \n",
       "3  ../data/cleaned/none/6eac051b9c45ff6821ec86752...  none  \n",
       "4  ../data/cleaned/none/fc72767f8520df9b2b8394107...  none  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define directories\n",
    "base_dir_path = \"../\"\n",
    "\n",
    "data_dir_path = os.path.join(base_dir_path, \"data\")\n",
    "data_cleaned_dir_path = os.path.join(data_dir_path, \"cleaned\")\n",
    "data_preprocessed_dir_path = os.path.join(data_dir_path, \"preprocessed\")\n",
    "\n",
    "data_dir = os.listdir(data_dir_path)\n",
    "data_cleaned_dir = os.listdir(data_cleaned_dir_path)\n",
    "\n",
    "metadata_cleaned_path = os.path.join(data_cleaned_dir_path, \"metadata.csv\")\n",
    "metadata = pd.read_csv(metadata_cleaned_path)\n",
    "\n",
    "# Write processed images to disk\n",
    "write_preprocessed_images = False\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a385b9",
   "metadata": {},
   "source": [
    "## Split Data into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10daea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 train images\n",
      "22 test images\n",
      "\n",
      "TRAIN IMAGE COUNTS\n",
      "------------------\n",
      "tick        26\n",
      "mosquito    25\n",
      "horsefly    25\n",
      "bedbug      25\n",
      "none        25\n",
      "ant         23\n",
      "bee         22\n",
      "mite        21\n",
      "Name: label, dtype: int64\n",
      "\n",
      "TEST IMAGE COUNTS\n",
      "------------------\n",
      "bedbug      3\n",
      "tick        3\n",
      "ant         3\n",
      "horsefly    3\n",
      "mosquito    3\n",
      "none        3\n",
      "mite        2\n",
      "bee         2\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "train_idx, test_idx, y_train, y_test = get_train_test_split(\n",
    "    metadata_df=metadata, \n",
    "    test_size=TEST_SIZE,\n",
    "    verbose=VERBOSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22bee324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-write metadata csv for preprocessed\n",
    "# WILL NEED TO UPDATE IF THERE WE GENERATE SYNTHETIC IMAGES\n",
    "metadata[\"split\"] = \"train\"\n",
    "metadata[\"split\"][test_idx] = \"test\"\n",
    "\n",
    "metadata_preprocessed_path = os.path.join(data_preprocessed_dir_path, \"metadata.csv\")\n",
    "metadata.to_csv(metadata_preprocessed_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ea31e",
   "metadata": {},
   "source": [
    "## Create Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca51ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from: ../data/cleaned\n",
      "Rows set to 512\n",
      "Columns set to 512\n",
      "Channels set to 3\n",
      "Writing images is set to: False\n",
      "Reading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 177.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 94.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 66.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 51.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 41.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 36.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 31.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 27.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image reading complete.\n",
      "Image array shape: (214, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "img_array = read_images(\n",
    "    data_dir_path=data_cleaned_dir_path, \n",
    "    rows=ROWS, \n",
    "    cols=COLS, \n",
    "    channels=CHANNELS, \n",
    "    write_images=False, \n",
    "    output_data_dir_path=None,\n",
    "    verbose=VERBOSE\n",
    ")\n",
    "\n",
    "# Split images into train/test\n",
    "X_train = img_array[train_idx]\n",
    "X_test = img_array[test_idx]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cce05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_preprocessed_images == True:\n",
    "    # Make train/test dirs for preprocessed images\n",
    "    if \"train\" not in os.listdir(data_preprocessed_dir_path):\n",
    "        os.mkdir(os.path.join(data_preprocessed_dir_path, \"train\"))\n",
    "    if \"test\" not in os.listdir(data_preprocessed_dir_path):\n",
    "        os.mkdir(os.path.join(data_preprocessed_dir_path, \"test\"))\n",
    "\n",
    "\n",
    "    # Write preprocessed images (split) to preprocessed directory\n",
    "    for idx in tqdm(metadata.index):\n",
    "        if metadata[\"split\"][idx] == \"train\":\n",
    "            img_dir_path = os.path.join(data_preprocessed_dir_path, \"train\", metadata[\"label\"][idx])\n",
    "            # If doesn't exist, create label directory\n",
    "            if not os.path.isdir(img_dir_path):\n",
    "                os.mkdir(img_dir_path)\n",
    "            # Create img write path\n",
    "            img_path_write = os.path.join(img_dir_path, metadata[\"img_name\"][idx])\n",
    "            # Write to train img directory\n",
    "            cv2.imwrite(img_path_write, img_array[idx])\n",
    "            \n",
    "        elif metadata[\"split\"][idx] == \"test\":\n",
    "            # Write to test directory\n",
    "            img_dir_path = os.path.join(data_preprocessed_dir_path, \"test\", metadata[\"label\"][idx])\n",
    "            # If doesn't exist, create label directory\n",
    "            if not os.path.isdir(img_dir_path):\n",
    "                os.mkdir(img_dir_path)\n",
    "            # Create img write path\n",
    "            img_path_write = os.path.join(img_dir_path, metadata[\"img_name\"][idx])\n",
    "            # Write to train img directory\n",
    "            cv2.imwrite(img_path_write, img_array[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad5607",
   "metadata": {},
   "source": [
    "## Run Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da7da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augs(imgs_raw: np.array, \n",
    "             labels_raw: np.array, \n",
    "             augs: list,\n",
    "             keep_originals: bool=True, \n",
    "             verbose: bool=True) -> np.array:\n",
    "    \"\"\"\n",
    "    Reads raw images and returns array containing augmented images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    imgs_raw : np.array\n",
    "        Array of raw images to augment.\n",
    "    labels_raw : np.array\n",
    "        Array of raw labels, retaining order in imgs_raw.\n",
    "    augs : list\n",
    "        List of augmentations to perform        \n",
    "    keep_originals : bool\n",
    "        If True, appends augmented images to original array, otherwise only returns augmented images.\n",
    "    verbose : bool\n",
    "        If True, prints verbose logging.EPOCHS\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    imgs_aug : np.array\n",
    "        Array containing augmented images. \n",
    "    labels_aug : np.array\n",
    "        Array containing augmented labels, replicating order in imgs_aug.\n",
    "    \"\"\"\n",
    "    # Define augmentations that can be done \n",
    "    fliplr = iaa.Sequential([iaa.Fliplr(p=1)])\n",
    "    flipud = iaa.Sequential([iaa.Flipud(p=1)])\n",
    "    gaussianblur = iaa.Sequential([iaa.GaussianBlur(p=1, sigma=6.0)])\n",
    "\n",
    "    \n",
    "    \n",
    "    num_augs = len(augs)\n",
    "    \n",
    "    if keep_originals == True:\n",
    "        # Create augmentations and add to array with original images\n",
    "        imgs_aug = np.concatenate(\n",
    "            (\n",
    "                imgs_raw, # Originals\n",
    "                fliplr(images=imgs_raw), # Flip horizontally left to right\n",
    "                flipud(images=imgs_raw), # Flip vertically up to down\n",
    "            ),\n",
    "            axis=0 \n",
    "        )\n",
    "        \n",
    "        # Count number of augmentations\n",
    "        labels_aug = np.concatenate(\n",
    "            (\n",
    "                labels_raw,\n",
    "                np.array([labels_raw for i in range(num_augs)]).flatten()\n",
    "            ),\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "    elif keep_originals == False:\n",
    "        # Create augmentations and add to array without original images\n",
    "        imgs_aug = np.concatenate(\n",
    "            (\n",
    "                fliplr(images=imgs_raw), # Flip horizontally left to right\n",
    "                flipud(images=imgs_raw), # Flip vertically up to down\n",
    "            ),\n",
    "            axis=0 \n",
    "        )\n",
    "        \n",
    "        # Count number of augmentations\n",
    "        labels_aug = np.array([labels_raw for i in range(num_augs)]).flatten()\n",
    "        \n",
    "    # Logging\n",
    "    if verbose:\n",
    "        print(f\"Used augs: {list(augs)}\")\n",
    "        print(f\"Created {imgs_aug.shape[0] - imgs_raw.shape[0]} augmentations.\")\n",
    "        print(f\"Image array shape: {imgs_aug.shape}\")\n",
    "        print(f\"Labels array shape: {labels_aug.shape}\")\n",
    "    \n",
    "    return imgs_aug, labels_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e969bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example preprocessing run\n",
    "X_train_aug, y_train_aug, augs = get_augs(\n",
    "    imgs_raw=X_train, \n",
    "    labels_raw=y_train,\n",
    "    keep_originals=False,\n",
    "    verbose=VERBOSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ba554c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fliplr': {'aug': imgaug.augmenters.flip.Fliplr, 'args': {'p': 1.0}},\n",
       " 'Flipud': {'aug': imgaug.augmenters.flip.Flipud, 'args': {'p': 1.0}},\n",
       " 'GaussianBlur': {'aug': imgaug.augmenters.blur.GaussianBlur,\n",
       "  'args': {'sigma': 6.0}},\n",
       " 'AverageBlur': {'aug': imgaug.augmenters.blur.AverageBlur,\n",
       "  'args': {'k': 20.0}},\n",
       " 'MotionBlur': {'aug': imgaug.augmenters.blur.MotionBlur, 'args': {'k': 15.0}},\n",
       " 'MultiplyBrightness': {'aug': imgaug.augmenters.color.MultiplyBrightness,\n",
       "  'args': {'mul': 0.5}},\n",
       " 'MultiplyHue': {'aug': imgaug.augmenters.color.MultiplyHue,\n",
       "  'args': {'mul': 0.8}},\n",
       " 'MultiplySaturation': {'aug': imgaug.augmenters.color.MultiplySaturation,\n",
       "  'args': {'mul': 0.5}},\n",
       " 'Grayscale': {'aug': imgaug.augmenters.color.Grayscale, 'args': {'mul': 0.7}},\n",
       " 'GammaContrast': {'aug': imgaug.augmenters.contrast.GammaContrast,\n",
       "  'args': {'gamma': 2.0}},\n",
       " 'SigmoidContrast': {'aug': imgaug.augmenters.contrast.SigmoidContrast,\n",
       "  'args': {'gain': 9.0}},\n",
       " 'LinearContrast': {'aug': imgaug.augmenters.contrast.LinearContrast,\n",
       "  'args': {'alpha': 2.0}},\n",
       " 'Affine': {'aug': imgaug.augmenters.geometric.Affine, 'args': {'scale': 0.8}},\n",
       " 'ScaleX': {'aug': imgaug.augmenters.geometric.ScaleX, 'args': {'scale': 0.8}},\n",
       " 'ScaleY': {'aug': imgaug.augmenters.geometric.ScaleY, 'args': {'scale': 0.8}},\n",
       " 'TranslateX': {'aug': imgaug.augmenters.geometric.TranslateX,\n",
       "  'args': {'percent': 0.1}},\n",
       " 'TranslateY': {'aug': imgaug.augmenters.geometric.TranslateY,\n",
       "  'args': {'percent': 0.1}},\n",
       " 'Rotate': {'aug': imgaug.augmenters.geometric.Rotate,\n",
       "  'args': {'rotate': 45.0}},\n",
       " 'ShearX': {'aug': imgaug.augmenters.geometric.ShearX,\n",
       "  'args': {'shear': 20.0}},\n",
       " 'ShearY': {'aug': imgaug.augmenters.geometric.ShearY,\n",
       "  'args': {'shear': 20.0}},\n",
       " 'GaussianNoise': {'aug': imgaug.augmenters.imgcorruptlike.GaussianNoise,\n",
       "  'args': {'severity': 5.0}},\n",
       " 'ShotNoise': {'aug': imgaug.augmenters.imgcorruptlike.ShotNoise,\n",
       "  'args': {'severity': 5.0}},\n",
       " 'ImpulseNoise': {'aug': imgaug.augmenters.arithmetic.ImpulseNoise,\n",
       "  'args': {'p': 0.1}},\n",
       " 'SpeckleNoise': {'aug': imgaug.augmenters.imgcorruptlike.SpeckleNoise,\n",
       "  'args': {'severity': 5.0}},\n",
       " 'DefocusBlur': {'aug': imgaug.augmenters.imgcorruptlike.DefocusBlur,\n",
       "  'args': {'severity': 5.0}},\n",
       " 'ZoomBlur': {'aug': imgaug.augmenters.imgcorruptlike.ZoomBlur,\n",
       "  'args': {'severity': 4.0}},\n",
       " 'Contrast': {'aug': imgaug.augmenters.imgcorruptlike.Contrast,\n",
       "  'args': {'severity': 2.0}},\n",
       " 'Brightness': {'aug': imgaug.augmenters.imgcorruptlike.Brightness,\n",
       "  'args': {'severity': 2.0}},\n",
       " 'Saturate': {'aug': imgaug.augmenters.imgcorruptlike.Saturate,\n",
       "  'args': {'severity': 2.0}},\n",
       " 'Solarize': {'aug': imgaug.augmenters.arithmetic.Solarize,\n",
       "  'args': {'threshold': 1.0}},\n",
       " 'EnhanceColor': {'aug': imgaug.augmenters.pillike.EnhanceColor,\n",
       "  'args': {'factor': 4.0}},\n",
       " 'EnhanceContrast': {'aug': imgaug.augmenters.pillike.EnhanceContrast,\n",
       "  'args': {'factor': 2.0}},\n",
       " 'EnhanceBrightness': {'aug': imgaug.augmenters.pillike.EnhanceBrightness,\n",
       "  'args': {'factor': 1.4}},\n",
       " 'EnhanceSharpness': {'aug': imgaug.augmenters.pillike.EnhanceSharpness,\n",
       "  'args': {'factor': 10.0}},\n",
       " 'AdditiveGaussianNoise': {'aug': imgaug.augmenters.arithmetic.AdditiveGaussianNoise,\n",
       "  'args': {'loc': 50.0}},\n",
       " 'AdditiveLaplaceNoise': {'aug': imgaug.augmenters.arithmetic.AdditiveLaplaceNoise,\n",
       "  'args': {'loc': 50.0}},\n",
       " 'AdditivePoissonNoise': {'aug': imgaug.augmenters.arithmetic.AdditivePoissonNoise,\n",
       "  'args': {'lam': 20.0}},\n",
       " 'Cutout': {'aug': imgaug.augmenters.arithmetic.Cutout,\n",
       "  'args': {'nb_iterations': 1,\n",
       "   'size': 0.2,\n",
       "   'fill_mode': 'gaussian',\n",
       "   'fill_per_channel': True}},\n",
       " 'Dropout': {'aug': imgaug.augmenters.arithmetic.Dropout,\n",
       "  'args': {'p': 0.2, 'per_channel': 0.5}},\n",
       " 'CoarseDropout': {'aug': imgaug.augmenters.arithmetic.CoarseDropout,\n",
       "  'args': {'size_percent': 0.5}},\n",
       " 'SaltAndPepper': {'aug': imgaug.augmenters.arithmetic.SaltAndPepper,\n",
       "  'args': {'p': 0.1}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d18611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biteme",
   "language": "python",
   "name": "biteme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
