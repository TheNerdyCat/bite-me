{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29cb011",
   "metadata": {},
   "source": [
    "# BiteMe | Data Definition\n",
    "\n",
    "In this notebook we source and download all available data on insect bites and stings.\n",
    "\n",
    "N.B. This will be explored in v2 if we decide to progress to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b15a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f982001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "base_dir_path = \"../\"\n",
    "\n",
    "data_dir_path = os.path.join(base_dir_path, \"data\")\n",
    "data_raw_dir_path = os.path.join(data_dir_path, \"raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd2dd23",
   "metadata": {},
   "source": [
    "## Rename images to its hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ff00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_files(data_raw_dir_path):\n",
    "    \"\"\"\n",
    "    Renames files in raw data directory to its file hash.\n",
    "    \"\"\"\n",
    "    def sha1_file(file_path):\n",
    "        \"\"\"\n",
    "        Create hashed name for file path\n",
    "        \"\"\"\n",
    "        f = open(file_path, \"rb\")\n",
    "        r = hashlib.sha1(f.read()).hexdigest()\n",
    "        f.close()\n",
    "        return r\n",
    "\n",
    "    # List raw data directory\n",
    "    data_raw_dir = os.listdir(data_raw_dir_path)\n",
    "\n",
    "    # List sub directories in raw data directory\n",
    "    for label_dir_path in data_raw_dir:\n",
    "        label_dir_path = os.path.join(data_raw_dir_path, label_dir_path)\n",
    "\n",
    "        # Get full relative file paths for images\n",
    "        for img_name in os.listdir(label_dir_path):\n",
    "            img_name_path = os.path.join(label_dir_path, img_name)\n",
    "            \n",
    "            # Rename image file with its hash\n",
    "            if img_name_path.endswith(\".jpg\"):\n",
    "                hexh = f\"{os.path.join(label_dir_path, sha1_file(img_name_path))}.jpg\"\n",
    "                print(f\"Renamed {img_name_path} to {hexh}\")\n",
    "                os.rename(img_name_path, hexh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb5e8d",
   "metadata": {},
   "source": [
    "## Create metadata csv from data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b17b0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata(data_raw_dir_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parses through raw data directory and sub-directories to create a metadata csv,\n",
    "    containing paths, names and labels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_raw_dir_path : str\n",
    "        Relative path to raw data directory.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Dataframe containing relevant metadata collected from raw data directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_raw_dir = os.listdir(data_raw_dir_path)\n",
    "\n",
    "    # Create empty dictionary \n",
    "    data_raw_metadata = pd.DataFrame(columns=[\"img_name\", \"img_path\", \"label\"])\n",
    "    \n",
    "    for label in data_raw_dir:\n",
    "        label_dir_path = os.path.join(data_raw_dir_path, label)\n",
    "        \n",
    "        if os.path.isdir(label_dir_path):\n",
    "            for img_name in os.listdir(label_dir_path):\n",
    "                img_name_path = os.path.join(label_dir_path, img_name)\n",
    "                \n",
    "                if \".jpg\" in img_name_path:\n",
    "                    # Add to metadata\n",
    "                    data_raw_metadata = data_raw_metadata.append(\n",
    "                        {\n",
    "                            \"img_name\": img_name, \n",
    "                            \"img_path\": img_name_path, \n",
    "                            \"label\": label\n",
    "                        }, ignore_index=True\n",
    "                    )            \n",
    "    \n",
    "    return data_raw_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75189fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metadata csv\n",
    "create_metadata(data_raw_dir_path).to_csv(f\"{data_raw_dir_path}/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de73921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ee925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef43ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf42fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f14f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541d8d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
