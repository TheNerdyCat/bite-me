{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef0d2692",
   "metadata": {},
   "source": [
    "# BiteMe | Train\n",
    "\n",
    "This notebook includes the most important part of the project - the modelling. The notebook tests methodologies for training, and in it the chosen algorithm is decided. Validation also occurs before final testing, which is conducted in the test notebook. This stage is highly iterative, so all model artefacts, logs and configurations are recorded and saved to disk automatically. This initial setup of what will eventually become MLOps for the final product will be really useful, and helps keep track of what is successful and what isn't.\n",
    "\n",
    "Models to try:\n",
    "\n",
    "~~[SE-ResNet50](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[SE-ResNet101](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[SE-ResNet152](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[SENet154](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[ResNet34](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[ResNet50](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[ResNet101](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[ResNet152](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[FBResNet152](https://github.com/Cadene/pretrained-models.pytorch#facebook-resnet)~~\n",
    "~~[PolyNet](https://github.com/Cadene/pretrained-models.pytorch#polynet)~~\n",
    "~~[InceptionV4](https://github.com/Cadene/pretrained-models.pytorch#inception)~~\n",
    "~~[BNInception](https://github.com/Cadene/pretrained-models.pytorch#bninception)~~\n",
    "~~[InceptionResNetV2](https://github.com/Cadene/pretrained-models.pytorch#inception)~~\n",
    "~~[Xception](https://github.com/Cadene/pretrained-models.pytorch#xception)~~\n",
    " - [ResNeXt101_32x4d](https://github.com/Cadene/pretrained-models.pytorch#resnext)\n",
    " - [SE-ResNeXt101_32x4d](https://github.com/Cadene/pretrained-models.pytorch#senet)\n",
    " - [DenseNet121](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet161](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet169](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet201](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DualPathNet68](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet92](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet98](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet107](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet131](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    "\n",
    "\n",
    " - efficientnet_b0\n",
    " - efficientnet_b1\n",
    " - efficientnet_b2\n",
    " - efficientnet_b3\n",
    " - efficientnet_b4\n",
    " - efficientnet_b5\n",
    "\n",
    "Initial model work is done by using simple, typical image recognition models (CNN architectures) to see how effective these models can be for the problem. Although I don't expect them to be particularly successful, it's important to establish baselines and take a holistic approach to modelling when it's possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8b5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from argparse import ArgumentParser\n",
    "import datetime\n",
    "from time import time\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "import torch\n",
    "import pretrainedmodels\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Local imports\n",
    "sys.path.append(\"..\")\n",
    "from utils.dataset import generate_transforms, generate_dataloaders\n",
    "from models.models import *\n",
    "from utils.loss_function import CrossEntropyLossOneHot\n",
    "from utils.lrs_scheduler import WarmRestart, warm_restart\n",
    "from utils.utils import read_images, augs, get_augs, seed_reproducer, init_logger\n",
    "from utils.constants import *\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a79a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "base_dir_path = \"../\"\n",
    "\n",
    "data_dir_path = os.path.join(base_dir_path, \"data\")\n",
    "data_preprocessed_dir_path = os.path.join(data_dir_path, \"preprocessed\")\n",
    "data_preprocessed_train_dir_path = os.path.join(data_dir_path, \"preprocessed/train\")\n",
    "\n",
    "data_dir = os.listdir(data_dir_path)\n",
    "data_preprocessed_dir = os.listdir(data_preprocessed_dir_path)\n",
    "data_preprocessed_train_dir = os.listdir(data_preprocessed_train_dir_path)\n",
    "\n",
    "metadata_preprocessed_path = os.path.join(data_preprocessed_dir_path, \"metadata.csv\")\n",
    "metadata = pd.read_csv(metadata_preprocessed_path)\n",
    "# Subset to train only\n",
    "metadata = metadata.loc[metadata.split == \"train\"]\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dde582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in train images\n",
    "X_train = read_images(\n",
    "    data_dir_path=data_preprocessed_train_dir_path, \n",
    "    rows=ROWS, \n",
    "    cols=COLS, \n",
    "    channels=CHANNELS, \n",
    "    write_images=False, \n",
    "    output_data_dir_path=None,\n",
    "    verbose=VERBOSE\n",
    ")\n",
    "\n",
    "# Get labels\n",
    "y_train = np.array(pd.get_dummies(metadata[\"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9eb1b2",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac202af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose augmentations to use in preprocessing\n",
    "# For full list see helpers.py\n",
    "#augs_to_select = [\n",
    "#    \"Resize\",\n",
    "#    \"HorizontalFlip\", \n",
    "#    \"VerticalFlip\",\n",
    "#    \"Normalize\"\n",
    "#]\n",
    "## Subset augs based on those selected\n",
    "#AUGS = dict((aug_name, augs[aug_name]) for aug_name in augs_to_select)\n",
    "\n",
    "\n",
    "def init_hparams():\n",
    "    \"\"\"\n",
    "    Initialise hyperparameters for modelling.\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    hparams : argparse.Namespace\n",
    "        Parsed hyperparameters\n",
    "    \"\"\"\n",
    "    parser = ArgumentParser(add_help=False)\n",
    "    parser.add_argument(\"-backbone\", \"--backbone\", type=str, default=MODEL_NAME)\n",
    "    parser.add_argument(\"-device_name\", type=str, default=DEVICE_NAME)\n",
    "    parser.add_argument(\"--gpus\", default=[0])\n",
    "    parser.add_argument(\"--n_workers\", type=int, default=N_WORKERS)\n",
    "    parser.add_argument(\"--image_size\", nargs=\"+\", default=[ROWS, COLS])\n",
    "    parser.add_argument(\"--seed\", type=int, default=SEED)\n",
    "    parser.add_argument(\"--min_epochs\", type=int, default=MIN_EPOCHS)\n",
    "    parser.add_argument(\"--max_epochs\", type=int, default=MAX_EPOCHS)\n",
    "    parser.add_argument(\"--patience\", type=str, default=PATIENCE)    \n",
    "    parser.add_argument(\"-tbs\", \"--train_batch_size\", type=int, default=TRAIN_BATCH_SIZE)\n",
    "    parser.add_argument(\"-vbs\", \"--val_batch_size\", type=int, default=VAL_BATCH_SIZE)\n",
    "    parser.add_argument(\"--n_splits\", type=int, default=N_SPLITS)\n",
    "    parser.add_argument(\"--test_size\", type=float, default=TEST_SIZE)\n",
    "    parser.add_argument(\"--lr\", type=float, default=LEARNING_RATE)\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=WEIGHT_DECAY)\n",
    "    parser.add_argument(\"--epsilon\", type=float, default=EPSILON)\n",
    "    parser.add_argument(\"--amsgrad\", type=bool, default=AMSGRAD)\n",
    "    parser.add_argument(\"--betas\", default=BETAS)\n",
    "    parser.add_argument(\"--eta_min\", type=float, default=ETA_MIN)\n",
    "    parser.add_argument(\"--t_max\", type=float, default=T_MAX)\n",
    "    parser.add_argument(\"--t_mult\", type=float, default=T_MULT)\n",
    "    parser.add_argument(\"--precision\", type=int, default=PRECISION)\n",
    "    parser.add_argument(\"--gradient_clip_val\", type=float, default=GRADIENT_CLIP_VAL)\n",
    "    parser.add_argument(\"--verbose\", type=str, default=VERBOSE)\n",
    "    parser.add_argument(\"--log_dir\", type=str, default=LOG_DIR)\n",
    "    parser.add_argument(\"--log_name\", type=str, default=LOG_NAME)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        hparams, unknown = parser.parse_known_args()\n",
    "    except:\n",
    "        hparams, unknown = parser.parse_args([])\n",
    "\n",
    "    if len(hparams.gpus) == 1:\n",
    "        hparams.gpus = [int(hparams.gpus[0])]\n",
    "    else:\n",
    "        hparams.gpus = [int(gpu) for gpu in hparams.gpus]\n",
    "\n",
    "    hparams.image_size = [int(size) for size in hparams.image_size]\n",
    "    \n",
    "    return hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca739edd",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoolSystem(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "\n",
    "        seed_reproducer(self.hparams.seed)\n",
    "\n",
    "        self.model = se_resnext101_32x4d()\n",
    "        self.criterion = CrossEntropyLossOneHot()\n",
    "        self.logger_kun = init_logger(\n",
    "            hparams.log_name, \n",
    "            hparams.log_dir\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.parameters(), \n",
    "            lr=self.hparams.lr, \n",
    "            betas=self.hparams.betas, \n",
    "            eps=self.hparams.epsilon, \n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "            amsgrad=self.hparams.amsgrad\n",
    "        )\n",
    "        self.scheduler = WarmRestart(\n",
    "            self.optimizer, \n",
    "            T_max=self.hparams.t_max, \n",
    "            T_mult=self.hparams.t_mult, \n",
    "            eta_min=self.hparams.eta_min\n",
    "        )\n",
    "        return [self.optimizer], [self.scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        step_start_time = time()\n",
    "        images, labels, data_load_time = batch\n",
    "\n",
    "        scores = self(images)\n",
    "        loss = self.criterion(scores, labels)\n",
    "\n",
    "        data_load_time = torch.sum(data_load_time)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"data_load_time\": data_load_time,\n",
    "            \"batch_run_time\": torch.Tensor([time() - step_start_time + data_load_time]).to(\n",
    "                data_load_time.device\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        # outputs is the return of training_step\n",
    "        train_loss_mean = torch.stack([output[\"loss\"] for output in outputs]).mean()\n",
    "        self.data_load_times = torch.stack([output[\"data_load_time\"] for output in outputs]).sum()\n",
    "        self.batch_run_times = torch.stack([output[\"batch_run_time\"] for output in outputs]).sum()\n",
    "\n",
    "        self.current_epoch += 1\n",
    "        if self.current_epoch < (self.trainer.max_epochs - 4):\n",
    "            self.scheduler = warm_restart(self.scheduler, T_mult=self.hparams.t_mult)\n",
    "\n",
    "        return {\"train_loss\": train_loss_mean}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        step_start_time = time()\n",
    "        images, labels, data_load_time = batch\n",
    "        data_load_time = torch.sum(data_load_time)\n",
    "        scores = self(images)\n",
    "        loss = self.criterion(scores, labels)\n",
    "\n",
    "        # must return key -> val_loss\n",
    "        return {\n",
    "            \"val_loss\": loss,\n",
    "            \"scores\": scores,\n",
    "            \"labels\": labels,\n",
    "            \"data_load_time\": data_load_time,\n",
    "            \"batch_run_time\": torch.Tensor([time() - step_start_time + data_load_time]).to(\n",
    "                data_load_time.device\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # compute loss\n",
    "        val_loss_mean = torch.stack([output[\"val_loss\"] for output in outputs]).mean()\n",
    "        self.data_load_times = torch.stack([output[\"data_load_time\"] for output in outputs]).sum()\n",
    "        self.batch_run_times = torch.stack([output[\"batch_run_time\"] for output in outputs]).sum()\n",
    "\n",
    "        # compute roc_auc\n",
    "        scores_all = torch.cat([output[\"scores\"] for output in outputs]).cpu()\n",
    "        labels_all = torch.round(torch.cat([output[\"labels\"] for output in outputs]).cpu())\n",
    "\n",
    "        val_roc_auc = torch.tensor(roc_auc_score(labels_all, scores_all))\n",
    "\n",
    "        # terminal logs\n",
    "        self.logger_kun.info(\n",
    "            f\"{self.hparams.fold_i}-{self.current_epoch} | \"\n",
    "            f\"lr : {self.scheduler.get_lr()[0]:.6f} | \"\n",
    "            f\"val_loss : {val_loss_mean:.4f} | \"\n",
    "            f\"val_roc_auc : {val_roc_auc:.4f} | \"\n",
    "            f\"data_load_times : {self.data_load_times:.2f} | \"\n",
    "            f\"batch_run_times : {self.batch_run_times:.2f}\"\n",
    "        )\n",
    "\n",
    "        return {\"val_loss\": val_loss_mean, \"val_roc_auc\": val_roc_auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd3fde",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c68f6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialise hyperparameters\n",
    "hparams = init_hparams()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "log_notes = \"t_mult increased to 6 from 5\"\n",
    "\n",
    "# Initialise logger\n",
    "logger = init_logger(hparams.log_name, hparams.log_dir)\n",
    "\n",
    "# Log parameters\n",
    "logger.info(f\"backbone: {hparams.backbone}\")\n",
    "logger.info(f\"device_name: {hparams.device_name}\")\n",
    "logger.info(f\"gpus: {hparams.gpus}\")\n",
    "logger.info(f\"n_workers: {hparams.n_workers}\")\n",
    "logger.info(f\"image_size: {hparams.image_size}\")\n",
    "logger.info(f\"seed: {hparams.seed}\")\n",
    "logger.info(f\"min_epochs: {hparams.min_epochs}\")\n",
    "logger.info(f\"max_epochs: {hparams.max_epochs}\")\n",
    "logger.info(f\"patience: {hparams.patience}\")\n",
    "logger.info(f\"train_batch_size: {hparams.train_batch_size}\")\n",
    "logger.info(f\"val_batch_size: {hparams.val_batch_size}\")\n",
    "logger.info(f\"n_splits: {hparams.n_splits}\")\n",
    "logger.info(f\"test_size: {hparams.test_size}\")\n",
    "logger.info(f\"learning rate: {hparams.lr}\")\n",
    "logger.info(f\"weight_decay: {hparams.weight_decay}\")\n",
    "logger.info(f\"epsilon: {hparams.epsilon}\")\n",
    "logger.info(f\"amsgrad: {hparams.amsgrad}\")\n",
    "logger.info(f\"betas: {hparams.betas}\")\n",
    "logger.info(f\"precision: {hparams.precision}\")\n",
    "logger.info(f\"gradient_clip_val: {hparams.gradient_clip_val}\")\n",
    "logger.info(f\"eta_min: {hparams.eta_min}\")\n",
    "logger.info(f\"t_max: {hparams.t_max}\")\n",
    "logger.info(f\"t_mult: {hparams.t_mult}\")\n",
    "logger.info(f\"log_dir: {hparams.log_dir}\")\n",
    "logger.info(f\"log_name: {hparams.log_name}\")\n",
    "\n",
    "# Log any notes if they exist\n",
    "if \"log_notes\" in locals():\n",
    "    logger.info(f\"Notes: {log_notes}\")\n",
    "\n",
    "\n",
    "# Create transform pipeline\n",
    "transforms = generate_transforms(hparams.image_size)\n",
    "\n",
    "# List for validation scores \n",
    "val_loss_scores = []\n",
    "\n",
    "# Initialise cross validation\n",
    "folds = StratifiedKFold(n_splits=hparams.n_splits, shuffle=True, random_state=hparams.seed)\n",
    "\n",
    "# Start cross validation\n",
    "for fold_i, (train_index, val_index) in enumerate(folds.split(metadata[[\"img_path\"]], metadata[[\"label\"]])):\n",
    "    hparams.fold_i = fold_i\n",
    "    # Split train images and validation sets\n",
    "    train_data = metadata.iloc[train_index][[\"img_path\", \"label\"]].reset_index(drop=True)\n",
    "    train_data = pd.get_dummies(train_data, columns=[\"label\"], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "    val_data = metadata.iloc[val_index][[\"img_path\", \"label\"]].reset_index(drop=True)\n",
    "    val_data = pd.get_dummies(val_data, columns=[\"label\"], prefix=\"\", prefix_sep=\"\")\n",
    "    \n",
    "    logger.info(f\"Fold {fold_i} num train records: {train_data.shape[0]}\")\n",
    "    logger.info(f\"Fold {fold_i} num val records: {val_data.shape[0]}\")\n",
    "    \n",
    "    train_dataloader, val_dataloader = generate_dataloaders(hparams, train_data, val_data, transforms)\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        save_top_k=2,\n",
    "        mode=\"min\",\n",
    "        filepath=os.path.join(\n",
    "            hparams.log_dir, \n",
    "            hparams.log_name, \n",
    "            f\"fold={fold_i}\" + \"-{epoch}-{val_loss:.4f}-{val_roc_auc:.4f}\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\", \n",
    "        patience=hparams.patience, \n",
    "        mode=\"min\", \n",
    "        verbose=hparams.verbose\n",
    "    )\n",
    "    \n",
    "    # Instance Model, Trainer and train model\n",
    "    model = CoolSystem(hparams)\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=hparams.gpus,\n",
    "        min_epochs=hparams.min_epochs,\n",
    "        max_epochs=hparams.max_epochs,\n",
    "        early_stop_callback=early_stop_callback,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        progress_bar_refresh_rate=0,\n",
    "        precision=hparams.precision,\n",
    "        num_sanity_val_steps=0,\n",
    "        profiler=False,\n",
    "        weights_summary=None,\n",
    "        gradient_clip_val=hparams.gradient_clip_val,\n",
    "        default_root_dir=os.path.join(hparams.log_dir, hparams.log_name)\n",
    "    )\n",
    "    \n",
    "    # Fit model\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "            \n",
    "    # Save val scores\n",
    "    val_loss_scores.append(checkpoint_callback.best)\n",
    "    \n",
    "    # Cleanup\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "val_loss_scores = [i.item() for i in val_loss_scores]\n",
    "\n",
    "# Add val scores to csv with all scores\n",
    "if os.path.isfile(\"../logs/scores.csv\") == False:\n",
    "    pd.DataFrame(columns=[\"name\", \"scores\", \"mean_score\"]).to_csv(\"../logs/scores.csv\", index=False)\n",
    "    \n",
    "# Append to current scores csv\n",
    "all_scores_df = pd.concat([\n",
    "    pd.read_csv(\"../logs/scores.csv\"),\n",
    "    pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"name\": [hparams.log_name],\n",
    "            \"scores\": [val_loss_scores],\n",
    "            \"mean_score\": [np.mean(val_loss_scores)]\n",
    "        }\n",
    "    )],\n",
    "    ignore_index=True\n",
    ")\n",
    "# Write all scores df to csv\n",
    "all_scores_df.to_csv(\"../logs/scores.csv\", index=False)\n",
    "\n",
    "logger.info(f\"Best scores: {val_loss_scores}\")\n",
    "logger.info(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aee771",
   "metadata": {},
   "source": [
    "## Validation Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7feb0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model run path and define chosen fold\n",
    "log_dir = \"../logs/logs\"\n",
    "#model_run = \"2022_11_08_14:57:52\" # manually choose model path\n",
    "model_run = hparams.log_name\n",
    "model_run_path = os.path.join(log_dir, model_run)\n",
    "#best_fold = 1 # manually choose model path\n",
    "best_fold = val_loss_scores.index(min(val_loss_scores))\n",
    "\n",
    "# Get best model for chosen fold\n",
    "model_run_dir = os.listdir(model_run_path)\n",
    "model_folds = [i for i in model_run_dir if i.startswith(f\"fold={best_fold}\")]\n",
    "model_folds_scores = [float(i.split(\"val_loss=\")[1].split(\"-\")[0]) for i in model_folds]\n",
    "model_name = model_folds[model_folds_scores.index(min(model_folds_scores))]\n",
    "model_path = os.path.join(model_run_path, model_name)\n",
    "\n",
    "# Load fold's model\n",
    "model = CoolSystem(hparams)\n",
    "model.load_state_dict(\n",
    "    torch.load(model_path)[\"state_dict\"]\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# Retrieve validation indices for chosen fold\n",
    "for fold_i, (train_index, val_index) in enumerate(folds.split(metadata[[\"img_path\"]], metadata[[\"label\"]])):\n",
    "    if fold_i == best_fold:\n",
    "        break\n",
    "\n",
    "# Select fold validation images\n",
    "X_val = torch.from_numpy(X_train[val_index]).permute(0, 3, 1, 2).float()\n",
    "\n",
    "# Create predictions looped by batch\n",
    "counter = 0\n",
    "val_i_batch = []\n",
    "val_idx_batch = []\n",
    "scores_df = pd.DataFrame()\n",
    "\n",
    "for i, idx in tqdm(enumerate(val_index)):\n",
    "    counter += 1\n",
    "    val_i_batch.append(i) # arrays don't preserve index so need ordered index values\n",
    "    val_idx_batch.append(idx) # for preserved index\n",
    "    \n",
    "    # Run inference for val_batch_size\n",
    "    if counter == hparams.val_batch_size:\n",
    "        preds = model(X_val[val_i_batch])\n",
    "        \n",
    "        # Create activation output\n",
    "        log_softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        # Convert raw output to probabilities\n",
    "        preds = np.exp(log_softmax(preds).detach().numpy())\n",
    "\n",
    "        # Create df with img paths and predicted label probs\n",
    "        scores_df_batch = pd.DataFrame(preds, columns=val_data.columns[1:])\n",
    "        scores_df_batch = pd.merge(\n",
    "            metadata.iloc[val_idx_batch, 1:3].reset_index(drop=True),\n",
    "            scores_df_batch, \n",
    "            left_index=True,\n",
    "            right_index=True\n",
    "        )\n",
    "        scores_df = pd.concat([scores_df, scores_df_batch], ignore_index=True, axis=0)\n",
    "\n",
    "        # Cleanup\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # Reset counter and batch\n",
    "        counter = 0\n",
    "        val_i_batch = []\n",
    "        val_idx_batch = []\n",
    "        \n",
    "    # Run inference for remaining batch\n",
    "    elif idx == val_index[-1]:\n",
    "        preds = model(X_val[val_i_batch])\n",
    "        \n",
    "        # Create activation output\n",
    "        log_softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        # Convert raw output to probabilities\n",
    "        preds = np.exp(log_softmax(preds).detach().numpy())\n",
    "\n",
    "        # Create df with img paths and predicted label probs\n",
    "        scores_df_batch = pd.DataFrame(preds, columns=val_data.columns[1:])\n",
    "        scores_df_batch = pd.merge(\n",
    "            metadata.iloc[val_idx_batch, 1:3].reset_index(drop=True),\n",
    "            scores_df_batch, \n",
    "            left_index=True,\n",
    "            right_index=True\n",
    "        )\n",
    "        scores_df = pd.concat([scores_df, scores_df_batch], ignore_index=True, axis=0)\n",
    "\n",
    "        # Cleanup\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "# Write predictions to log\n",
    "scores_df.to_csv(\n",
    "    os.path.join(model_run_path, f\"{model_run}_preds_fold_{best_fold}.csv\"),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a910bef3",
   "metadata": {},
   "source": [
    "## Validation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(scores_df['img_path'].unique())} unique image paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6565caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation label counts:\")\n",
    "print(scores_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f8676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation prediction counts:\")\n",
    "print(\n",
    "    pd.melt(\n",
    "        scores_df,\n",
    "        id_vars=[\"img_path\", \"label\"],\n",
    "        value_vars=[\"ant\", \"bedbug\", \"bee\", \"horsefly\", \"mite\", \"mosquito\" ,\"none\", \"tick\"],\n",
    "        var_name=\"pred_label\",\n",
    "        value_name=\"pred_prob\"\n",
    "    ).sort_values([\"img_path\", \"pred_prob\"], ascending=False) \\\n",
    "    .groupby([\"img_path\", \"label\"]).first()[\"pred_label\"] \\\n",
    "    .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf48d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability stats by label\n",
    "pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].mean(), columns=[\"mean\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].std(), columns=[\"std\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].min(), columns=[\"min\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].quantile(0.25)),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].median(), columns=[\"median\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].quantile(0.75)),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].max(), columns=[\"max\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].max() - scores_df.iloc[:, 2:].min(), columns=[\"range\"])\n",
    "    ], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d47fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(\n",
    "    scores_df,\n",
    "    id_vars=[\"img_path\", \"label\"],\n",
    "    value_vars=[\"ant\", \"bedbug\", \"bee\", \"horsefly\", \"mite\", \"mosquito\" ,\"none\", \"tick\"],\n",
    "    var_name=\"pred_label\",\n",
    "    value_name=\"pred_prob\"\n",
    ").pivot_table(\n",
    "    index=[\"label\"],\n",
    "    columns=[\"pred_label\"],\n",
    "    aggfunc=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(\n",
    "    scores_df,\n",
    "    id_vars=[\"img_path\", \"label\"],\n",
    "    value_vars=[\"ant\", \"bedbug\", \"bee\", \"horsefly\", \"mite\", \"mosquito\" ,\"none\", \"tick\"],\n",
    "    var_name=\"pred_label\",\n",
    "    value_name=\"pred_prob\"\n",
    ").sort_values([\"img_path\", \"pred_prob\"], ascending=False).groupby([\"img_path\", \"label\"]).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249a0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613be570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88807ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biteme",
   "language": "python",
   "name": "biteme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
