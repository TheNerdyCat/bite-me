{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef0d2692",
   "metadata": {},
   "source": [
    "# BiteMe | Train\n",
    "\n",
    "This notebook includes the most important part of the project - the modelling. The notebook tests methodologies for training, and in it the chosen algorithm is decided. Validation also occurs before final testing, which is conducted in the test notebook. This stage is highly iterative, so all model artefacts, logs and configurations are recorded and saved to disk automatically. This initial setup of what will eventually become MLOps for the final product will be really useful, and helps keep track of what is successful and what isn't.\n",
    "\n",
    "Models to try:\n",
    "\n",
    "~~[SE-ResNet50](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[SE-ResNet101](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[SE-ResNet152](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[SENet154](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[ResNet34](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[ResNet50](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[ResNet101](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[ResNet152](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[FBResNet152](https://github.com/Cadene/pretrained-models.pytorch#facebook-resnet)~~\n",
    "~~[PolyNet](https://github.com/Cadene/pretrained-models.pytorch#polynet)~~\n",
    "~~[InceptionV4](https://github.com/Cadene/pretrained-models.pytorch#inception)~~\n",
    "~~[BNInception](https://github.com/Cadene/pretrained-models.pytorch#bninception)~~\n",
    "~~[InceptionResNetV2](https://github.com/Cadene/pretrained-models.pytorch#inception)~~\n",
    "~~[Xception](https://github.com/Cadene/pretrained-models.pytorch#xception)~~\n",
    " - [ResNeXt101_32x4d](https://github.com/Cadene/pretrained-models.pytorch#resnext)\n",
    " - [SE-ResNeXt101_32x4d](https://github.com/Cadene/pretrained-models.pytorch#senet)\n",
    " - [DenseNet121](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet161](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet169](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet201](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DualPathNet68](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet92](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet98](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet107](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet131](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    "\n",
    "\n",
    " - efficientnet_b0\n",
    " - efficientnet_b1\n",
    " - efficientnet_b2\n",
    " - efficientnet_b3\n",
    " - efficientnet_b4\n",
    " - efficientnet_b5\n",
    "\n",
    "Initial model work is done by using simple, typical image recognition models (CNN architectures) to see how effective these models can be for the problem. Although I don't expect them to be particularly successful, it's important to establish baselines and take a holistic approach to modelling when it's possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be8b5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from argparse import ArgumentParser\n",
    "import datetime\n",
    "from time import time\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "import torch\n",
    "import pretrainedmodels\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Local imports\n",
    "sys.path.append(\"..\")\n",
    "from utils.dataset import generate_transforms, generate_dataloaders\n",
    "from models.models import *\n",
    "from utils.loss_function import CrossEntropyLossOneHot\n",
    "from utils.lrs_scheduler import WarmRestart, warm_restart\n",
    "from utils.utils import read_images, augs, get_augs, seed_reproducer, init_logger\n",
    "from utils.constants import *\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a79a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7059b14d2aa03ed6c4de11afa32591995181d31c.jpg</td>\n",
       "      <td>../data/cleaned/none/7059b14d2aa03ed6c4de11afa...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea1b100b581fcdb7ddfae52cc62347a99e304ba4.jpg</td>\n",
       "      <td>../data/cleaned/none/ea1b100b581fcdb7ddfae52cc...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6eac051b9c45ff6821ec8675216f371711b7cea9.jpg</td>\n",
       "      <td>../data/cleaned/none/6eac051b9c45ff6821ec86752...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fc72767f8520df9b2b83941077dc0ee013eb9399.jpg</td>\n",
       "      <td>../data/cleaned/none/fc72767f8520df9b2b8394107...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49850884a00703afe5aab78c3ce074d2d4acae30.jpg</td>\n",
       "      <td>../data/cleaned/none/49850884a00703afe5aab78c3...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       img_name  \\\n",
       "0  7059b14d2aa03ed6c4de11afa32591995181d31c.jpg   \n",
       "1  ea1b100b581fcdb7ddfae52cc62347a99e304ba4.jpg   \n",
       "2  6eac051b9c45ff6821ec8675216f371711b7cea9.jpg   \n",
       "3  fc72767f8520df9b2b83941077dc0ee013eb9399.jpg   \n",
       "4  49850884a00703afe5aab78c3ce074d2d4acae30.jpg   \n",
       "\n",
       "                                            img_path label  split  \n",
       "0  ../data/cleaned/none/7059b14d2aa03ed6c4de11afa...  none  train  \n",
       "1  ../data/cleaned/none/ea1b100b581fcdb7ddfae52cc...  none  train  \n",
       "2  ../data/cleaned/none/6eac051b9c45ff6821ec86752...  none  train  \n",
       "3  ../data/cleaned/none/fc72767f8520df9b2b8394107...  none  train  \n",
       "4  ../data/cleaned/none/49850884a00703afe5aab78c3...  none  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define directories\n",
    "base_dir_path = \"../\"\n",
    "\n",
    "data_dir_path = os.path.join(base_dir_path, \"data\")\n",
    "data_preprocessed_dir_path = os.path.join(data_dir_path, \"preprocessed\")\n",
    "data_preprocessed_train_dir_path = os.path.join(data_dir_path, \"preprocessed/train\")\n",
    "\n",
    "data_dir = os.listdir(data_dir_path)\n",
    "data_preprocessed_dir = os.listdir(data_preprocessed_dir_path)\n",
    "data_preprocessed_train_dir = os.listdir(data_preprocessed_train_dir_path)\n",
    "\n",
    "metadata_preprocessed_path = os.path.join(data_preprocessed_dir_path, \"metadata.csv\")\n",
    "metadata = pd.read_csv(metadata_preprocessed_path)\n",
    "# Subset to train only\n",
    "metadata = metadata.loc[metadata.split == \"train\"]\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4dde582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from: ../data/preprocessed/train\n",
      "Rows set to 1024\n",
      "Columns set to 1024\n",
      "Channels set to 3\n",
      "Writing images is set to: False\n",
      "Reading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 49.25it/s]\n",
      "100%|███████████████████████████████████████████| 55/55 [00:02<00:00, 20.81it/s]\n",
      "100%|███████████████████████████████████████████| 21/21 [00:01<00:00, 13.39it/s]\n",
      "100%|███████████████████████████████████████████| 46/46 [00:04<00:00, 10.38it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  8.20it/s]\n",
      "100%|███████████████████████████████████████████| 21/21 [00:02<00:00,  7.28it/s]\n",
      "100%|███████████████████████████████████████████| 58/58 [00:09<00:00,  6.13it/s]\n",
      "100%|███████████████████████████████████████████| 46/46 [00:09<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image reading complete.\n",
      "Image array shape: (299, 1024, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read in train images\n",
    "X_train = read_images(\n",
    "    data_dir_path=data_preprocessed_train_dir_path, \n",
    "    rows=ROWS, \n",
    "    cols=COLS, \n",
    "    channels=CHANNELS, \n",
    "    write_images=False, \n",
    "    output_data_dir_path=None,\n",
    "    verbose=VERBOSE\n",
    ")\n",
    "\n",
    "# Get labels\n",
    "y_train = np.array(pd.get_dummies(metadata[\"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9eb1b2",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac202af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose augmentations to use in preprocessing\n",
    "# For full list see helpers.py\n",
    "#augs_to_select = [\n",
    "#    \"Resize\",\n",
    "#    \"HorizontalFlip\", \n",
    "#    \"VerticalFlip\",\n",
    "#    \"Normalize\"\n",
    "#]\n",
    "## Subset augs based on those selected\n",
    "#AUGS = dict((aug_name, augs[aug_name]) for aug_name in augs_to_select)\n",
    "\n",
    "\n",
    "def init_hparams():\n",
    "    \"\"\"\n",
    "    Initialise hyperparameters for modelling.\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    hparams : argparse.Namespace\n",
    "        Parsed hyperparameters\n",
    "    \"\"\"\n",
    "    parser = ArgumentParser(add_help=False)\n",
    "    parser.add_argument(\"-backbone\", \"--backbone\", type=str, default=MODEL_NAME)\n",
    "    parser.add_argument(\"-device_name\", type=str, default=DEVICE_NAME)\n",
    "    parser.add_argument(\"--gpus\", default=[0])\n",
    "    parser.add_argument(\"--n_workers\", type=int, default=N_WORKERS)\n",
    "    parser.add_argument(\"--image_size\", nargs=\"+\", default=[ROWS, COLS])\n",
    "    parser.add_argument(\"--seed\", type=int, default=SEED)\n",
    "    parser.add_argument(\"--min_epochs\", type=int, default=MIN_EPOCHS)\n",
    "    parser.add_argument(\"--max_epochs\", type=int, default=MAX_EPOCHS)\n",
    "    parser.add_argument(\"--patience\", type=str, default=PATIENCE)    \n",
    "    parser.add_argument(\"-tbs\", \"--train_batch_size\", type=int, default=TRAIN_BATCH_SIZE)\n",
    "    parser.add_argument(\"-vbs\", \"--val_batch_size\", type=int, default=VAL_BATCH_SIZE)\n",
    "    parser.add_argument(\"--n_splits\", type=int, default=N_SPLITS)\n",
    "    parser.add_argument(\"--test_size\", type=float, default=TEST_SIZE)\n",
    "    parser.add_argument(\"--lr\", type=float, default=LEARNING_RATE)\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=WEIGHT_DECAY)\n",
    "    parser.add_argument(\"--epsilon\", type=float, default=EPSILON)\n",
    "    parser.add_argument(\"--amsgrad\", type=bool, default=AMSGRAD)\n",
    "    parser.add_argument(\"--betas\", default=BETAS)\n",
    "    parser.add_argument(\"--eta_min\", type=float, default=ETA_MIN)\n",
    "    parser.add_argument(\"--t_max\", type=float, default=T_MAX)\n",
    "    parser.add_argument(\"--t_mult\", type=float, default=T_MULT)\n",
    "    parser.add_argument(\"--precision\", type=int, default=PRECISION)\n",
    "    parser.add_argument(\"--gradient_clip_val\", type=float, default=GRADIENT_CLIP_VAL)\n",
    "    parser.add_argument(\"--verbose\", type=str, default=VERBOSE)\n",
    "    parser.add_argument(\"--log_dir\", type=str, default=LOG_DIR)\n",
    "    parser.add_argument(\"--log_name\", type=str, default=LOG_NAME)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        hparams, unknown = parser.parse_known_args()\n",
    "    except:\n",
    "        hparams, unknown = parser.parse_args([])\n",
    "\n",
    "    if len(hparams.gpus) == 1:\n",
    "        hparams.gpus = [int(hparams.gpus[0])]\n",
    "    else:\n",
    "        hparams.gpus = [int(gpu) for gpu in hparams.gpus]\n",
    "\n",
    "    hparams.image_size = [int(size) for size in hparams.image_size]\n",
    "    \n",
    "    return hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca739edd",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b5b9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoolSystem(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "\n",
    "        seed_reproducer(self.hparams.seed)\n",
    "\n",
    "        self.model = se_resnext101_32x4d()\n",
    "        self.criterion = CrossEntropyLossOneHot()\n",
    "        self.logger_kun = init_logger(\n",
    "            hparams.log_name, \n",
    "            hparams.log_dir\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.parameters(), \n",
    "            lr=self.hparams.lr, \n",
    "            betas=self.hparams.betas, \n",
    "            eps=self.hparams.epsilon, \n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "            amsgrad=self.hparams.amsgrad\n",
    "        )\n",
    "        self.scheduler = WarmRestart(\n",
    "            self.optimizer, \n",
    "            T_max=self.hparams.t_max, \n",
    "            T_mult=self.hparams.t_mult, \n",
    "            eta_min=self.hparams.eta_min\n",
    "        )\n",
    "        return [self.optimizer], [self.scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        step_start_time = time()\n",
    "        images, labels, data_load_time = batch\n",
    "\n",
    "        scores = self(images)\n",
    "        loss = self.criterion(scores, labels)\n",
    "\n",
    "        data_load_time = torch.sum(data_load_time)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"data_load_time\": data_load_time,\n",
    "            \"batch_run_time\": torch.Tensor([time() - step_start_time + data_load_time]).to(\n",
    "                data_load_time.device\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        # outputs is the return of training_step\n",
    "        train_loss_mean = torch.stack([output[\"loss\"] for output in outputs]).mean()\n",
    "        self.data_load_times = torch.stack([output[\"data_load_time\"] for output in outputs]).sum()\n",
    "        self.batch_run_times = torch.stack([output[\"batch_run_time\"] for output in outputs]).sum()\n",
    "\n",
    "        self.current_epoch += 1\n",
    "        if self.current_epoch < (self.trainer.max_epochs - 4):\n",
    "            self.scheduler = warm_restart(self.scheduler, T_mult=self.hparams.t_mult)\n",
    "\n",
    "        return {\"train_loss\": train_loss_mean}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        step_start_time = time()\n",
    "        images, labels, data_load_time = batch\n",
    "        data_load_time = torch.sum(data_load_time)\n",
    "        scores = self(images)\n",
    "        loss = self.criterion(scores, labels)\n",
    "\n",
    "        # must return key -> val_loss\n",
    "        return {\n",
    "            \"val_loss\": loss,\n",
    "            \"scores\": scores,\n",
    "            \"labels\": labels,\n",
    "            \"data_load_time\": data_load_time,\n",
    "            \"batch_run_time\": torch.Tensor([time() - step_start_time + data_load_time]).to(\n",
    "                data_load_time.device\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # compute loss\n",
    "        val_loss_mean = torch.stack([output[\"val_loss\"] for output in outputs]).mean()\n",
    "        self.data_load_times = torch.stack([output[\"data_load_time\"] for output in outputs]).sum()\n",
    "        self.batch_run_times = torch.stack([output[\"batch_run_time\"] for output in outputs]).sum()\n",
    "\n",
    "        # compute roc_auc\n",
    "        scores_all = torch.cat([output[\"scores\"] for output in outputs]).cpu()\n",
    "        labels_all = torch.round(torch.cat([output[\"labels\"] for output in outputs]).cpu())\n",
    "\n",
    "        val_roc_auc = torch.tensor(roc_auc_score(labels_all, scores_all))\n",
    "\n",
    "        # terminal logs\n",
    "        self.logger_kun.info(\n",
    "            f\"{self.hparams.fold_i}-{self.current_epoch} | \"\n",
    "            f\"lr : {self.scheduler.get_lr()[0]:.6f} | \"\n",
    "            f\"val_loss : {val_loss_mean:.4f} | \"\n",
    "            f\"val_roc_auc : {val_roc_auc:.4f} | \"\n",
    "            f\"data_load_times : {self.data_load_times:.2f} | \"\n",
    "            f\"batch_run_times : {self.batch_run_times:.2f}\"\n",
    "        )\n",
    "\n",
    "        return {\"val_loss\": val_loss_mean, \"val_roc_auc\": val_roc_auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd3fde",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c68f6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-08 09:36:07] 3687493274.py[  11] : INFO  backbone: se_resnext101_32x4d\n",
      "[2022-12-08 09:36:07] 3687493274.py[  12] : INFO  device_name: NVIDIA GeForce RTX 3090\n",
      "[2022-12-08 09:36:07] 3687493274.py[  13] : INFO  gpus: [0]\n",
      "[2022-12-08 09:36:07] 3687493274.py[  14] : INFO  n_workers: 128\n",
      "[2022-12-08 09:36:07] 3687493274.py[  15] : INFO  image_size: [1024, 1024]\n",
      "[2022-12-08 09:36:07] 3687493274.py[  16] : INFO  seed: 14\n",
      "[2022-12-08 09:36:07] 3687493274.py[  17] : INFO  min_epochs: 50\n",
      "[2022-12-08 09:36:07] 3687493274.py[  18] : INFO  max_epochs: 100\n",
      "[2022-12-08 09:36:07] 3687493274.py[  19] : INFO  patience: 11\n",
      "[2022-12-08 09:36:07] 3687493274.py[  20] : INFO  train_batch_size: 4\n",
      "[2022-12-08 09:36:07] 3687493274.py[  21] : INFO  val_batch_size: 4\n",
      "[2022-12-08 09:36:07] 3687493274.py[  22] : INFO  n_splits: 3\n",
      "[2022-12-08 09:36:07] 3687493274.py[  23] : INFO  test_size: 0.1\n",
      "[2022-12-08 09:36:07] 3687493274.py[  24] : INFO  learning rate: 0.0001\n",
      "[2022-12-08 09:36:07] 3687493274.py[  25] : INFO  weight_decay: 0\n",
      "[2022-12-08 09:36:07] 3687493274.py[  26] : INFO  epsilon: 1e-08\n",
      "[2022-12-08 09:36:07] 3687493274.py[  27] : INFO  amsgrad: True\n",
      "[2022-12-08 09:36:07] 3687493274.py[  28] : INFO  betas: (0.9, 0.999)\n",
      "[2022-12-08 09:36:07] 3687493274.py[  29] : INFO  precision: 16\n",
      "[2022-12-08 09:36:07] 3687493274.py[  30] : INFO  gradient_clip_val: 1.0\n",
      "[2022-12-08 09:36:07] 3687493274.py[  31] : INFO  eta_min: 5e-06\n",
      "[2022-12-08 09:36:07] 3687493274.py[  32] : INFO  t_max: 15\n",
      "[2022-12-08 09:36:07] 3687493274.py[  33] : INFO  t_mult: 6\n",
      "[2022-12-08 09:36:07] 3687493274.py[  34] : INFO  log_dir: ../logs/logs\n",
      "[2022-12-08 09:36:07] 3687493274.py[  35] : INFO  log_name: 2022_12_08_09:35:33\n",
      "[2022-12-08 09:36:07] 3687493274.py[  39] : INFO  Notes: t_mult increased to 6 from 5\n",
      "[2022-12-08 09:36:07] 3687493274.py[  61] : INFO  Fold 0 num train records: 199\n",
      "[2022-12-08 09:36:07] 3687493274.py[  62] : INFO  Fold 0 num val records: 100\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "[2022-12-08 09:36:47] 1068281035.py[  95] : INFO  0-0 | lr : 0.000100 | val_loss : 2.0603 | val_roc_auc : 0.7276 | data_load_times : 45.23 | batch_run_times : 45.78\n",
      "[2022-12-08 09:37:24] 1068281035.py[  95] : INFO  0-1 | lr : 0.000099 | val_loss : 2.0105 | val_roc_auc : 0.7930 | data_load_times : 46.64 | batch_run_times : 47.17\n",
      "[2022-12-08 09:38:00] 1068281035.py[  95] : INFO  0-2 | lr : 0.000096 | val_loss : 1.9602 | val_roc_auc : 0.7833 | data_load_times : 43.58 | batch_run_times : 44.15\n",
      "[2022-12-08 09:38:37] 1068281035.py[  95] : INFO  0-3 | lr : 0.000091 | val_loss : 1.9383 | val_roc_auc : 0.7887 | data_load_times : 46.55 | batch_run_times : 47.31\n",
      "[2022-12-08 09:39:13] 1068281035.py[  95] : INFO  0-4 | lr : 0.000084 | val_loss : 1.8984 | val_roc_auc : 0.8114 | data_load_times : 45.04 | batch_run_times : 45.66\n",
      "[2022-12-08 09:39:50] 1068281035.py[  95] : INFO  0-5 | lr : 0.000076 | val_loss : 1.8681 | val_roc_auc : 0.7882 | data_load_times : 46.76 | batch_run_times : 47.34\n",
      "[2022-12-08 09:40:27] 1068281035.py[  95] : INFO  0-6 | lr : 0.000067 | val_loss : 1.8265 | val_roc_auc : 0.7990 | data_load_times : 47.26 | batch_run_times : 47.86\n",
      "[2022-12-08 09:41:04] 1068281035.py[  95] : INFO  0-7 | lr : 0.000057 | val_loss : 1.8155 | val_roc_auc : 0.8294 | data_load_times : 46.59 | batch_run_times : 47.19\n",
      "[2022-12-08 09:41:41] 1068281035.py[  95] : INFO  0-8 | lr : 0.000048 | val_loss : 1.7804 | val_roc_auc : 0.8234 | data_load_times : 44.84 | batch_run_times : 45.44\n",
      "[2022-12-08 09:42:18] 1068281035.py[  95] : INFO  0-9 | lr : 0.000038 | val_loss : 1.7564 | val_roc_auc : 0.8292 | data_load_times : 45.12 | batch_run_times : 45.72\n",
      "[2022-12-08 09:42:54] 1068281035.py[  95] : INFO  0-10 | lr : 0.000029 | val_loss : 1.7286 | val_roc_auc : 0.8428 | data_load_times : 45.33 | batch_run_times : 45.91\n",
      "[2022-12-08 09:43:32] 1068281035.py[  95] : INFO  0-11 | lr : 0.000021 | val_loss : 1.7194 | val_roc_auc : 0.8492 | data_load_times : 45.89 | batch_run_times : 46.49\n",
      "[2022-12-08 09:44:09] 1068281035.py[  95] : INFO  0-12 | lr : 0.000014 | val_loss : 1.7062 | val_roc_auc : 0.8560 | data_load_times : 48.00 | batch_run_times : 48.56\n",
      "[2022-12-08 09:44:46] 1068281035.py[  95] : INFO  0-13 | lr : 0.000009 | val_loss : 1.6905 | val_roc_auc : 0.8563 | data_load_times : 45.54 | batch_run_times : 46.09\n",
      "[2022-12-08 09:45:23] 1068281035.py[  95] : INFO  0-14 | lr : 0.000006 | val_loss : 1.6990 | val_roc_auc : 0.8520 | data_load_times : 46.68 | batch_run_times : 47.23\n",
      "[2022-12-08 09:46:00] 1068281035.py[  95] : INFO  0-15 | lr : 0.000100 | val_loss : 1.7537 | val_roc_auc : 0.8156 | data_load_times : 44.00 | batch_run_times : 44.55\n",
      "[2022-12-08 09:46:36] 1068281035.py[  95] : INFO  0-16 | lr : 0.000100 | val_loss : 1.7115 | val_roc_auc : 0.8282 | data_load_times : 45.83 | batch_run_times : 46.46\n",
      "[2022-12-08 09:47:12] 1068281035.py[  95] : INFO  0-17 | lr : 0.000100 | val_loss : 1.7168 | val_roc_auc : 0.8256 | data_load_times : 46.60 | batch_run_times : 47.18\n",
      "[2022-12-08 09:47:48] 1068281035.py[  95] : INFO  0-18 | lr : 0.000100 | val_loss : 1.7651 | val_roc_auc : 0.7803 | data_load_times : 43.19 | batch_run_times : 43.88\n",
      "[2022-12-08 09:48:24] 1068281035.py[  95] : INFO  0-19 | lr : 0.000100 | val_loss : 1.6411 | val_roc_auc : 0.8355 | data_load_times : 44.32 | batch_run_times : 44.87\n",
      "[2022-12-08 09:49:01] 1068281035.py[  95] : INFO  0-20 | lr : 0.000099 | val_loss : 1.5688 | val_roc_auc : 0.8288 | data_load_times : 45.75 | batch_run_times : 46.38\n",
      "[2022-12-08 09:49:38] 1068281035.py[  95] : INFO  0-21 | lr : 0.000099 | val_loss : 1.6248 | val_roc_auc : 0.7985 | data_load_times : 46.26 | batch_run_times : 47.02\n",
      "[2022-12-08 09:50:16] 1068281035.py[  95] : INFO  0-22 | lr : 0.000099 | val_loss : 1.5806 | val_roc_auc : 0.8231 | data_load_times : 48.71 | batch_run_times : 49.29\n",
      "[2022-12-08 09:50:52] 1068281035.py[  95] : INFO  0-23 | lr : 0.000098 | val_loss : 1.6575 | val_roc_auc : 0.7850 | data_load_times : 46.46 | batch_run_times : 47.02\n",
      "[2022-12-08 09:51:29] 1068281035.py[  95] : INFO  0-24 | lr : 0.000098 | val_loss : 1.6114 | val_roc_auc : 0.8034 | data_load_times : 45.95 | batch_run_times : 46.58\n",
      "[2022-12-08 09:52:05] 1068281035.py[  95] : INFO  0-25 | lr : 0.000097 | val_loss : 1.6064 | val_roc_auc : 0.8128 | data_load_times : 46.46 | batch_run_times : 47.03\n",
      "[2022-12-08 09:52:41] 1068281035.py[  95] : INFO  0-26 | lr : 0.000097 | val_loss : 1.5852 | val_roc_auc : 0.8175 | data_load_times : 47.17 | batch_run_times : 47.74\n",
      "[2022-12-08 09:53:18] 1068281035.py[  95] : INFO  0-27 | lr : 0.000096 | val_loss : 1.5804 | val_roc_auc : 0.7971 | data_load_times : 45.60 | batch_run_times : 46.13\n",
      "[2022-12-08 09:53:55] 1068281035.py[  95] : INFO  0-28 | lr : 0.000095 | val_loss : 1.5162 | val_roc_auc : 0.8058 | data_load_times : 45.37 | batch_run_times : 45.95\n",
      "[2022-12-08 09:54:33] 1068281035.py[  95] : INFO  0-29 | lr : 0.000094 | val_loss : 1.4917 | val_roc_auc : 0.8127 | data_load_times : 45.94 | batch_run_times : 46.49\n",
      "[2022-12-08 09:55:09] 1068281035.py[  95] : INFO  0-30 | lr : 0.000094 | val_loss : 1.6064 | val_roc_auc : 0.8014 | data_load_times : 47.14 | batch_run_times : 48.16\n",
      "[2022-12-08 09:55:45] 1068281035.py[  95] : INFO  0-31 | lr : 0.000093 | val_loss : 1.6449 | val_roc_auc : 0.8051 | data_load_times : 45.25 | batch_run_times : 45.82\n",
      "[2022-12-08 09:56:21] 1068281035.py[  95] : INFO  0-32 | lr : 0.000092 | val_loss : 1.5390 | val_roc_auc : 0.7992 | data_load_times : 45.23 | batch_run_times : 45.85\n",
      "[2022-12-08 09:56:58] 1068281035.py[  95] : INFO  0-33 | lr : 0.000091 | val_loss : 1.5462 | val_roc_auc : 0.8031 | data_load_times : 47.41 | batch_run_times : 47.97\n",
      "[2022-12-08 09:57:34] 1068281035.py[  95] : INFO  0-34 | lr : 0.000090 | val_loss : 1.5469 | val_roc_auc : 0.7903 | data_load_times : 43.82 | batch_run_times : 44.40\n",
      "[2022-12-08 09:58:10] 1068281035.py[  95] : INFO  0-35 | lr : 0.000089 | val_loss : 1.5214 | val_roc_auc : 0.7665 | data_load_times : 46.34 | batch_run_times : 46.94\n",
      "[2022-12-08 09:58:46] 1068281035.py[  95] : INFO  0-36 | lr : 0.000088 | val_loss : 1.5205 | val_roc_auc : 0.8214 | data_load_times : 46.21 | batch_run_times : 46.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-08 09:59:22] 1068281035.py[  95] : INFO  0-37 | lr : 0.000087 | val_loss : 1.4747 | val_roc_auc : 0.7765 | data_load_times : 45.36 | batch_run_times : 45.90\n",
      "[2022-12-08 09:59:58] 1068281035.py[  95] : INFO  0-38 | lr : 0.000085 | val_loss : 1.4120 | val_roc_auc : 0.7850 | data_load_times : 45.80 | batch_run_times : 46.38\n",
      "[2022-12-08 10:00:36] 1068281035.py[  95] : INFO  0-39 | lr : 0.000084 | val_loss : 1.3271 | val_roc_auc : 0.8353 | data_load_times : 46.07 | batch_run_times : 46.62\n",
      "[2022-12-08 10:01:13] 1068281035.py[  95] : INFO  0-40 | lr : 0.000083 | val_loss : 1.5139 | val_roc_auc : 0.8033 | data_load_times : 45.05 | batch_run_times : 45.61\n",
      "[2022-12-08 10:01:49] 1068281035.py[  95] : INFO  0-41 | lr : 0.000082 | val_loss : 1.4819 | val_roc_auc : 0.8163 | data_load_times : 46.24 | batch_run_times : 46.81\n",
      "[2022-12-08 10:02:26] 1068281035.py[  95] : INFO  0-42 | lr : 0.000080 | val_loss : 1.6713 | val_roc_auc : 0.7933 | data_load_times : 35.83 | batch_run_times : 36.65\n",
      "[2022-12-08 10:03:02] 1068281035.py[  95] : INFO  0-43 | lr : 0.000079 | val_loss : 1.5069 | val_roc_auc : 0.7738 | data_load_times : 45.56 | batch_run_times : 46.12\n",
      "[2022-12-08 10:03:38] 1068281035.py[  95] : INFO  0-44 | lr : 0.000078 | val_loss : 1.5600 | val_roc_auc : 0.8144 | data_load_times : 46.62 | batch_run_times : 47.21\n",
      "[2022-12-08 10:04:14] 1068281035.py[  95] : INFO  0-45 | lr : 0.000076 | val_loss : 1.5754 | val_roc_auc : 0.8031 | data_load_times : 44.15 | batch_run_times : 44.71\n",
      "[2022-12-08 10:04:50] 1068281035.py[  95] : INFO  0-46 | lr : 0.000075 | val_loss : 1.5995 | val_roc_auc : 0.7880 | data_load_times : 45.50 | batch_run_times : 46.07\n",
      "[2022-12-08 10:05:26] 1068281035.py[  95] : INFO  0-47 | lr : 0.000073 | val_loss : 1.6305 | val_roc_auc : 0.7714 | data_load_times : 44.94 | batch_run_times : 45.52\n",
      "[2022-12-08 10:06:03] 1068281035.py[  95] : INFO  0-48 | lr : 0.000072 | val_loss : 1.5678 | val_roc_auc : 0.7557 | data_load_times : 46.42 | batch_run_times : 47.01\n",
      "[2022-12-08 10:06:39] 1068281035.py[  95] : INFO  0-49 | lr : 0.000070 | val_loss : 1.7289 | val_roc_auc : 0.7820 | data_load_times : 46.22 | batch_run_times : 46.84\n",
      "[2022-12-08 10:07:15] 1068281035.py[  95] : INFO  0-50 | lr : 0.000069 | val_loss : 1.5980 | val_roc_auc : 0.7788 | data_load_times : 45.80 | batch_run_times : 46.39\n",
      "Epoch 00051: early stopping triggered.\n",
      "[2022-12-08 10:07:15] 3687493274.py[  61] : INFO  Fold 1 num train records: 199\n",
      "[2022-12-08 10:07:15] 3687493274.py[  62] : INFO  Fold 1 num val records: 100\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "[2022-12-08 10:07:54] 1068281035.py[  95] : INFO  1-0 | lr : 0.000100 | val_loss : 2.0366 | val_roc_auc : 0.7516 | data_load_times : 45.47 | batch_run_times : 46.06\n",
      "[2022-12-08 10:08:33] 1068281035.py[  95] : INFO  1-1 | lr : 0.000099 | val_loss : 1.9829 | val_roc_auc : 0.7866 | data_load_times : 45.22 | batch_run_times : 45.81\n",
      "[2022-12-08 10:09:13] 1068281035.py[  95] : INFO  1-2 | lr : 0.000096 | val_loss : 1.9483 | val_roc_auc : 0.7766 | data_load_times : 46.59 | batch_run_times : 47.15\n",
      "[2022-12-08 10:09:52] 1068281035.py[  95] : INFO  1-3 | lr : 0.000091 | val_loss : 1.9183 | val_roc_auc : 0.7932 | data_load_times : 45.15 | batch_run_times : 45.72\n",
      "[2022-12-08 10:10:31] 1068281035.py[  95] : INFO  1-4 | lr : 0.000084 | val_loss : 1.8550 | val_roc_auc : 0.8329 | data_load_times : 46.37 | batch_run_times : 47.03\n",
      "[2022-12-08 10:11:11] 1068281035.py[  95] : INFO  1-5 | lr : 0.000076 | val_loss : 1.8685 | val_roc_auc : 0.7884 | data_load_times : 48.51 | batch_run_times : 49.05\n",
      "[2022-12-08 10:11:50] 1068281035.py[  95] : INFO  1-6 | lr : 0.000067 | val_loss : 1.8289 | val_roc_auc : 0.8087 | data_load_times : 48.16 | batch_run_times : 48.74\n",
      "[2022-12-08 10:12:30] 1068281035.py[  95] : INFO  1-7 | lr : 0.000057 | val_loss : 1.8284 | val_roc_auc : 0.7814 | data_load_times : 46.64 | batch_run_times : 47.22\n",
      "[2022-12-08 10:13:09] 1068281035.py[  95] : INFO  1-8 | lr : 0.000048 | val_loss : 1.7689 | val_roc_auc : 0.8293 | data_load_times : 47.07 | batch_run_times : 47.62\n",
      "[2022-12-08 10:13:48] 1068281035.py[  95] : INFO  1-9 | lr : 0.000038 | val_loss : 1.7529 | val_roc_auc : 0.8231 | data_load_times : 45.79 | batch_run_times : 46.38\n",
      "[2022-12-08 10:14:28] 1068281035.py[  95] : INFO  1-10 | lr : 0.000029 | val_loss : 1.7239 | val_roc_auc : 0.8274 | data_load_times : 45.54 | batch_run_times : 46.12\n",
      "[2022-12-08 10:15:07] 1068281035.py[  95] : INFO  1-11 | lr : 0.000021 | val_loss : 1.7087 | val_roc_auc : 0.8269 | data_load_times : 47.19 | batch_run_times : 47.76\n",
      "[2022-12-08 10:15:47] 1068281035.py[  95] : INFO  1-12 | lr : 0.000014 | val_loss : 1.7047 | val_roc_auc : 0.8317 | data_load_times : 46.11 | batch_run_times : 46.68\n",
      "[2022-12-08 10:16:26] 1068281035.py[  95] : INFO  1-13 | lr : 0.000009 | val_loss : 1.6936 | val_roc_auc : 0.8321 | data_load_times : 46.20 | batch_run_times : 46.75\n",
      "[2022-12-08 10:17:06] 1068281035.py[  95] : INFO  1-14 | lr : 0.000006 | val_loss : 1.6997 | val_roc_auc : 0.8304 | data_load_times : 45.02 | batch_run_times : 45.57\n",
      "[2022-12-08 10:17:46] 1068281035.py[  95] : INFO  1-15 | lr : 0.000100 | val_loss : 1.7197 | val_roc_auc : 0.8234 | data_load_times : 45.72 | batch_run_times : 46.34\n",
      "[2022-12-08 10:18:24] 1068281035.py[  95] : INFO  1-16 | lr : 0.000100 | val_loss : 1.7192 | val_roc_auc : 0.7996 | data_load_times : 45.05 | batch_run_times : 45.78\n",
      "[2022-12-08 10:19:02] 1068281035.py[  95] : INFO  1-17 | lr : 0.000100 | val_loss : 1.7092 | val_roc_auc : 0.8038 | data_load_times : 47.91 | batch_run_times : 48.54\n",
      "[2022-12-08 10:19:41] 1068281035.py[  95] : INFO  1-18 | lr : 0.000100 | val_loss : 1.7172 | val_roc_auc : 0.7868 | data_load_times : 47.70 | batch_run_times : 48.36\n",
      "[2022-12-08 10:20:19] 1068281035.py[  95] : INFO  1-19 | lr : 0.000100 | val_loss : 1.7638 | val_roc_auc : 0.7823 | data_load_times : 44.29 | batch_run_times : 44.87\n",
      "[2022-12-08 10:20:58] 1068281035.py[  95] : INFO  1-20 | lr : 0.000099 | val_loss : 1.6057 | val_roc_auc : 0.8232 | data_load_times : 45.23 | batch_run_times : 45.78\n",
      "[2022-12-08 10:21:38] 1068281035.py[  95] : INFO  1-21 | lr : 0.000099 | val_loss : 1.6799 | val_roc_auc : 0.8045 | data_load_times : 46.58 | batch_run_times : 47.21\n",
      "[2022-12-08 10:22:17] 1068281035.py[  95] : INFO  1-22 | lr : 0.000099 | val_loss : 1.5846 | val_roc_auc : 0.8267 | data_load_times : 46.00 | batch_run_times : 46.63\n",
      "[2022-12-08 10:22:57] 1068281035.py[  95] : INFO  1-23 | lr : 0.000098 | val_loss : 1.6498 | val_roc_auc : 0.8035 | data_load_times : 46.33 | batch_run_times : 46.88\n",
      "[2022-12-08 10:23:36] 1068281035.py[  95] : INFO  1-24 | lr : 0.000098 | val_loss : 1.6309 | val_roc_auc : 0.7980 | data_load_times : 46.74 | batch_run_times : 47.31\n",
      "[2022-12-08 10:24:14] 1068281035.py[  95] : INFO  1-25 | lr : 0.000097 | val_loss : 1.5391 | val_roc_auc : 0.8280 | data_load_times : 43.58 | batch_run_times : 44.15\n",
      "[2022-12-08 10:24:54] 1068281035.py[  95] : INFO  1-26 | lr : 0.000097 | val_loss : 1.6693 | val_roc_auc : 0.7959 | data_load_times : 43.80 | batch_run_times : 44.38\n",
      "[2022-12-08 10:25:32] 1068281035.py[  95] : INFO  1-27 | lr : 0.000096 | val_loss : 1.6199 | val_roc_auc : 0.8150 | data_load_times : 44.96 | batch_run_times : 45.53\n",
      "[2022-12-08 10:26:11] 1068281035.py[  95] : INFO  1-28 | lr : 0.000095 | val_loss : 1.5847 | val_roc_auc : 0.8177 | data_load_times : 44.11 | batch_run_times : 44.72\n",
      "[2022-12-08 10:26:50] 1068281035.py[  95] : INFO  1-29 | lr : 0.000094 | val_loss : 1.5369 | val_roc_auc : 0.8241 | data_load_times : 47.06 | batch_run_times : 47.67\n",
      "[2022-12-08 10:27:30] 1068281035.py[  95] : INFO  1-30 | lr : 0.000094 | val_loss : 1.6502 | val_roc_auc : 0.7834 | data_load_times : 44.97 | batch_run_times : 45.53\n",
      "[2022-12-08 10:28:08] 1068281035.py[  95] : INFO  1-31 | lr : 0.000093 | val_loss : 1.6610 | val_roc_auc : 0.7792 | data_load_times : 45.84 | batch_run_times : 46.46\n",
      "[2022-12-08 10:28:47] 1068281035.py[  95] : INFO  1-32 | lr : 0.000092 | val_loss : 1.5889 | val_roc_auc : 0.7948 | data_load_times : 45.44 | batch_run_times : 46.01\n",
      "[2022-12-08 10:29:25] 1068281035.py[  95] : INFO  1-33 | lr : 0.000091 | val_loss : 1.5674 | val_roc_auc : 0.8165 | data_load_times : 44.14 | batch_run_times : 44.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-08 10:30:04] 1068281035.py[  95] : INFO  1-34 | lr : 0.000090 | val_loss : 1.6960 | val_roc_auc : 0.7690 | data_load_times : 44.58 | batch_run_times : 45.14\n",
      "[2022-12-08 10:30:43] 1068281035.py[  95] : INFO  1-35 | lr : 0.000089 | val_loss : 1.7396 | val_roc_auc : 0.7498 | data_load_times : 46.15 | batch_run_times : 46.77\n",
      "[2022-12-08 10:31:21] 1068281035.py[  95] : INFO  1-36 | lr : 0.000088 | val_loss : 1.5753 | val_roc_auc : 0.8063 | data_load_times : 45.83 | batch_run_times : 46.66\n",
      "[2022-12-08 10:32:00] 1068281035.py[  95] : INFO  1-37 | lr : 0.000087 | val_loss : 1.6585 | val_roc_auc : 0.7722 | data_load_times : 44.80 | batch_run_times : 45.35\n",
      "[2022-12-08 10:32:39] 1068281035.py[  95] : INFO  1-38 | lr : 0.000085 | val_loss : 1.5753 | val_roc_auc : 0.7776 | data_load_times : 46.27 | batch_run_times : 47.13\n",
      "[2022-12-08 10:33:17] 1068281035.py[  95] : INFO  1-39 | lr : 0.000084 | val_loss : 1.6590 | val_roc_auc : 0.7835 | data_load_times : 46.41 | batch_run_times : 46.95\n",
      "[2022-12-08 10:33:56] 1068281035.py[  95] : INFO  1-40 | lr : 0.000083 | val_loss : 1.5998 | val_roc_auc : 0.8015 | data_load_times : 44.98 | batch_run_times : 45.61\n",
      "Trainer was signaled to stop but required minimum epochs (50) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-08 10:34:34] 1068281035.py[  95] : INFO  1-41 | lr : 0.000082 | val_loss : 1.7680 | val_roc_auc : 0.7878 | data_load_times : 46.15 | batch_run_times : 46.75\n",
      "Trainer was signaled to stop but required minimum epochs (50) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-08 10:35:13] 1068281035.py[  95] : INFO  1-42 | lr : 0.000080 | val_loss : 1.7330 | val_roc_auc : 0.7319 | data_load_times : 44.59 | batch_run_times : 45.19\n",
      "Trainer was signaled to stop but required minimum epochs (50) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-08 10:35:52] 1068281035.py[  95] : INFO  1-43 | lr : 0.000079 | val_loss : 1.6876 | val_roc_auc : 0.7775 | data_load_times : 45.21 | batch_run_times : 45.88\n",
      "Trainer was signaled to stop but required minimum epochs (50) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-08 10:36:31] 1068281035.py[  95] : INFO  1-44 | lr : 0.000078 | val_loss : 1.7687 | val_roc_auc : 0.7559 | data_load_times : 45.98 | batch_run_times : 46.63\n",
      "Trainer was signaled to stop but required minimum epochs (50) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-08 10:37:10] 1068281035.py[  95] : INFO  1-45 | lr : 0.000076 | val_loss : 1.8580 | val_roc_auc : 0.7772 | data_load_times : 46.93 | batch_run_times : 47.48\n",
      "Trainer was signaled to stop but required minimum epochs (50) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-08 10:37:49] 1068281035.py[  95] : INFO  1-46 | lr : 0.000075 | val_loss : 1.8602 | val_roc_auc : 0.7469 | data_load_times : 43.93 | batch_run_times : 44.48\n",
      "Trainer was signaled to stop but required minimum epochs (50) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-08 10:38:28] 1068281035.py[  95] : INFO  1-47 | lr : 0.000073 | val_loss : 1.9561 | val_roc_auc : 0.7553 | data_load_times : 46.38 | batch_run_times : 46.93\n",
      "Trainer was signaled to stop but required minimum epochs (50) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-08 10:39:06] 1068281035.py[  95] : INFO  1-48 | lr : 0.000072 | val_loss : 1.8003 | val_roc_auc : 0.7593 | data_load_times : 46.90 | batch_run_times : 47.46\n",
      "Trainer was signaled to stop but required minimum epochs (50) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-08 10:39:45] 1068281035.py[  95] : INFO  1-49 | lr : 0.000070 | val_loss : 1.8857 | val_roc_auc : 0.7464 | data_load_times : 44.87 | batch_run_times : 45.44\n",
      "Epoch 00050: early stopping triggered.\n",
      "[2022-12-08 10:39:46] 3687493274.py[  61] : INFO  Fold 2 num train records: 200\n",
      "[2022-12-08 10:39:46] 3687493274.py[  62] : INFO  Fold 2 num val records: 99\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "[2022-12-08 10:40:25] 1068281035.py[  95] : INFO  2-0 | lr : 0.000100 | val_loss : 2.0631 | val_roc_auc : 0.6065 | data_load_times : 44.42 | batch_run_times : 45.00\n",
      "[2022-12-08 10:41:06] 1068281035.py[  95] : INFO  2-1 | lr : 0.000099 | val_loss : 2.0364 | val_roc_auc : 0.6786 | data_load_times : 44.59 | batch_run_times : 45.21\n",
      "[2022-12-08 10:41:46] 1068281035.py[  95] : INFO  2-2 | lr : 0.000096 | val_loss : 2.0042 | val_roc_auc : 0.7140 | data_load_times : 45.13 | batch_run_times : 45.70\n",
      "[2022-12-08 10:42:27] 1068281035.py[  95] : INFO  2-3 | lr : 0.000091 | val_loss : 1.9798 | val_roc_auc : 0.7481 | data_load_times : 47.07 | batch_run_times : 47.69\n",
      "[2022-12-08 10:43:07] 1068281035.py[  95] : INFO  2-4 | lr : 0.000084 | val_loss : 1.9245 | val_roc_auc : 0.7568 | data_load_times : 46.24 | batch_run_times : 46.81\n",
      "[2022-12-08 10:43:48] 1068281035.py[  95] : INFO  2-5 | lr : 0.000076 | val_loss : 1.8707 | val_roc_auc : 0.7930 | data_load_times : 47.88 | batch_run_times : 48.48\n",
      "[2022-12-08 10:44:29] 1068281035.py[  95] : INFO  2-6 | lr : 0.000067 | val_loss : 1.8569 | val_roc_auc : 0.8044 | data_load_times : 47.52 | batch_run_times : 48.08\n",
      "[2022-12-08 10:45:10] 1068281035.py[  95] : INFO  2-7 | lr : 0.000057 | val_loss : 1.8380 | val_roc_auc : 0.8060 | data_load_times : 47.53 | batch_run_times : 48.08\n",
      "[2022-12-08 10:45:50] 1068281035.py[  95] : INFO  2-8 | lr : 0.000048 | val_loss : 1.8030 | val_roc_auc : 0.8021 | data_load_times : 46.58 | batch_run_times : 47.14\n",
      "[2022-12-08 10:46:31] 1068281035.py[  95] : INFO  2-9 | lr : 0.000038 | val_loss : 1.7630 | val_roc_auc : 0.8280 | data_load_times : 47.05 | batch_run_times : 47.65\n",
      "[2022-12-08 10:47:12] 1068281035.py[  95] : INFO  2-10 | lr : 0.000029 | val_loss : 1.7615 | val_roc_auc : 0.8244 | data_load_times : 47.07 | batch_run_times : 47.71\n",
      "[2022-12-08 10:47:53] 1068281035.py[  95] : INFO  2-11 | lr : 0.000021 | val_loss : 1.7476 | val_roc_auc : 0.8123 | data_load_times : 46.54 | batch_run_times : 47.10\n",
      "[2022-12-08 10:48:34] 1068281035.py[  95] : INFO  2-12 | lr : 0.000014 | val_loss : 1.7354 | val_roc_auc : 0.8118 | data_load_times : 49.32 | batch_run_times : 49.86\n",
      "[2022-12-08 10:49:15] 1068281035.py[  95] : INFO  2-13 | lr : 0.000009 | val_loss : 1.7420 | val_roc_auc : 0.8231 | data_load_times : 46.82 | batch_run_times : 47.48\n",
      "[2022-12-08 10:49:56] 1068281035.py[  95] : INFO  2-14 | lr : 0.000006 | val_loss : 1.7270 | val_roc_auc : 0.8180 | data_load_times : 48.34 | batch_run_times : 48.93\n",
      "[2022-12-08 10:50:36] 1068281035.py[  95] : INFO  2-15 | lr : 0.000100 | val_loss : 1.7354 | val_roc_auc : 0.8270 | data_load_times : 48.64 | batch_run_times : 49.21\n",
      "[2022-12-08 10:51:17] 1068281035.py[  95] : INFO  2-16 | lr : 0.000100 | val_loss : 1.7377 | val_roc_auc : 0.8193 | data_load_times : 46.67 | batch_run_times : 47.29\n",
      "[2022-12-08 10:51:57] 1068281035.py[  95] : INFO  2-17 | lr : 0.000100 | val_loss : 1.7191 | val_roc_auc : 0.8054 | data_load_times : 44.17 | batch_run_times : 44.75\n",
      "[2022-12-08 10:52:37] 1068281035.py[  95] : INFO  2-18 | lr : 0.000100 | val_loss : 1.6814 | val_roc_auc : 0.8104 | data_load_times : 46.76 | batch_run_times : 47.43\n",
      "[2022-12-08 10:53:18] 1068281035.py[  95] : INFO  2-19 | lr : 0.000100 | val_loss : 1.6831 | val_roc_auc : 0.8122 | data_load_times : 46.97 | batch_run_times : 47.55\n",
      "[2022-12-08 10:53:59] 1068281035.py[  95] : INFO  2-20 | lr : 0.000099 | val_loss : 1.6077 | val_roc_auc : 0.8488 | data_load_times : 47.89 | batch_run_times : 48.56\n",
      "[2022-12-08 10:54:40] 1068281035.py[  95] : INFO  2-21 | lr : 0.000099 | val_loss : 1.6035 | val_roc_auc : 0.8366 | data_load_times : 45.99 | batch_run_times : 46.58\n",
      "[2022-12-08 10:55:21] 1068281035.py[  95] : INFO  2-22 | lr : 0.000099 | val_loss : 1.6045 | val_roc_auc : 0.7909 | data_load_times : 48.18 | batch_run_times : 48.75\n",
      "[2022-12-08 10:56:02] 1068281035.py[  95] : INFO  2-23 | lr : 0.000098 | val_loss : 1.5657 | val_roc_auc : 0.8246 | data_load_times : 48.41 | batch_run_times : 49.01\n",
      "[2022-12-08 10:56:42] 1068281035.py[  95] : INFO  2-24 | lr : 0.000098 | val_loss : 1.5596 | val_roc_auc : 0.8107 | data_load_times : 47.58 | batch_run_times : 48.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-08 10:57:23] 1068281035.py[  95] : INFO  2-25 | lr : 0.000097 | val_loss : 1.5535 | val_roc_auc : 0.8218 | data_load_times : 48.53 | batch_run_times : 49.15\n",
      "[2022-12-08 10:58:03] 1068281035.py[  95] : INFO  2-26 | lr : 0.000097 | val_loss : 1.5443 | val_roc_auc : 0.8217 | data_load_times : 45.57 | batch_run_times : 46.18\n",
      "[2022-12-08 10:58:44] 1068281035.py[  95] : INFO  2-27 | lr : 0.000096 | val_loss : 1.5695 | val_roc_auc : 0.8047 | data_load_times : 48.36 | batch_run_times : 48.92\n",
      "[2022-12-08 10:59:24] 1068281035.py[  95] : INFO  2-28 | lr : 0.000095 | val_loss : 1.5927 | val_roc_auc : 0.7822 | data_load_times : 47.85 | batch_run_times : 48.38\n",
      "[2022-12-08 11:00:05] 1068281035.py[  95] : INFO  2-29 | lr : 0.000094 | val_loss : 1.5698 | val_roc_auc : 0.7734 | data_load_times : 46.66 | batch_run_times : 47.21\n",
      "[2022-12-08 11:00:45] 1068281035.py[  95] : INFO  2-30 | lr : 0.000094 | val_loss : 1.4674 | val_roc_auc : 0.8141 | data_load_times : 46.33 | batch_run_times : 46.87\n",
      "[2022-12-08 11:01:26] 1068281035.py[  95] : INFO  2-31 | lr : 0.000093 | val_loss : 1.4447 | val_roc_auc : 0.8188 | data_load_times : 46.84 | batch_run_times : 47.39\n",
      "[2022-12-08 11:02:07] 1068281035.py[  95] : INFO  2-32 | lr : 0.000092 | val_loss : 1.4667 | val_roc_auc : 0.8334 | data_load_times : 46.38 | batch_run_times : 46.96\n",
      "[2022-12-08 11:02:48] 1068281035.py[  95] : INFO  2-33 | lr : 0.000091 | val_loss : 1.5036 | val_roc_auc : 0.8017 | data_load_times : 46.05 | batch_run_times : 46.71\n",
      "[2022-12-08 11:03:28] 1068281035.py[  95] : INFO  2-34 | lr : 0.000090 | val_loss : 1.4535 | val_roc_auc : 0.8112 | data_load_times : 47.13 | batch_run_times : 47.69\n",
      "[2022-12-08 11:04:08] 1068281035.py[  95] : INFO  2-35 | lr : 0.000089 | val_loss : 1.4436 | val_roc_auc : 0.8029 | data_load_times : 45.66 | batch_run_times : 46.25\n",
      "[2022-12-08 11:04:49] 1068281035.py[  95] : INFO  2-36 | lr : 0.000088 | val_loss : 1.4629 | val_roc_auc : 0.8109 | data_load_times : 48.52 | batch_run_times : 49.22\n",
      "[2022-12-08 11:05:29] 1068281035.py[  95] : INFO  2-37 | lr : 0.000087 | val_loss : 1.5761 | val_roc_auc : 0.7790 | data_load_times : 46.48 | batch_run_times : 47.09\n",
      "[2022-12-08 11:06:09] 1068281035.py[  95] : INFO  2-38 | lr : 0.000085 | val_loss : 1.3642 | val_roc_auc : 0.8299 | data_load_times : 47.14 | batch_run_times : 47.67\n",
      "[2022-12-08 11:06:50] 1068281035.py[  95] : INFO  2-39 | lr : 0.000084 | val_loss : 1.4113 | val_roc_auc : 0.8313 | data_load_times : 46.73 | batch_run_times : 47.44\n",
      "[2022-12-08 11:07:30] 1068281035.py[  95] : INFO  2-40 | lr : 0.000083 | val_loss : 1.5340 | val_roc_auc : 0.8118 | data_load_times : 49.78 | batch_run_times : 50.59\n",
      "[2022-12-08 11:08:10] 1068281035.py[  95] : INFO  2-41 | lr : 0.000082 | val_loss : 1.4094 | val_roc_auc : 0.8131 | data_load_times : 47.27 | batch_run_times : 47.85\n",
      "[2022-12-08 11:08:51] 1068281035.py[  95] : INFO  2-42 | lr : 0.000080 | val_loss : 1.4967 | val_roc_auc : 0.8150 | data_load_times : 48.23 | batch_run_times : 48.79\n",
      "[2022-12-08 11:09:31] 1068281035.py[  95] : INFO  2-43 | lr : 0.000079 | val_loss : 1.5330 | val_roc_auc : 0.8105 | data_load_times : 46.63 | batch_run_times : 47.27\n",
      "[2022-12-08 11:10:12] 1068281035.py[  95] : INFO  2-44 | lr : 0.000078 | val_loss : 1.4985 | val_roc_auc : 0.8194 | data_load_times : 48.63 | batch_run_times : 49.27\n",
      "[2022-12-08 11:10:52] 1068281035.py[  95] : INFO  2-45 | lr : 0.000076 | val_loss : 1.5379 | val_roc_auc : 0.8177 | data_load_times : 47.09 | batch_run_times : 47.64\n",
      "[2022-12-08 11:11:32] 1068281035.py[  95] : INFO  2-46 | lr : 0.000075 | val_loss : 1.5273 | val_roc_auc : 0.8029 | data_load_times : 47.66 | batch_run_times : 48.22\n",
      "[2022-12-08 11:12:12] 1068281035.py[  95] : INFO  2-47 | lr : 0.000073 | val_loss : 1.6011 | val_roc_auc : 0.7986 | data_load_times : 46.79 | batch_run_times : 47.35\n",
      "[2022-12-08 11:12:51] 1068281035.py[  95] : INFO  2-48 | lr : 0.000072 | val_loss : 1.6189 | val_roc_auc : 0.7584 | data_load_times : 48.38 | batch_run_times : 48.97\n",
      "[2022-12-08 11:13:32] 1068281035.py[  95] : INFO  2-49 | lr : 0.000070 | val_loss : 1.5472 | val_roc_auc : 0.7994 | data_load_times : 50.34 | batch_run_times : 50.92\n",
      "Epoch 00050: early stopping triggered.\n",
      "[2022-12-08 11:13:32] 3687493274.py[ 133] : INFO  Best scores: [1.3270795345306396, 1.5369290113449097, 1.3641525506973267]\n",
      "[2022-12-08 11:13:32] 3687493274.py[ 134] : INFO  Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialise hyperparameters\n",
    "hparams = init_hparams()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "log_notes = \"t_mult increased to 6 from 5\"\n",
    "\n",
    "# Initialise logger\n",
    "logger = init_logger(hparams.log_name, hparams.log_dir)\n",
    "\n",
    "# Log parameters\n",
    "logger.info(f\"backbone: {hparams.backbone}\")\n",
    "logger.info(f\"device_name: {hparams.device_name}\")\n",
    "logger.info(f\"gpus: {hparams.gpus}\")\n",
    "logger.info(f\"n_workers: {hparams.n_workers}\")\n",
    "logger.info(f\"image_size: {hparams.image_size}\")\n",
    "logger.info(f\"seed: {hparams.seed}\")\n",
    "logger.info(f\"min_epochs: {hparams.min_epochs}\")\n",
    "logger.info(f\"max_epochs: {hparams.max_epochs}\")\n",
    "logger.info(f\"patience: {hparams.patience}\")\n",
    "logger.info(f\"train_batch_size: {hparams.train_batch_size}\")\n",
    "logger.info(f\"val_batch_size: {hparams.val_batch_size}\")\n",
    "logger.info(f\"n_splits: {hparams.n_splits}\")\n",
    "logger.info(f\"test_size: {hparams.test_size}\")\n",
    "logger.info(f\"learning rate: {hparams.lr}\")\n",
    "logger.info(f\"weight_decay: {hparams.weight_decay}\")\n",
    "logger.info(f\"epsilon: {hparams.epsilon}\")\n",
    "logger.info(f\"amsgrad: {hparams.amsgrad}\")\n",
    "logger.info(f\"betas: {hparams.betas}\")\n",
    "logger.info(f\"precision: {hparams.precision}\")\n",
    "logger.info(f\"gradient_clip_val: {hparams.gradient_clip_val}\")\n",
    "logger.info(f\"eta_min: {hparams.eta_min}\")\n",
    "logger.info(f\"t_max: {hparams.t_max}\")\n",
    "logger.info(f\"t_mult: {hparams.t_mult}\")\n",
    "logger.info(f\"log_dir: {hparams.log_dir}\")\n",
    "logger.info(f\"log_name: {hparams.log_name}\")\n",
    "\n",
    "# Log any notes if they exist\n",
    "if \"log_notes\" in locals():\n",
    "    logger.info(f\"Notes: {log_notes}\")\n",
    "\n",
    "\n",
    "# Create transform pipeline\n",
    "transforms = generate_transforms(hparams.image_size)\n",
    "\n",
    "# List for validation scores \n",
    "val_loss_scores = []\n",
    "\n",
    "# Initialise cross validation\n",
    "folds = StratifiedKFold(n_splits=hparams.n_splits, shuffle=True, random_state=hparams.seed)\n",
    "\n",
    "# Start cross validation\n",
    "for fold_i, (train_index, val_index) in enumerate(folds.split(metadata[[\"img_path\"]], metadata[[\"label\"]])):\n",
    "    hparams.fold_i = fold_i\n",
    "    # Split train images and validation sets\n",
    "    train_data = metadata.iloc[train_index][[\"img_path\", \"label\"]].reset_index(drop=True)\n",
    "    train_data = pd.get_dummies(train_data, columns=[\"label\"], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "    val_data = metadata.iloc[val_index][[\"img_path\", \"label\"]].reset_index(drop=True)\n",
    "    val_data = pd.get_dummies(val_data, columns=[\"label\"], prefix=\"\", prefix_sep=\"\")\n",
    "    \n",
    "    logger.info(f\"Fold {fold_i} num train records: {train_data.shape[0]}\")\n",
    "    logger.info(f\"Fold {fold_i} num val records: {val_data.shape[0]}\")\n",
    "    \n",
    "    train_dataloader, val_dataloader = generate_dataloaders(hparams, train_data, val_data, transforms)\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        save_top_k=2,\n",
    "        mode=\"min\",\n",
    "        filepath=os.path.join(\n",
    "            hparams.log_dir, \n",
    "            hparams.log_name, \n",
    "            f\"fold={fold_i}\" + \"-{epoch}-{val_loss:.4f}-{val_roc_auc:.4f}\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\", \n",
    "        patience=hparams.patience, \n",
    "        mode=\"min\", \n",
    "        verbose=hparams.verbose\n",
    "    )\n",
    "    \n",
    "    # Instance Model, Trainer and train model\n",
    "    model = CoolSystem(hparams)\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=hparams.gpus,\n",
    "        min_epochs=hparams.min_epochs,\n",
    "        max_epochs=hparams.max_epochs,\n",
    "        early_stop_callback=early_stop_callback,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        progress_bar_refresh_rate=0,\n",
    "        precision=hparams.precision,\n",
    "        num_sanity_val_steps=0,\n",
    "        profiler=False,\n",
    "        weights_summary=None,\n",
    "        gradient_clip_val=hparams.gradient_clip_val,\n",
    "        default_root_dir=os.path.join(hparams.log_dir, hparams.log_name)\n",
    "    )\n",
    "    \n",
    "    # Fit model\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "            \n",
    "    # Save val scores\n",
    "    val_loss_scores.append(checkpoint_callback.best)\n",
    "    \n",
    "    # Cleanup\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "val_loss_scores = [i.item() for i in val_loss_scores]\n",
    "\n",
    "# Add val scores to csv with all scores\n",
    "if os.path.isfile(\"../logs/scores.csv\") == False:\n",
    "    pd.DataFrame(columns=[\"name\", \"scores\", \"mean_score\"]).to_csv(\"../logs/scores.csv\", index=False)\n",
    "    \n",
    "# Append to current scores csv\n",
    "all_scores_df = pd.concat([\n",
    "    pd.read_csv(\"../logs/scores.csv\"),\n",
    "    pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"name\": [hparams.log_name],\n",
    "            \"scores\": [val_loss_scores],\n",
    "            \"mean_score\": [np.mean(val_loss_scores)]\n",
    "        }\n",
    "    )],\n",
    "    ignore_index=True\n",
    ")\n",
    "# Write all scores df to csv\n",
    "all_scores_df.to_csv(\"../logs/scores.csv\", index=False)\n",
    "\n",
    "logger.info(f\"Best scores: {val_loss_scores}\")\n",
    "logger.info(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aee771",
   "metadata": {},
   "source": [
    "## Validation Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7feb0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [07:22,  4.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get model run path and define chosen fold\n",
    "log_dir = \"../logs/logs\"\n",
    "#model_run = \"2022_11_08_14:57:52\" # manually choose model path\n",
    "model_run = hparams.log_name\n",
    "model_run_path = os.path.join(log_dir, model_run)\n",
    "#best_fold = 1 # manually choose model path\n",
    "best_fold = val_loss_scores.index(min(val_loss_scores))\n",
    "\n",
    "# Get best model for chosen fold\n",
    "model_run_dir = os.listdir(model_run_path)\n",
    "model_folds = [i for i in model_run_dir if i.startswith(f\"fold={best_fold}\")]\n",
    "model_folds_scores = [float(i.split(\"val_loss=\")[1].split(\"-\")[0]) for i in model_folds]\n",
    "model_name = model_folds[model_folds_scores.index(min(model_folds_scores))]\n",
    "model_path = os.path.join(model_run_path, model_name)\n",
    "\n",
    "# Load fold's model\n",
    "model = CoolSystem(hparams)\n",
    "model.load_state_dict(\n",
    "    torch.load(model_path)[\"state_dict\"]\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# Retrieve validation indices for chosen fold\n",
    "for fold_i, (train_index, val_index) in enumerate(folds.split(metadata[[\"img_path\"]], metadata[[\"label\"]])):\n",
    "    if fold_i == best_fold:\n",
    "        break\n",
    "\n",
    "# Select fold validation images\n",
    "X_val = torch.from_numpy(X_train[val_index]).permute(0, 3, 1, 2).float()\n",
    "\n",
    "# Create predictions looped by batch\n",
    "counter = 0\n",
    "val_i_batch = []\n",
    "val_idx_batch = []\n",
    "scores_df = pd.DataFrame()\n",
    "\n",
    "for i, idx in tqdm(enumerate(val_index)):\n",
    "    counter += 1\n",
    "    val_i_batch.append(i) # arrays don't preserve index so need ordered index values\n",
    "    val_idx_batch.append(idx) # for preserved index\n",
    "    \n",
    "    # Run inference for val_batch_size\n",
    "    if counter == hparams.val_batch_size:\n",
    "        preds = model(X_val[val_i_batch])\n",
    "        \n",
    "        # Create activation output\n",
    "        log_softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        # Convert raw output to probabilities\n",
    "        preds = np.exp(log_softmax(preds).detach().numpy())\n",
    "\n",
    "        # Create df with img paths and predicted label probs\n",
    "        scores_df_batch = pd.DataFrame(preds, columns=val_data.columns[1:])\n",
    "        scores_df_batch = pd.merge(\n",
    "            metadata.iloc[val_idx_batch, 1:3].reset_index(drop=True),\n",
    "            scores_df_batch, \n",
    "            left_index=True,\n",
    "            right_index=True\n",
    "        )\n",
    "        scores_df = pd.concat([scores_df, scores_df_batch], ignore_index=True, axis=0)\n",
    "\n",
    "        # Cleanup\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # Reset counter and batch\n",
    "        counter = 0\n",
    "        val_i_batch = []\n",
    "        val_idx_batch = []\n",
    "        \n",
    "    # Run inference for remaining batch\n",
    "    elif idx == val_index[-1]:\n",
    "        preds = model(X_val[val_i_batch])\n",
    "        \n",
    "        # Create activation output\n",
    "        log_softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        # Convert raw output to probabilities\n",
    "        preds = np.exp(log_softmax(preds).detach().numpy())\n",
    "\n",
    "        # Create df with img paths and predicted label probs\n",
    "        scores_df_batch = pd.DataFrame(preds, columns=val_data.columns[1:])\n",
    "        scores_df_batch = pd.merge(\n",
    "            metadata.iloc[val_idx_batch, 1:3].reset_index(drop=True),\n",
    "            scores_df_batch, \n",
    "            left_index=True,\n",
    "            right_index=True\n",
    "        )\n",
    "        scores_df = pd.concat([scores_df, scores_df_batch], ignore_index=True, axis=0)\n",
    "\n",
    "        # Cleanup\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "# Write predictions to log\n",
    "scores_df.to_csv(\n",
    "    os.path.join(model_run_path, f\"{model_run}_preds_fold_{best_fold}.csv\"),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fc3edc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>ant</th>\n",
       "      <th>bedbug</th>\n",
       "      <th>bee</th>\n",
       "      <th>horsefly</th>\n",
       "      <th>mite</th>\n",
       "      <th>mosquito</th>\n",
       "      <th>none</th>\n",
       "      <th>tick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/cleaned/none/7059b14d2aa03ed6c4de11afa...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.124998</td>\n",
       "      <td>0.127505</td>\n",
       "      <td>0.138024</td>\n",
       "      <td>0.129489</td>\n",
       "      <td>0.149257</td>\n",
       "      <td>0.112448</td>\n",
       "      <td>0.096403</td>\n",
       "      <td>0.121876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/cleaned/none/ea1b100b581fcdb7ddfae52cc...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.119071</td>\n",
       "      <td>0.127625</td>\n",
       "      <td>0.141309</td>\n",
       "      <td>0.128924</td>\n",
       "      <td>0.150748</td>\n",
       "      <td>0.114408</td>\n",
       "      <td>0.098422</td>\n",
       "      <td>0.119494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/cleaned/none/6c68654ed15dc485d527dd85f...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.121919</td>\n",
       "      <td>0.118456</td>\n",
       "      <td>0.141615</td>\n",
       "      <td>0.136042</td>\n",
       "      <td>0.145989</td>\n",
       "      <td>0.117594</td>\n",
       "      <td>0.097614</td>\n",
       "      <td>0.120771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/cleaned/none/f64f47a69e72ce97b3ae2b07e...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.123417</td>\n",
       "      <td>0.127582</td>\n",
       "      <td>0.138511</td>\n",
       "      <td>0.128951</td>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.108925</td>\n",
       "      <td>0.097903</td>\n",
       "      <td>0.118715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/cleaned/none/b8f71c61c19392c3cb24ebc54...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.122788</td>\n",
       "      <td>0.129511</td>\n",
       "      <td>0.139414</td>\n",
       "      <td>0.127349</td>\n",
       "      <td>0.153652</td>\n",
       "      <td>0.111325</td>\n",
       "      <td>0.097411</td>\n",
       "      <td>0.118549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>../data/cleaned/ant/9a0a79963955f8ac3e6de74750...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.123945</td>\n",
       "      <td>0.127328</td>\n",
       "      <td>0.136644</td>\n",
       "      <td>0.129611</td>\n",
       "      <td>0.151594</td>\n",
       "      <td>0.113221</td>\n",
       "      <td>0.096889</td>\n",
       "      <td>0.120767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>../data/cleaned/ant/f54a2ecb91d8d3d0935d518d81...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.119437</td>\n",
       "      <td>0.126298</td>\n",
       "      <td>0.142780</td>\n",
       "      <td>0.130300</td>\n",
       "      <td>0.153670</td>\n",
       "      <td>0.113144</td>\n",
       "      <td>0.095956</td>\n",
       "      <td>0.118415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>../data/cleaned/ant/06443ff82c28fd0d52f62868d8...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.124024</td>\n",
       "      <td>0.123984</td>\n",
       "      <td>0.137007</td>\n",
       "      <td>0.133916</td>\n",
       "      <td>0.151467</td>\n",
       "      <td>0.113509</td>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.119291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>../data/cleaned/ant/ea946cc42f2daadb6eca6aac12...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.125333</td>\n",
       "      <td>0.127760</td>\n",
       "      <td>0.138207</td>\n",
       "      <td>0.128275</td>\n",
       "      <td>0.149787</td>\n",
       "      <td>0.113549</td>\n",
       "      <td>0.096532</td>\n",
       "      <td>0.120557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>../data/cleaned/ant/db1d2481cc394bac5182bfcc0c...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.126503</td>\n",
       "      <td>0.127464</td>\n",
       "      <td>0.136579</td>\n",
       "      <td>0.130044</td>\n",
       "      <td>0.151916</td>\n",
       "      <td>0.109533</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.121862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             img_path label       ant  \\\n",
       "0   ../data/cleaned/none/7059b14d2aa03ed6c4de11afa...  none  0.124998   \n",
       "1   ../data/cleaned/none/ea1b100b581fcdb7ddfae52cc...  none  0.119071   \n",
       "2   ../data/cleaned/none/6c68654ed15dc485d527dd85f...  none  0.121919   \n",
       "3   ../data/cleaned/none/f64f47a69e72ce97b3ae2b07e...  none  0.123417   \n",
       "4   ../data/cleaned/none/b8f71c61c19392c3cb24ebc54...  none  0.122788   \n",
       "..                                                ...   ...       ...   \n",
       "95  ../data/cleaned/ant/9a0a79963955f8ac3e6de74750...   ant  0.123945   \n",
       "96  ../data/cleaned/ant/f54a2ecb91d8d3d0935d518d81...   ant  0.119437   \n",
       "97  ../data/cleaned/ant/06443ff82c28fd0d52f62868d8...   ant  0.124024   \n",
       "98  ../data/cleaned/ant/ea946cc42f2daadb6eca6aac12...   ant  0.125333   \n",
       "99  ../data/cleaned/ant/db1d2481cc394bac5182bfcc0c...   ant  0.126503   \n",
       "\n",
       "      bedbug       bee  horsefly      mite  mosquito      none      tick  \n",
       "0   0.127505  0.138024  0.129489  0.149257  0.112448  0.096403  0.121876  \n",
       "1   0.127625  0.141309  0.128924  0.150748  0.114408  0.098422  0.119494  \n",
       "2   0.118456  0.141615  0.136042  0.145989  0.117594  0.097614  0.120771  \n",
       "3   0.127582  0.138511  0.128951  0.155995  0.108925  0.097903  0.118715  \n",
       "4   0.129511  0.139414  0.127349  0.153652  0.111325  0.097411  0.118549  \n",
       "..       ...       ...       ...       ...       ...       ...       ...  \n",
       "95  0.127328  0.136644  0.129611  0.151594  0.113221  0.096889  0.120767  \n",
       "96  0.126298  0.142780  0.130300  0.153670  0.113144  0.095956  0.118415  \n",
       "97  0.123984  0.137007  0.133916  0.151467  0.113509  0.096801  0.119291  \n",
       "98  0.127760  0.138207  0.128275  0.149787  0.113549  0.096532  0.120557  \n",
       "99  0.127464  0.136579  0.130044  0.151916  0.109533  0.096100  0.121862  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a910bef3",
   "metadata": {},
   "source": [
    "## Validation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b4293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 unique image paths.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(scores_df['img_path'].unique())} unique image paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6565caec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation label counts:\n",
      "bedbug      20\n",
      "tick        19\n",
      "mosquito    15\n",
      "ant         15\n",
      "none         9\n",
      "horsefly     8\n",
      "mite         7\n",
      "bee          7\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation label counts:\")\n",
    "print(scores_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f8676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction counts:\n",
      "mite    100\n",
      "Name: pred_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation prediction counts:\")\n",
    "print(\n",
    "    pd.melt(\n",
    "        scores_df,\n",
    "        id_vars=[\"img_path\", \"label\"],\n",
    "        value_vars=[\"ant\", \"bedbug\", \"bee\", \"horsefly\", \"mite\", \"mosquito\" ,\"none\", \"tick\"],\n",
    "        var_name=\"pred_label\",\n",
    "        value_name=\"pred_prob\"\n",
    "    ).sort_values([\"img_path\", \"pred_prob\"], ascending=False) \\\n",
    "    .groupby([\"img_path\", \"label\"]).first()[\"pred_label\"] \\\n",
    "    .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24bf48d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>0.25</th>\n",
       "      <th>median</th>\n",
       "      <th>0.75</th>\n",
       "      <th>max</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ant</th>\n",
       "      <td>0.123860</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.118318</td>\n",
       "      <td>0.122737</td>\n",
       "      <td>0.124608</td>\n",
       "      <td>0.125526</td>\n",
       "      <td>0.127672</td>\n",
       "      <td>0.009354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedbug</th>\n",
       "      <td>0.125951</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.118164</td>\n",
       "      <td>0.124688</td>\n",
       "      <td>0.126599</td>\n",
       "      <td>0.127593</td>\n",
       "      <td>0.130038</td>\n",
       "      <td>0.011874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bee</th>\n",
       "      <td>0.138538</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.134231</td>\n",
       "      <td>0.137313</td>\n",
       "      <td>0.138415</td>\n",
       "      <td>0.139370</td>\n",
       "      <td>0.143347</td>\n",
       "      <td>0.009117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsefly</th>\n",
       "      <td>0.131333</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.126209</td>\n",
       "      <td>0.129120</td>\n",
       "      <td>0.130857</td>\n",
       "      <td>0.132999</td>\n",
       "      <td>0.140255</td>\n",
       "      <td>0.014046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mite</th>\n",
       "      <td>0.151062</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.145761</td>\n",
       "      <td>0.149355</td>\n",
       "      <td>0.151096</td>\n",
       "      <td>0.152340</td>\n",
       "      <td>0.159071</td>\n",
       "      <td>0.013310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mosquito</th>\n",
       "      <td>0.112704</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.106808</td>\n",
       "      <td>0.111812</td>\n",
       "      <td>0.112896</td>\n",
       "      <td>0.114012</td>\n",
       "      <td>0.117594</td>\n",
       "      <td>0.010786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>0.096256</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.093781</td>\n",
       "      <td>0.095727</td>\n",
       "      <td>0.096318</td>\n",
       "      <td>0.096773</td>\n",
       "      <td>0.098422</td>\n",
       "      <td>0.004641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tick</th>\n",
       "      <td>0.120296</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.116227</td>\n",
       "      <td>0.119460</td>\n",
       "      <td>0.120503</td>\n",
       "      <td>0.121232</td>\n",
       "      <td>0.124697</td>\n",
       "      <td>0.008471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean       std       min      0.25    median      0.75  \\\n",
       "ant       0.123860  0.002391  0.118318  0.122737  0.124608  0.125526   \n",
       "bedbug    0.125951  0.002448  0.118164  0.124688  0.126599  0.127593   \n",
       "bee       0.138538  0.002170  0.134231  0.137313  0.138415  0.139370   \n",
       "horsefly  0.131333  0.003211  0.126209  0.129120  0.130857  0.132999   \n",
       "mite      0.151062  0.002139  0.145761  0.149355  0.151096  0.152340   \n",
       "mosquito  0.112704  0.001977  0.106808  0.111812  0.112896  0.114012   \n",
       "none      0.096256  0.000840  0.093781  0.095727  0.096318  0.096773   \n",
       "tick      0.120296  0.001496  0.116227  0.119460  0.120503  0.121232   \n",
       "\n",
       "               max     range  \n",
       "ant       0.127672  0.009354  \n",
       "bedbug    0.130038  0.011874  \n",
       "bee       0.143347  0.009117  \n",
       "horsefly  0.140255  0.014046  \n",
       "mite      0.159071  0.013310  \n",
       "mosquito  0.117594  0.010786  \n",
       "none      0.098422  0.004641  \n",
       "tick      0.124697  0.008471  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability stats by label\n",
    "pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].mean(), columns=[\"mean\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].std(), columns=[\"std\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].min(), columns=[\"min\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].quantile(0.25)),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].median(), columns=[\"median\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].quantile(0.75)),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].max(), columns=[\"max\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].max() - scores_df.iloc[:, 2:].min(), columns=[\"range\"])\n",
    "    ], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92d47fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">pred_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_label</th>\n",
       "      <th>ant</th>\n",
       "      <th>bedbug</th>\n",
       "      <th>bee</th>\n",
       "      <th>horsefly</th>\n",
       "      <th>mite</th>\n",
       "      <th>mosquito</th>\n",
       "      <th>none</th>\n",
       "      <th>tick</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ant</th>\n",
       "      <td>0.124070</td>\n",
       "      <td>0.126414</td>\n",
       "      <td>0.138031</td>\n",
       "      <td>0.130843</td>\n",
       "      <td>0.151572</td>\n",
       "      <td>0.112613</td>\n",
       "      <td>0.096374</td>\n",
       "      <td>0.120082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedbug</th>\n",
       "      <td>0.124016</td>\n",
       "      <td>0.125785</td>\n",
       "      <td>0.138380</td>\n",
       "      <td>0.132091</td>\n",
       "      <td>0.151048</td>\n",
       "      <td>0.112173</td>\n",
       "      <td>0.096038</td>\n",
       "      <td>0.120469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bee</th>\n",
       "      <td>0.124523</td>\n",
       "      <td>0.123855</td>\n",
       "      <td>0.136868</td>\n",
       "      <td>0.134502</td>\n",
       "      <td>0.152375</td>\n",
       "      <td>0.110869</td>\n",
       "      <td>0.096499</td>\n",
       "      <td>0.120508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsefly</th>\n",
       "      <td>0.123396</td>\n",
       "      <td>0.126054</td>\n",
       "      <td>0.138131</td>\n",
       "      <td>0.132124</td>\n",
       "      <td>0.152386</td>\n",
       "      <td>0.111753</td>\n",
       "      <td>0.096002</td>\n",
       "      <td>0.120154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mite</th>\n",
       "      <td>0.123323</td>\n",
       "      <td>0.126742</td>\n",
       "      <td>0.139457</td>\n",
       "      <td>0.129705</td>\n",
       "      <td>0.151186</td>\n",
       "      <td>0.113194</td>\n",
       "      <td>0.095808</td>\n",
       "      <td>0.120584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mosquito</th>\n",
       "      <td>0.124443</td>\n",
       "      <td>0.125687</td>\n",
       "      <td>0.138198</td>\n",
       "      <td>0.131477</td>\n",
       "      <td>0.150204</td>\n",
       "      <td>0.113323</td>\n",
       "      <td>0.096373</td>\n",
       "      <td>0.120294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>0.122469</td>\n",
       "      <td>0.126829</td>\n",
       "      <td>0.139818</td>\n",
       "      <td>0.129824</td>\n",
       "      <td>0.151054</td>\n",
       "      <td>0.113040</td>\n",
       "      <td>0.096936</td>\n",
       "      <td>0.120029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tick</th>\n",
       "      <td>0.123876</td>\n",
       "      <td>0.125990</td>\n",
       "      <td>0.139215</td>\n",
       "      <td>0.130623</td>\n",
       "      <td>0.150268</td>\n",
       "      <td>0.113584</td>\n",
       "      <td>0.096159</td>\n",
       "      <td>0.120286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred_prob                                                    \\\n",
       "pred_label       ant    bedbug       bee  horsefly      mite  mosquito   \n",
       "label                                                                    \n",
       "ant         0.124070  0.126414  0.138031  0.130843  0.151572  0.112613   \n",
       "bedbug      0.124016  0.125785  0.138380  0.132091  0.151048  0.112173   \n",
       "bee         0.124523  0.123855  0.136868  0.134502  0.152375  0.110869   \n",
       "horsefly    0.123396  0.126054  0.138131  0.132124  0.152386  0.111753   \n",
       "mite        0.123323  0.126742  0.139457  0.129705  0.151186  0.113194   \n",
       "mosquito    0.124443  0.125687  0.138198  0.131477  0.150204  0.113323   \n",
       "none        0.122469  0.126829  0.139818  0.129824  0.151054  0.113040   \n",
       "tick        0.123876  0.125990  0.139215  0.130623  0.150268  0.113584   \n",
       "\n",
       "                                \n",
       "pred_label      none      tick  \n",
       "label                           \n",
       "ant         0.096374  0.120082  \n",
       "bedbug      0.096038  0.120469  \n",
       "bee         0.096499  0.120508  \n",
       "horsefly    0.096002  0.120154  \n",
       "mite        0.095808  0.120584  \n",
       "mosquito    0.096373  0.120294  \n",
       "none        0.096936  0.120029  \n",
       "tick        0.096159  0.120286  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.melt(\n",
    "    scores_df,\n",
    "    id_vars=[\"img_path\", \"label\"],\n",
    "    value_vars=[\"ant\", \"bedbug\", \"bee\", \"horsefly\", \"mite\", \"mosquito\" ,\"none\", \"tick\"],\n",
    "    var_name=\"pred_label\",\n",
    "    value_name=\"pred_prob\"\n",
    ").pivot_table(\n",
    "    index=[\"label\"],\n",
    "    columns=[\"pred_label\"],\n",
    "    aggfunc=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "980e4931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/0161d75756b770ac6fd28e6b5a3156a201ae179a.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>mite</td>\n",
       "      <td>0.151958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/06443ff82c28fd0d52f62868d8995e8e70107d7a.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>mite</td>\n",
       "      <td>0.151467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/1018442462dbb9419f327b652ff28a0c55a2710d.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>mite</td>\n",
       "      <td>0.154454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/11ad398be6c87a2a6fca4de0b332022f12521cb8.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>mite</td>\n",
       "      <td>0.148712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/477e86816e544bcf371c470b65c887567f8fd186.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>mite</td>\n",
       "      <td>0.150962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/b4f637d0ccc21bb6631b77c6bfe1f8fff2e8cf06.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>mite</td>\n",
       "      <td>0.148771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/c6d142ee77529c16153491fecb202e2edd8cefec.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>mite</td>\n",
       "      <td>0.148703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/d3eb4c5c6aa879b6a460910d461b9a22690105af.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>mite</td>\n",
       "      <td>0.149769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/da47cb31b81340f6ed5e46dbadb295f8543234a3.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>mite</td>\n",
       "      <td>0.148802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/e2839d39fc114a853ca88d64c0a75d4d29f67a8a.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>mite</td>\n",
       "      <td>0.151672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         pred_label  pred_prob\n",
       "img_path                                           label                      \n",
       "../data/cleaned/ant/0161d75756b770ac6fd28e6b5a3... ant         mite   0.151958\n",
       "../data/cleaned/ant/06443ff82c28fd0d52f62868d89... ant         mite   0.151467\n",
       "../data/cleaned/ant/1018442462dbb9419f327b652ff... ant         mite   0.154454\n",
       "../data/cleaned/ant/11ad398be6c87a2a6fca4de0b33... ant         mite   0.148712\n",
       "../data/cleaned/ant/477e86816e544bcf371c470b65c... ant         mite   0.150962\n",
       "...                                                             ...        ...\n",
       "../data/cleaned/tick/b4f637d0ccc21bb6631b77c6bf... tick        mite   0.148771\n",
       "../data/cleaned/tick/c6d142ee77529c16153491fecb... tick        mite   0.148703\n",
       "../data/cleaned/tick/d3eb4c5c6aa879b6a460910d46... tick        mite   0.149769\n",
       "../data/cleaned/tick/da47cb31b81340f6ed5e46dbad... tick        mite   0.148802\n",
       "../data/cleaned/tick/e2839d39fc114a853ca88d64c0... tick        mite   0.151672\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.melt(\n",
    "    scores_df,\n",
    "    id_vars=[\"img_path\", \"label\"],\n",
    "    value_vars=[\"ant\", \"bedbug\", \"bee\", \"horsefly\", \"mite\", \"mosquito\" ,\"none\", \"tick\"],\n",
    "    var_name=\"pred_label\",\n",
    "    value_name=\"pred_prob\"\n",
    ").sort_values([\"img_path\", \"pred_prob\"], ascending=False).groupby([\"img_path\", \"label\"]).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249a0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613be570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88807ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biteme",
   "language": "python",
   "name": "biteme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
