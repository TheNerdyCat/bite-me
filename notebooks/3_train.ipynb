{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef0d2692",
   "metadata": {},
   "source": [
    "# BiteMe | Train\n",
    "\n",
    "This notebook includes the most important part of the project - the modelling. The notebook tests methodologies for training, and in it the chosen algorithm is decided. Validation also occurs before final testing, which is conducted in the test notebook. This stage is highly iterative, so all model artefacts, logs and configurations are recorded and saved to disk automatically. This initial setup of what will eventually become MLOps for the final product will be really useful, and helps keep track of what is successful and what isn't.\n",
    "\n",
    "Models to try:\n",
    "\n",
    "~~[SE-ResNet50](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[SE-ResNet101](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[SE-ResNet152](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[SENet154](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[ResNet34](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[ResNet50](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[ResNet101](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[ResNet152](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    " - [FBResNet152](https://github.com/Cadene/pretrained-models.pytorch#facebook-resnet)\n",
    " - [VGG16](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [VGG19](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [VGG16_BN](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [VGG19_BN](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [PolyNet](https://github.com/Cadene/pretrained-models.pytorch#polynet)\n",
    " - [InceptionResNetV2](https://github.com/Cadene/pretrained-models.pytorch#inception)\n",
    " - [InceptionV4](https://github.com/Cadene/pretrained-models.pytorch#inception)\n",
    " - [Xception](https://github.com/Cadene/pretrained-models.pytorch#xception)\n",
    " - [ResNeXt101_32x4d](https://github.com/Cadene/pretrained-models.pytorch#resnext)\n",
    " - [ResNeXt101_64x4d](https://github.com/Cadene/pretrained-models.pytorch#resnext)\n",
    " - [SE-ResNeXt50_32x4d](https://github.com/Cadene/pretrained-models.pytorch#senet)\n",
    " - [SE-ResNeXt101_32x4d](https://github.com/Cadene/pretrained-models.pytorch#senet)\n",
    " - [DenseNet121](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet161](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet169](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet201](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DualPathNet68](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet92](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet98](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet107](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet131](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [NASNet-A-Large](https://github.com/Cadene/pretrained-models.pytorch#nasnet)\n",
    " - [PNASNet-5-Large](https://github.com/Cadene/pretrained-models.pytorch#pnasnet)\n",
    "\n",
    "\n",
    " - efficientnet_b0\n",
    " - efficientnet_b1\n",
    " - efficientnet_b2\n",
    " - efficientnet_b3\n",
    " - efficientnet_b4\n",
    " - efficientnet_b5\n",
    "\n",
    "Initial model work is done by using simple, typical image recognition models (CNN architectures) to see how effective these models can be for the problem. Although I don't expect them to be particularly successful, it's important to establish baselines and take a holistic approach to modelling when it's possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be8b5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from argparse import ArgumentParser\n",
    "import datetime\n",
    "from time import time\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "import torch\n",
    "import pretrainedmodels\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Local imports\n",
    "sys.path.append(\"..\")\n",
    "from utils.dataset import generate_transforms, generate_dataloaders\n",
    "from models.models import *\n",
    "from utils.loss_function import CrossEntropyLossOneHot\n",
    "from utils.lrs_scheduler import WarmRestart, warm_restart\n",
    "from utils.utils import read_images, augs, get_augs, seed_reproducer, init_logger\n",
    "from utils.constants import *\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a79a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7059b14d2aa03ed6c4de11afa32591995181d31c.jpg</td>\n",
       "      <td>../data/cleaned/none/7059b14d2aa03ed6c4de11afa...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea1b100b581fcdb7ddfae52cc62347a99e304ba4.jpg</td>\n",
       "      <td>../data/cleaned/none/ea1b100b581fcdb7ddfae52cc...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6eac051b9c45ff6821ec8675216f371711b7cea9.jpg</td>\n",
       "      <td>../data/cleaned/none/6eac051b9c45ff6821ec86752...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fc72767f8520df9b2b83941077dc0ee013eb9399.jpg</td>\n",
       "      <td>../data/cleaned/none/fc72767f8520df9b2b8394107...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49850884a00703afe5aab78c3ce074d2d4acae30.jpg</td>\n",
       "      <td>../data/cleaned/none/49850884a00703afe5aab78c3...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       img_name  \\\n",
       "0  7059b14d2aa03ed6c4de11afa32591995181d31c.jpg   \n",
       "1  ea1b100b581fcdb7ddfae52cc62347a99e304ba4.jpg   \n",
       "2  6eac051b9c45ff6821ec8675216f371711b7cea9.jpg   \n",
       "3  fc72767f8520df9b2b83941077dc0ee013eb9399.jpg   \n",
       "4  49850884a00703afe5aab78c3ce074d2d4acae30.jpg   \n",
       "\n",
       "                                            img_path label  split  \n",
       "0  ../data/cleaned/none/7059b14d2aa03ed6c4de11afa...  none  train  \n",
       "1  ../data/cleaned/none/ea1b100b581fcdb7ddfae52cc...  none  train  \n",
       "2  ../data/cleaned/none/6eac051b9c45ff6821ec86752...  none  train  \n",
       "3  ../data/cleaned/none/fc72767f8520df9b2b8394107...  none  train  \n",
       "4  ../data/cleaned/none/49850884a00703afe5aab78c3...  none  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define directories\n",
    "base_dir_path = \"../\"\n",
    "\n",
    "data_dir_path = os.path.join(base_dir_path, \"data\")\n",
    "data_preprocessed_dir_path = os.path.join(data_dir_path, \"preprocessed\")\n",
    "data_preprocessed_train_dir_path = os.path.join(data_dir_path, \"preprocessed/train\")\n",
    "\n",
    "data_dir = os.listdir(data_dir_path)\n",
    "data_preprocessed_dir = os.listdir(data_preprocessed_dir_path)\n",
    "data_preprocessed_train_dir = os.listdir(data_preprocessed_train_dir_path)\n",
    "\n",
    "metadata_preprocessed_path = os.path.join(data_preprocessed_dir_path, \"metadata.csv\")\n",
    "metadata = pd.read_csv(metadata_preprocessed_path)\n",
    "# Subset to train only\n",
    "metadata = metadata.loc[metadata.split == \"train\"]\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4dde582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from: ../data/preprocessed/train\n",
      "Rows set to 1024\n",
      "Columns set to 1024\n",
      "Channels set to 3\n",
      "Writing images is set to: False\n",
      "Reading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 48.97it/s]\n",
      "100%|███████████████████████████████████████████| 55/55 [00:02<00:00, 21.32it/s]\n",
      "100%|███████████████████████████████████████████| 21/21 [00:01<00:00, 13.84it/s]\n",
      "100%|███████████████████████████████████████████| 46/46 [00:04<00:00, 10.69it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:02<00:00,  8.49it/s]\n",
      "100%|███████████████████████████████████████████| 21/21 [00:02<00:00,  7.53it/s]\n",
      "100%|███████████████████████████████████████████| 58/58 [00:09<00:00,  6.35it/s]\n",
      "100%|███████████████████████████████████████████| 46/46 [00:08<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image reading complete.\n",
      "Image array shape: (299, 1024, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read in train images\n",
    "X_train = read_images(\n",
    "    data_dir_path=data_preprocessed_train_dir_path, \n",
    "    rows=ROWS, \n",
    "    cols=COLS, \n",
    "    channels=CHANNELS, \n",
    "    write_images=False, \n",
    "    output_data_dir_path=None,\n",
    "    verbose=VERBOSE\n",
    ")\n",
    "\n",
    "# Get labels\n",
    "y_train = np.array(pd.get_dummies(metadata[\"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9eb1b2",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac202af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose augmentations to use in preprocessing\n",
    "# For full list see helpers.py\n",
    "#augs_to_select = [\n",
    "#    \"Resize\",\n",
    "#    \"HorizontalFlip\", \n",
    "#    \"VerticalFlip\",\n",
    "#    \"Normalize\"\n",
    "#]\n",
    "## Subset augs based on those selected\n",
    "#AUGS = dict((aug_name, augs[aug_name]) for aug_name in augs_to_select)\n",
    "\n",
    "\n",
    "def init_hparams():\n",
    "    \"\"\"\n",
    "    Initialise hyperparameters for modelling.\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    hparams : argparse.Namespace\n",
    "        Parsed hyperparameters\n",
    "    \"\"\"\n",
    "    parser = ArgumentParser(add_help=False)\n",
    "    parser.add_argument(\"-backbone\", \"--backbone\", type=str, default=MODEL_NAME)\n",
    "    parser.add_argument(\"-device_name\", type=str, default=DEVICE_NAME)\n",
    "    parser.add_argument(\"--gpus\", default=[0])\n",
    "    parser.add_argument(\"--n_workers\", type=int, default=N_WORKERS)\n",
    "    parser.add_argument(\"--image_size\", nargs=\"+\", default=[ROWS, COLS])\n",
    "    parser.add_argument(\"--seed\", type=int, default=SEED)\n",
    "    parser.add_argument(\"--min_epochs\", type=int, default=MIN_EPOCHS)\n",
    "    parser.add_argument(\"--max_epochs\", type=int, default=MAX_EPOCHS)\n",
    "    parser.add_argument(\"--patience\", type=str, default=PATIENCE)    \n",
    "    parser.add_argument(\"-tbs\", \"--train_batch_size\", type=int, default=TRAIN_BATCH_SIZE)\n",
    "    parser.add_argument(\"-vbs\", \"--val_batch_size\", type=int, default=VAL_BATCH_SIZE)\n",
    "    parser.add_argument(\"--n_splits\", type=int, default=N_SPLITS)\n",
    "    parser.add_argument(\"--test_size\", type=float, default=TEST_SIZE)\n",
    "    parser.add_argument(\"--precision\", type=int, default=PRECISION)\n",
    "    parser.add_argument(\"--gradient_clip_val\", type=float, default=GRADIENT_CLIP_VAL)\n",
    "    parser.add_argument(\"--verbose\", type=str, default=VERBOSE)\n",
    "    parser.add_argument(\"--log_dir\", type=str, default=LOG_DIR)\n",
    "    parser.add_argument(\"--log_name\", type=str, default=LOG_NAME)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        hparams, unknown = parser.parse_known_args()\n",
    "    except:\n",
    "        hparams, unknown = parser.parse_args([])\n",
    "\n",
    "    if len(hparams.gpus) == 1:\n",
    "        hparams.gpus = [int(hparams.gpus[0])]\n",
    "    else:\n",
    "        hparams.gpus = [int(gpu) for gpu in hparams.gpus]\n",
    "\n",
    "    hparams.image_size = [int(size) for size in hparams.image_size]\n",
    "    \n",
    "    return hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca739edd",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b5b9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoolSystem(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "\n",
    "        seed_reproducer(self.hparams.seed)\n",
    "\n",
    "        self.model = fbresnet152()\n",
    "        self.criterion = CrossEntropyLossOneHot()\n",
    "        self.logger_kun = init_logger(\n",
    "            hparams.log_name, \n",
    "            hparams.log_dir\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0\n",
    "        )\n",
    "        self.scheduler = WarmRestart(self.optimizer, T_max=10, T_mult=3, eta_min=1e-5)\n",
    "        return [self.optimizer], [self.scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        step_start_time = time()\n",
    "        images, labels, data_load_time = batch\n",
    "\n",
    "        scores = self(images)\n",
    "        loss = self.criterion(scores, labels)\n",
    "\n",
    "        data_load_time = torch.sum(data_load_time)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"data_load_time\": data_load_time,\n",
    "            \"batch_run_time\": torch.Tensor([time() - step_start_time + data_load_time]).to(\n",
    "                data_load_time.device\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        # outputs is the return of training_step\n",
    "        train_loss_mean = torch.stack([output[\"loss\"] for output in outputs]).mean()\n",
    "        self.data_load_times = torch.stack([output[\"data_load_time\"] for output in outputs]).sum()\n",
    "        self.batch_run_times = torch.stack([output[\"batch_run_time\"] for output in outputs]).sum()\n",
    "\n",
    "        self.current_epoch += 1\n",
    "        if self.current_epoch < (self.trainer.max_epochs - 4):\n",
    "            self.scheduler = warm_restart(self.scheduler, T_mult=2)\n",
    "\n",
    "        return {\"train_loss\": train_loss_mean}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        step_start_time = time()\n",
    "        images, labels, data_load_time = batch\n",
    "        data_load_time = torch.sum(data_load_time)\n",
    "        scores = self(images)\n",
    "        loss = self.criterion(scores, labels)\n",
    "\n",
    "        # must return key -> val_loss\n",
    "        return {\n",
    "            \"val_loss\": loss,\n",
    "            \"scores\": scores,\n",
    "            \"labels\": labels,\n",
    "            \"data_load_time\": data_load_time,\n",
    "            \"batch_run_time\": torch.Tensor([time() - step_start_time + data_load_time]).to(\n",
    "                data_load_time.device\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # compute loss\n",
    "        val_loss_mean = torch.stack([output[\"val_loss\"] for output in outputs]).mean()\n",
    "        self.data_load_times = torch.stack([output[\"data_load_time\"] for output in outputs]).sum()\n",
    "        self.batch_run_times = torch.stack([output[\"batch_run_time\"] for output in outputs]).sum()\n",
    "\n",
    "        # compute roc_auc\n",
    "        scores_all = torch.cat([output[\"scores\"] for output in outputs]).cpu()\n",
    "        labels_all = torch.round(torch.cat([output[\"labels\"] for output in outputs]).cpu())\n",
    "\n",
    "        val_roc_auc = torch.tensor(roc_auc_score(labels_all, scores_all))\n",
    "\n",
    "        # terminal logs\n",
    "        self.logger_kun.info(\n",
    "            f\"{self.hparams.fold_i}-{self.current_epoch} | \"\n",
    "            f\"lr : {self.scheduler.get_lr()[0]:.6f} | \"\n",
    "            f\"val_loss : {val_loss_mean:.4f} | \"\n",
    "            f\"val_roc_auc : {val_roc_auc:.4f} | \"\n",
    "            f\"data_load_times : {self.data_load_times:.2f} | \"\n",
    "            f\"batch_run_times : {self.batch_run_times:.2f}\"\n",
    "        )\n",
    "\n",
    "        return {\"val_loss\": val_loss_mean, \"val_roc_auc\": val_roc_auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd3fde",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c68f6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-23 20:26:37] 4182638920.py[  11] : INFO  backbone: fbresnet152\n",
      "[2022-11-23 20:26:37] 4182638920.py[  12] : INFO  device_name: NVIDIA GeForce RTX 3090\n",
      "[2022-11-23 20:26:37] 4182638920.py[  13] : INFO  gpus: [0]\n",
      "[2022-11-23 20:26:37] 4182638920.py[  14] : INFO  n_workers: 128\n",
      "[2022-11-23 20:26:37] 4182638920.py[  15] : INFO  image_size: [1024, 1024]\n",
      "[2022-11-23 20:26:37] 4182638920.py[  16] : INFO  seed: 14\n",
      "[2022-11-23 20:26:37] 4182638920.py[  17] : INFO  min_epochs: 30\n",
      "[2022-11-23 20:26:37] 4182638920.py[  18] : INFO  max_epochs: 50\n",
      "[2022-11-23 20:26:37] 4182638920.py[  19] : INFO  patience: 11\n",
      "[2022-11-23 20:26:37] 4182638920.py[  20] : INFO  train_batch_size: 4\n",
      "[2022-11-23 20:26:37] 4182638920.py[  21] : INFO  val_batch_size: 4\n",
      "[2022-11-23 20:26:37] 4182638920.py[  22] : INFO  n_splits: 3\n",
      "[2022-11-23 20:26:37] 4182638920.py[  23] : INFO  test_size: 0.1\n",
      "[2022-11-23 20:26:37] 4182638920.py[  24] : INFO  precision: 16\n",
      "[2022-11-23 20:26:37] 4182638920.py[  25] : INFO  gradient_clip_val: 0.5\n",
      "[2022-11-23 20:26:37] 4182638920.py[  26] : INFO  log_dir: ../logs/logs\n",
      "[2022-11-23 20:26:37] 4182638920.py[  27] : INFO  log_name: 2022_11_23_20:26:03\n",
      "[2022-11-23 20:26:37] 4182638920.py[  31] : INFO  Notes: decreased gradient_clip_val to 0.5\n",
      "[2022-11-23 20:26:37] 4182638920.py[  53] : INFO  Fold 0 num train records: 199\n",
      "[2022-11-23 20:26:37] 4182638920.py[  54] : INFO  Fold 0 num val records: 100\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "[2022-11-23 20:27:25] 3799136884.py[  85] : INFO  0-0 | lr : 0.000100 | val_loss : 2.0506 | val_roc_auc : 0.7065 | data_load_times : 47.08 | batch_run_times : 48.12\n",
      "[2022-11-23 20:28:09] 3799136884.py[  85] : INFO  0-1 | lr : 0.000098 | val_loss : 2.0045 | val_roc_auc : 0.7257 | data_load_times : 45.17 | batch_run_times : 46.20\n",
      "[2022-11-23 20:28:53] 3799136884.py[  85] : INFO  0-2 | lr : 0.000091 | val_loss : 1.9600 | val_roc_auc : 0.7399 | data_load_times : 46.78 | batch_run_times : 47.81\n",
      "[2022-11-23 20:29:39] 3799136884.py[  85] : INFO  0-3 | lr : 0.000081 | val_loss : 1.9107 | val_roc_auc : 0.7886 | data_load_times : 44.73 | batch_run_times : 45.75\n",
      "[2022-11-23 20:30:23] 3799136884.py[  85] : INFO  0-4 | lr : 0.000069 | val_loss : 1.8635 | val_roc_auc : 0.7943 | data_load_times : 45.06 | batch_run_times : 46.09\n",
      "[2022-11-23 20:31:08] 3799136884.py[  85] : INFO  0-5 | lr : 0.000055 | val_loss : 1.8977 | val_roc_auc : 0.7560 | data_load_times : 46.28 | batch_run_times : 47.32\n",
      "[2022-11-23 20:31:52] 3799136884.py[  85] : INFO  0-6 | lr : 0.000041 | val_loss : 1.8174 | val_roc_auc : 0.8120 | data_load_times : 46.20 | batch_run_times : 47.43\n",
      "[2022-11-23 20:32:37] 3799136884.py[  85] : INFO  0-7 | lr : 0.000029 | val_loss : 1.7912 | val_roc_auc : 0.8330 | data_load_times : 45.14 | batch_run_times : 46.21\n",
      "[2022-11-23 20:33:21] 3799136884.py[  85] : INFO  0-8 | lr : 0.000019 | val_loss : 1.7914 | val_roc_auc : 0.8173 | data_load_times : 46.23 | batch_run_times : 47.25\n",
      "[2022-11-23 20:34:06] 3799136884.py[  85] : INFO  0-9 | lr : 0.000012 | val_loss : 1.7719 | val_roc_auc : 0.8146 | data_load_times : 46.65 | batch_run_times : 47.76\n",
      "[2022-11-23 20:34:50] 3799136884.py[  85] : INFO  0-10 | lr : 0.000100 | val_loss : 1.8520 | val_roc_auc : 0.7719 | data_load_times : 45.87 | batch_run_times : 46.90\n",
      "[2022-11-23 20:35:34] 3799136884.py[  85] : INFO  0-11 | lr : 0.000100 | val_loss : 1.8615 | val_roc_auc : 0.7486 | data_load_times : 46.07 | batch_run_times : 47.09\n",
      "[2022-11-23 20:36:18] 3799136884.py[  85] : INFO  0-12 | lr : 0.000099 | val_loss : 1.8251 | val_roc_auc : 0.7523 | data_load_times : 47.68 | batch_run_times : 48.72\n",
      "[2022-11-23 20:37:02] 3799136884.py[  85] : INFO  0-13 | lr : 0.000098 | val_loss : 1.7341 | val_roc_auc : 0.8123 | data_load_times : 45.89 | batch_run_times : 46.91\n",
      "[2022-11-23 20:37:46] 3799136884.py[  85] : INFO  0-14 | lr : 0.000096 | val_loss : 1.7254 | val_roc_auc : 0.7978 | data_load_times : 46.06 | batch_run_times : 47.08\n",
      "[2022-11-23 20:38:31] 3799136884.py[  85] : INFO  0-15 | lr : 0.000094 | val_loss : 1.7117 | val_roc_auc : 0.8163 | data_load_times : 44.49 | batch_run_times : 45.50\n",
      "[2022-11-23 20:39:17] 3799136884.py[  85] : INFO  0-16 | lr : 0.000091 | val_loss : 1.7232 | val_roc_auc : 0.7905 | data_load_times : 49.05 | batch_run_times : 50.08\n",
      "[2022-11-23 20:40:02] 3799136884.py[  85] : INFO  0-17 | lr : 0.000088 | val_loss : 1.6723 | val_roc_auc : 0.7989 | data_load_times : 45.28 | batch_run_times : 46.30\n",
      "[2022-11-23 20:40:47] 3799136884.py[  85] : INFO  0-18 | lr : 0.000085 | val_loss : 1.6641 | val_roc_auc : 0.8179 | data_load_times : 46.09 | batch_run_times : 47.13\n",
      "[2022-11-23 20:41:32] 3799136884.py[  85] : INFO  0-19 | lr : 0.000081 | val_loss : 1.6872 | val_roc_auc : 0.7691 | data_load_times : 45.26 | batch_run_times : 46.28\n",
      "[2022-11-23 20:42:16] 3799136884.py[  85] : INFO  0-20 | lr : 0.000077 | val_loss : 1.6439 | val_roc_auc : 0.8171 | data_load_times : 45.98 | batch_run_times : 47.06\n",
      "[2022-11-23 20:43:01] 3799136884.py[  85] : INFO  0-21 | lr : 0.000073 | val_loss : 1.6045 | val_roc_auc : 0.8084 | data_load_times : 44.30 | batch_run_times : 45.34\n",
      "[2022-11-23 20:43:46] 3799136884.py[  85] : INFO  0-22 | lr : 0.000069 | val_loss : 1.6864 | val_roc_auc : 0.7638 | data_load_times : 45.66 | batch_run_times : 46.69\n",
      "[2022-11-23 20:44:31] 3799136884.py[  85] : INFO  0-23 | lr : 0.000064 | val_loss : 1.6218 | val_roc_auc : 0.7933 | data_load_times : 45.06 | batch_run_times : 46.07\n",
      "[2022-11-23 20:45:15] 3799136884.py[  85] : INFO  0-24 | lr : 0.000060 | val_loss : 1.6282 | val_roc_auc : 0.8062 | data_load_times : 45.85 | batch_run_times : 47.14\n",
      "[2022-11-23 20:45:59] 3799136884.py[  85] : INFO  0-25 | lr : 0.000055 | val_loss : 1.5498 | val_roc_auc : 0.8274 | data_load_times : 47.08 | batch_run_times : 48.10\n",
      "[2022-11-23 20:46:45] 3799136884.py[  85] : INFO  0-26 | lr : 0.000050 | val_loss : 1.5958 | val_roc_auc : 0.8066 | data_load_times : 44.98 | batch_run_times : 46.13\n",
      "[2022-11-23 20:47:30] 3799136884.py[  85] : INFO  0-27 | lr : 0.000046 | val_loss : 1.6015 | val_roc_auc : 0.7955 | data_load_times : 45.95 | batch_run_times : 46.98\n",
      "[2022-11-23 20:48:14] 3799136884.py[  85] : INFO  0-28 | lr : 0.000041 | val_loss : 1.5756 | val_roc_auc : 0.8127 | data_load_times : 44.35 | batch_run_times : 45.49\n",
      "[2022-11-23 20:48:58] 3799136884.py[  85] : INFO  0-29 | lr : 0.000037 | val_loss : 1.5661 | val_roc_auc : 0.8145 | data_load_times : 44.99 | batch_run_times : 46.02\n",
      "[2022-11-23 20:49:43] 3799136884.py[  85] : INFO  0-30 | lr : 0.000033 | val_loss : 1.5640 | val_roc_auc : 0.8178 | data_load_times : 46.27 | batch_run_times : 47.33\n",
      "[2022-11-23 20:50:29] 3799136884.py[  85] : INFO  0-31 | lr : 0.000029 | val_loss : 1.5391 | val_roc_auc : 0.8185 | data_load_times : 45.21 | batch_run_times : 46.25\n",
      "[2022-11-23 20:51:13] 3799136884.py[  85] : INFO  0-32 | lr : 0.000025 | val_loss : 1.5135 | val_roc_auc : 0.8345 | data_load_times : 45.86 | batch_run_times : 46.88\n",
      "[2022-11-23 20:51:58] 3799136884.py[  85] : INFO  0-33 | lr : 0.000022 | val_loss : 1.5272 | val_roc_auc : 0.8128 | data_load_times : 47.13 | batch_run_times : 48.30\n",
      "[2022-11-23 20:52:43] 3799136884.py[  85] : INFO  0-34 | lr : 0.000019 | val_loss : 1.5134 | val_roc_auc : 0.8228 | data_load_times : 45.12 | batch_run_times : 46.14\n",
      "[2022-11-23 20:53:27] 3799136884.py[  85] : INFO  0-35 | lr : 0.000016 | val_loss : 1.5055 | val_roc_auc : 0.8214 | data_load_times : 47.42 | batch_run_times : 48.45\n",
      "[2022-11-23 20:54:12] 3799136884.py[  85] : INFO  0-36 | lr : 0.000014 | val_loss : 1.4631 | val_roc_auc : 0.8332 | data_load_times : 46.40 | batch_run_times : 47.46\n",
      "[2022-11-23 20:54:56] 3799136884.py[  85] : INFO  0-37 | lr : 0.000012 | val_loss : 1.4890 | val_roc_auc : 0.8228 | data_load_times : 46.03 | batch_run_times : 47.06\n",
      "[2022-11-23 20:55:40] 3799136884.py[  85] : INFO  0-38 | lr : 0.000011 | val_loss : 1.4670 | val_roc_auc : 0.8275 | data_load_times : 46.67 | batch_run_times : 47.77\n",
      "[2022-11-23 20:56:26] 3799136884.py[  85] : INFO  0-39 | lr : 0.000010 | val_loss : 1.4707 | val_roc_auc : 0.8240 | data_load_times : 46.72 | batch_run_times : 47.74\n",
      "[2022-11-23 20:57:10] 3799136884.py[  85] : INFO  0-40 | lr : 0.000100 | val_loss : 1.4999 | val_roc_auc : 0.8211 | data_load_times : 43.63 | batch_run_times : 44.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-23 20:57:55] 3799136884.py[  85] : INFO  0-41 | lr : 0.000100 | val_loss : 1.5059 | val_roc_auc : 0.8258 | data_load_times : 45.29 | batch_run_times : 46.31\n",
      "[2022-11-23 20:58:40] 3799136884.py[  85] : INFO  0-42 | lr : 0.000100 | val_loss : 1.5270 | val_roc_auc : 0.8221 | data_load_times : 44.61 | batch_run_times : 45.63\n",
      "[2022-11-23 20:59:24] 3799136884.py[  85] : INFO  0-43 | lr : 0.000100 | val_loss : 1.4758 | val_roc_auc : 0.8131 | data_load_times : 44.97 | batch_run_times : 45.99\n",
      "[2022-11-23 21:00:08] 3799136884.py[  85] : INFO  0-44 | lr : 0.000100 | val_loss : 1.5434 | val_roc_auc : 0.8004 | data_load_times : 44.31 | batch_run_times : 45.34\n",
      "[2022-11-23 21:00:52] 3799136884.py[  85] : INFO  0-45 | lr : 0.000099 | val_loss : 1.5737 | val_roc_auc : 0.7936 | data_load_times : 45.37 | batch_run_times : 46.39\n",
      "[2022-11-23 21:01:36] 3799136884.py[  85] : INFO  0-46 | lr : 0.000099 | val_loss : 1.6066 | val_roc_auc : 0.7523 | data_load_times : 46.73 | batch_run_times : 47.76\n",
      "[2022-11-23 21:02:19] 3799136884.py[  85] : INFO  0-47 | lr : 0.000099 | val_loss : 1.5934 | val_roc_auc : 0.7845 | data_load_times : 46.02 | batch_run_times : 47.04\n",
      "Epoch 00048: early stopping triggered.\n",
      "[2022-11-23 21:02:20] 4182638920.py[  53] : INFO  Fold 1 num train records: 199\n",
      "[2022-11-23 21:02:20] 4182638920.py[  54] : INFO  Fold 1 num val records: 100\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "[2022-11-23 21:03:08] 3799136884.py[  85] : INFO  1-0 | lr : 0.000100 | val_loss : 2.0576 | val_roc_auc : 0.6906 | data_load_times : 44.47 | batch_run_times : 45.49\n",
      "[2022-11-23 21:03:56] 3799136884.py[  85] : INFO  1-1 | lr : 0.000098 | val_loss : 2.0083 | val_roc_auc : 0.7661 | data_load_times : 45.08 | batch_run_times : 46.20\n",
      "[2022-11-23 21:04:44] 3799136884.py[  85] : INFO  1-2 | lr : 0.000091 | val_loss : 1.9917 | val_roc_auc : 0.7699 | data_load_times : 45.54 | batch_run_times : 46.58\n",
      "[2022-11-23 21:05:33] 3799136884.py[  85] : INFO  1-3 | lr : 0.000081 | val_loss : 1.9315 | val_roc_auc : 0.7935 | data_load_times : 46.22 | batch_run_times : 47.25\n",
      "[2022-11-23 21:06:21] 3799136884.py[  85] : INFO  1-4 | lr : 0.000069 | val_loss : 1.8511 | val_roc_auc : 0.8392 | data_load_times : 45.87 | batch_run_times : 46.89\n",
      "[2022-11-23 21:07:08] 3799136884.py[  85] : INFO  1-5 | lr : 0.000055 | val_loss : 1.8374 | val_roc_auc : 0.8507 | data_load_times : 46.59 | batch_run_times : 47.69\n",
      "[2022-11-23 21:07:55] 3799136884.py[  85] : INFO  1-6 | lr : 0.000041 | val_loss : 1.8020 | val_roc_auc : 0.8569 | data_load_times : 44.22 | batch_run_times : 45.23\n",
      "[2022-11-23 21:08:44] 3799136884.py[  85] : INFO  1-7 | lr : 0.000029 | val_loss : 1.8080 | val_roc_auc : 0.8354 | data_load_times : 47.10 | batch_run_times : 48.12\n",
      "[2022-11-23 21:09:32] 3799136884.py[  85] : INFO  1-8 | lr : 0.000019 | val_loss : 1.7936 | val_roc_auc : 0.8434 | data_load_times : 46.13 | batch_run_times : 47.18\n",
      "[2022-11-23 21:10:19] 3799136884.py[  85] : INFO  1-9 | lr : 0.000012 | val_loss : 1.7663 | val_roc_auc : 0.8577 | data_load_times : 46.55 | batch_run_times : 47.56\n",
      "[2022-11-23 21:11:07] 3799136884.py[  85] : INFO  1-10 | lr : 0.000100 | val_loss : 1.7876 | val_roc_auc : 0.8226 | data_load_times : 46.53 | batch_run_times : 47.56\n",
      "[2022-11-23 21:11:54] 3799136884.py[  85] : INFO  1-11 | lr : 0.000100 | val_loss : 1.8651 | val_roc_auc : 0.7786 | data_load_times : 47.33 | batch_run_times : 48.60\n",
      "[2022-11-23 21:12:40] 3799136884.py[  85] : INFO  1-12 | lr : 0.000099 | val_loss : 1.7671 | val_roc_auc : 0.8169 | data_load_times : 45.62 | batch_run_times : 46.66\n",
      "[2022-11-23 21:13:27] 3799136884.py[  85] : INFO  1-13 | lr : 0.000098 | val_loss : 1.7601 | val_roc_auc : 0.8246 | data_load_times : 47.16 | batch_run_times : 48.18\n",
      "[2022-11-23 21:14:14] 3799136884.py[  85] : INFO  1-14 | lr : 0.000096 | val_loss : 1.6932 | val_roc_auc : 0.8596 | data_load_times : 46.22 | batch_run_times : 47.26\n",
      "[2022-11-23 21:15:02] 3799136884.py[  85] : INFO  1-15 | lr : 0.000094 | val_loss : 1.7099 | val_roc_auc : 0.8162 | data_load_times : 44.68 | batch_run_times : 45.70\n",
      "[2022-11-23 21:15:50] 3799136884.py[  85] : INFO  1-16 | lr : 0.000091 | val_loss : 1.7121 | val_roc_auc : 0.8234 | data_load_times : 47.83 | batch_run_times : 48.85\n",
      "[2022-11-23 21:16:37] 3799136884.py[  85] : INFO  1-17 | lr : 0.000088 | val_loss : 1.6443 | val_roc_auc : 0.8380 | data_load_times : 47.11 | batch_run_times : 48.13\n",
      "[2022-11-23 21:17:24] 3799136884.py[  85] : INFO  1-18 | lr : 0.000085 | val_loss : 1.6611 | val_roc_auc : 0.8247 | data_load_times : 48.12 | batch_run_times : 49.16\n",
      "[2022-11-23 21:18:11] 3799136884.py[  85] : INFO  1-19 | lr : 0.000081 | val_loss : 1.6493 | val_roc_auc : 0.8184 | data_load_times : 47.17 | batch_run_times : 48.19\n",
      "[2022-11-23 21:18:59] 3799136884.py[  85] : INFO  1-20 | lr : 0.000077 | val_loss : 1.6366 | val_roc_auc : 0.8401 | data_load_times : 46.53 | batch_run_times : 47.55\n",
      "[2022-11-23 21:19:46] 3799136884.py[  85] : INFO  1-21 | lr : 0.000073 | val_loss : 1.5721 | val_roc_auc : 0.8509 | data_load_times : 45.02 | batch_run_times : 46.07\n",
      "[2022-11-23 21:20:35] 3799136884.py[  85] : INFO  1-22 | lr : 0.000069 | val_loss : 1.5955 | val_roc_auc : 0.8420 | data_load_times : 47.41 | batch_run_times : 48.44\n",
      "[2022-11-23 21:21:23] 3799136884.py[  85] : INFO  1-23 | lr : 0.000064 | val_loss : 1.5968 | val_roc_auc : 0.8220 | data_load_times : 48.11 | batch_run_times : 49.14\n",
      "[2022-11-23 21:22:10] 3799136884.py[  85] : INFO  1-24 | lr : 0.000060 | val_loss : 1.5516 | val_roc_auc : 0.8535 | data_load_times : 44.97 | batch_run_times : 45.99\n",
      "[2022-11-23 21:22:57] 3799136884.py[  85] : INFO  1-25 | lr : 0.000055 | val_loss : 1.5398 | val_roc_auc : 0.8391 | data_load_times : 49.28 | batch_run_times : 50.48\n",
      "[2022-11-23 21:23:45] 3799136884.py[  85] : INFO  1-26 | lr : 0.000050 | val_loss : 1.5531 | val_roc_auc : 0.8346 | data_load_times : 46.27 | batch_run_times : 47.29\n",
      "[2022-11-23 21:24:31] 3799136884.py[  85] : INFO  1-27 | lr : 0.000046 | val_loss : 1.5931 | val_roc_auc : 0.8292 | data_load_times : 46.72 | batch_run_times : 47.76\n",
      "[2022-11-23 21:25:18] 3799136884.py[  85] : INFO  1-28 | lr : 0.000041 | val_loss : 1.5009 | val_roc_auc : 0.8457 | data_load_times : 47.65 | batch_run_times : 48.67\n",
      "[2022-11-23 21:26:05] 3799136884.py[  85] : INFO  1-29 | lr : 0.000037 | val_loss : 1.4989 | val_roc_auc : 0.8595 | data_load_times : 48.66 | batch_run_times : 49.70\n",
      "[2022-11-23 21:26:53] 3799136884.py[  85] : INFO  1-30 | lr : 0.000033 | val_loss : 1.4796 | val_roc_auc : 0.8553 | data_load_times : 44.25 | batch_run_times : 45.27\n",
      "[2022-11-23 21:27:42] 3799136884.py[  85] : INFO  1-31 | lr : 0.000029 | val_loss : 1.4711 | val_roc_auc : 0.8580 | data_load_times : 47.09 | batch_run_times : 48.12\n",
      "[2022-11-23 21:28:30] 3799136884.py[  85] : INFO  1-32 | lr : 0.000025 | val_loss : 1.5241 | val_roc_auc : 0.8324 | data_load_times : 46.89 | batch_run_times : 47.94\n",
      "[2022-11-23 21:29:17] 3799136884.py[  85] : INFO  1-33 | lr : 0.000022 | val_loss : 1.4533 | val_roc_auc : 0.8428 | data_load_times : 47.23 | batch_run_times : 48.25\n",
      "[2022-11-23 21:30:04] 3799136884.py[  85] : INFO  1-34 | lr : 0.000019 | val_loss : 1.4410 | val_roc_auc : 0.8529 | data_load_times : 46.47 | batch_run_times : 47.50\n",
      "[2022-11-23 21:30:52] 3799136884.py[  85] : INFO  1-35 | lr : 0.000016 | val_loss : 1.4622 | val_roc_auc : 0.8455 | data_load_times : 47.32 | batch_run_times : 48.34\n",
      "[2022-11-23 21:31:39] 3799136884.py[  85] : INFO  1-36 | lr : 0.000014 | val_loss : 1.4423 | val_roc_auc : 0.8472 | data_load_times : 46.24 | batch_run_times : 47.26\n",
      "[2022-11-23 21:32:26] 3799136884.py[  85] : INFO  1-37 | lr : 0.000012 | val_loss : 1.4695 | val_roc_auc : 0.8437 | data_load_times : 46.95 | batch_run_times : 47.97\n",
      "[2022-11-23 21:33:12] 3799136884.py[  85] : INFO  1-38 | lr : 0.000011 | val_loss : 1.4595 | val_roc_auc : 0.8447 | data_load_times : 46.85 | batch_run_times : 47.88\n",
      "[2022-11-23 21:34:00] 3799136884.py[  85] : INFO  1-39 | lr : 0.000010 | val_loss : 1.4293 | val_roc_auc : 0.8543 | data_load_times : 46.82 | batch_run_times : 48.15\n",
      "[2022-11-23 21:34:47] 3799136884.py[  85] : INFO  1-40 | lr : 0.000100 | val_loss : 1.5338 | val_roc_auc : 0.8364 | data_load_times : 45.53 | batch_run_times : 46.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-23 21:35:34] 3799136884.py[  85] : INFO  1-41 | lr : 0.000100 | val_loss : 1.5091 | val_roc_auc : 0.8175 | data_load_times : 47.26 | batch_run_times : 48.31\n",
      "[2022-11-23 21:36:21] 3799136884.py[  85] : INFO  1-42 | lr : 0.000100 | val_loss : 1.5073 | val_roc_auc : 0.8332 | data_load_times : 46.43 | batch_run_times : 47.46\n",
      "[2022-11-23 21:37:08] 3799136884.py[  85] : INFO  1-43 | lr : 0.000100 | val_loss : 1.5268 | val_roc_auc : 0.8435 | data_load_times : 45.29 | batch_run_times : 46.41\n",
      "[2022-11-23 21:37:55] 3799136884.py[  85] : INFO  1-44 | lr : 0.000100 | val_loss : 1.5416 | val_roc_auc : 0.8250 | data_load_times : 46.24 | batch_run_times : 47.27\n",
      "[2022-11-23 21:38:42] 3799136884.py[  85] : INFO  1-45 | lr : 0.000099 | val_loss : 1.4706 | val_roc_auc : 0.8397 | data_load_times : 46.12 | batch_run_times : 47.34\n",
      "[2022-11-23 21:39:29] 3799136884.py[  85] : INFO  1-46 | lr : 0.000099 | val_loss : 1.4706 | val_roc_auc : 0.8404 | data_load_times : 45.66 | batch_run_times : 46.71\n",
      "[2022-11-23 21:40:16] 3799136884.py[  85] : INFO  1-47 | lr : 0.000099 | val_loss : 1.5483 | val_roc_auc : 0.8181 | data_load_times : 47.52 | batch_run_times : 48.76\n",
      "[2022-11-23 21:41:03] 3799136884.py[  85] : INFO  1-48 | lr : 0.000098 | val_loss : 1.4934 | val_roc_auc : 0.8421 | data_load_times : 47.87 | batch_run_times : 48.96\n",
      "[2022-11-23 21:41:50] 3799136884.py[  85] : INFO  1-49 | lr : 0.000098 | val_loss : 1.4483 | val_roc_auc : 0.8413 | data_load_times : 48.32 | batch_run_times : 49.47\n",
      "[2022-11-23 21:41:51] 4182638920.py[  53] : INFO  Fold 2 num train records: 200\n",
      "[2022-11-23 21:41:51] 4182638920.py[  54] : INFO  Fold 2 num val records: 99\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "[2022-11-23 21:42:40] 3799136884.py[  85] : INFO  2-0 | lr : 0.000100 | val_loss : 2.0576 | val_roc_auc : 0.6126 | data_load_times : 44.07 | batch_run_times : 45.10\n",
      "[2022-11-23 21:43:27] 3799136884.py[  85] : INFO  2-1 | lr : 0.000098 | val_loss : 2.0299 | val_roc_auc : 0.6566 | data_load_times : 41.97 | batch_run_times : 42.98\n",
      "[2022-11-23 21:44:15] 3799136884.py[  85] : INFO  2-2 | lr : 0.000091 | val_loss : 2.0329 | val_roc_auc : 0.6319 | data_load_times : 44.55 | batch_run_times : 45.57\n",
      "[2022-11-23 21:45:03] 3799136884.py[  85] : INFO  2-3 | lr : 0.000081 | val_loss : 1.9443 | val_roc_auc : 0.7568 | data_load_times : 44.31 | batch_run_times : 45.32\n",
      "[2022-11-23 21:45:50] 3799136884.py[  85] : INFO  2-4 | lr : 0.000069 | val_loss : 1.9244 | val_roc_auc : 0.7474 | data_load_times : 44.68 | batch_run_times : 45.70\n",
      "[2022-11-23 21:46:38] 3799136884.py[  85] : INFO  2-5 | lr : 0.000055 | val_loss : 1.8801 | val_roc_auc : 0.7902 | data_load_times : 46.68 | batch_run_times : 47.71\n",
      "[2022-11-23 21:47:26] 3799136884.py[  85] : INFO  2-6 | lr : 0.000041 | val_loss : 1.8867 | val_roc_auc : 0.7822 | data_load_times : 44.64 | batch_run_times : 45.65\n",
      "[2022-11-23 21:48:15] 3799136884.py[  85] : INFO  2-7 | lr : 0.000029 | val_loss : 1.8389 | val_roc_auc : 0.8079 | data_load_times : 45.46 | batch_run_times : 46.51\n",
      "[2022-11-23 21:49:03] 3799136884.py[  85] : INFO  2-8 | lr : 0.000019 | val_loss : 1.8310 | val_roc_auc : 0.8118 | data_load_times : 44.59 | batch_run_times : 45.62\n",
      "[2022-11-23 21:49:50] 3799136884.py[  85] : INFO  2-9 | lr : 0.000012 | val_loss : 1.8177 | val_roc_auc : 0.8187 | data_load_times : 44.96 | batch_run_times : 45.97\n",
      "[2022-11-23 21:50:39] 3799136884.py[  85] : INFO  2-10 | lr : 0.000100 | val_loss : 1.8500 | val_roc_auc : 0.7920 | data_load_times : 44.58 | batch_run_times : 45.66\n",
      "[2022-11-23 21:51:26] 3799136884.py[  85] : INFO  2-11 | lr : 0.000100 | val_loss : 1.8314 | val_roc_auc : 0.7829 | data_load_times : 46.16 | batch_run_times : 47.17\n",
      "[2022-11-23 21:52:14] 3799136884.py[  85] : INFO  2-12 | lr : 0.000099 | val_loss : 1.8398 | val_roc_auc : 0.7778 | data_load_times : 44.28 | batch_run_times : 45.56\n",
      "[2022-11-23 21:53:02] 3799136884.py[  85] : INFO  2-13 | lr : 0.000098 | val_loss : 1.8286 | val_roc_auc : 0.7483 | data_load_times : 48.89 | batch_run_times : 49.97\n",
      "[2022-11-23 21:53:50] 3799136884.py[  85] : INFO  2-14 | lr : 0.000096 | val_loss : 1.7539 | val_roc_auc : 0.7929 | data_load_times : 44.22 | batch_run_times : 45.24\n",
      "[2022-11-23 21:54:39] 3799136884.py[  85] : INFO  2-15 | lr : 0.000094 | val_loss : 1.7560 | val_roc_auc : 0.7951 | data_load_times : 44.68 | batch_run_times : 45.70\n",
      "[2022-11-23 21:55:28] 3799136884.py[  85] : INFO  2-16 | lr : 0.000091 | val_loss : 1.7093 | val_roc_auc : 0.8135 | data_load_times : 45.76 | batch_run_times : 46.78\n",
      "[2022-11-23 21:56:17] 3799136884.py[  85] : INFO  2-17 | lr : 0.000088 | val_loss : 1.7552 | val_roc_auc : 0.7745 | data_load_times : 44.02 | batch_run_times : 45.03\n",
      "[2022-11-23 21:57:04] 3799136884.py[  85] : INFO  2-18 | lr : 0.000085 | val_loss : 1.6845 | val_roc_auc : 0.8121 | data_load_times : 44.39 | batch_run_times : 45.48\n",
      "[2022-11-23 21:57:52] 3799136884.py[  85] : INFO  2-19 | lr : 0.000081 | val_loss : 1.6412 | val_roc_auc : 0.8399 | data_load_times : 46.95 | batch_run_times : 47.96\n",
      "[2022-11-23 21:58:39] 3799136884.py[  85] : INFO  2-20 | lr : 0.000077 | val_loss : 1.6753 | val_roc_auc : 0.8034 | data_load_times : 43.40 | batch_run_times : 44.43\n",
      "[2022-11-23 21:59:28] 3799136884.py[  85] : INFO  2-21 | lr : 0.000073 | val_loss : 1.6638 | val_roc_auc : 0.8004 | data_load_times : 44.86 | batch_run_times : 45.87\n",
      "[2022-11-23 22:00:16] 3799136884.py[  85] : INFO  2-22 | lr : 0.000069 | val_loss : 1.6319 | val_roc_auc : 0.8403 | data_load_times : 45.77 | batch_run_times : 46.83\n",
      "[2022-11-23 22:01:04] 3799136884.py[  85] : INFO  2-23 | lr : 0.000064 | val_loss : 1.6698 | val_roc_auc : 0.8009 | data_load_times : 48.13 | batch_run_times : 49.15\n",
      "[2022-11-23 22:01:52] 3799136884.py[  85] : INFO  2-24 | lr : 0.000060 | val_loss : 1.6235 | val_roc_auc : 0.8341 | data_load_times : 45.35 | batch_run_times : 46.37\n",
      "[2022-11-23 22:02:41] 3799136884.py[  85] : INFO  2-25 | lr : 0.000055 | val_loss : 1.6139 | val_roc_auc : 0.8186 | data_load_times : 44.60 | batch_run_times : 45.61\n",
      "[2022-11-23 22:03:29] 3799136884.py[  85] : INFO  2-26 | lr : 0.000050 | val_loss : 1.6176 | val_roc_auc : 0.8039 | data_load_times : 44.56 | batch_run_times : 45.60\n",
      "[2022-11-23 22:04:17] 3799136884.py[  85] : INFO  2-27 | lr : 0.000046 | val_loss : 1.6267 | val_roc_auc : 0.8166 | data_load_times : 44.81 | batch_run_times : 45.91\n",
      "[2022-11-23 22:05:05] 3799136884.py[  85] : INFO  2-28 | lr : 0.000041 | val_loss : 1.5695 | val_roc_auc : 0.8327 | data_load_times : 43.60 | batch_run_times : 44.64\n",
      "[2022-11-23 22:05:53] 3799136884.py[  85] : INFO  2-29 | lr : 0.000037 | val_loss : 1.5598 | val_roc_auc : 0.8325 | data_load_times : 42.19 | batch_run_times : 43.19\n",
      "[2022-11-23 22:06:41] 3799136884.py[  85] : INFO  2-30 | lr : 0.000033 | val_loss : 1.5459 | val_roc_auc : 0.8325 | data_load_times : 44.17 | batch_run_times : 45.19\n",
      "[2022-11-23 22:07:28] 3799136884.py[  85] : INFO  2-31 | lr : 0.000029 | val_loss : 1.5384 | val_roc_auc : 0.8344 | data_load_times : 43.44 | batch_run_times : 44.46\n",
      "[2022-11-23 22:08:16] 3799136884.py[  85] : INFO  2-32 | lr : 0.000025 | val_loss : 1.5558 | val_roc_auc : 0.8374 | data_load_times : 45.80 | batch_run_times : 46.82\n",
      "[2022-11-23 22:09:03] 3799136884.py[  85] : INFO  2-33 | lr : 0.000022 | val_loss : 1.5047 | val_roc_auc : 0.8441 | data_load_times : 44.34 | batch_run_times : 45.37\n",
      "[2022-11-23 22:09:51] 3799136884.py[  85] : INFO  2-34 | lr : 0.000019 | val_loss : 1.4782 | val_roc_auc : 0.8508 | data_load_times : 43.48 | batch_run_times : 44.50\n",
      "[2022-11-23 22:10:38] 3799136884.py[  85] : INFO  2-35 | lr : 0.000016 | val_loss : 1.5226 | val_roc_auc : 0.8267 | data_load_times : 43.30 | batch_run_times : 44.31\n",
      "[2022-11-23 22:11:27] 3799136884.py[  85] : INFO  2-36 | lr : 0.000014 | val_loss : 1.5207 | val_roc_auc : 0.8390 | data_load_times : 45.10 | batch_run_times : 46.11\n",
      "[2022-11-23 22:12:14] 3799136884.py[  85] : INFO  2-37 | lr : 0.000012 | val_loss : 1.5324 | val_roc_auc : 0.8346 | data_load_times : 44.29 | batch_run_times : 45.30\n",
      "[2022-11-23 22:13:03] 3799136884.py[  85] : INFO  2-38 | lr : 0.000011 | val_loss : 1.5155 | val_roc_auc : 0.8376 | data_load_times : 44.19 | batch_run_times : 45.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-23 22:13:49] 3799136884.py[  85] : INFO  2-39 | lr : 0.000010 | val_loss : 1.5064 | val_roc_auc : 0.8420 | data_load_times : 44.51 | batch_run_times : 45.55\n",
      "[2022-11-23 22:14:38] 3799136884.py[  85] : INFO  2-40 | lr : 0.000100 | val_loss : 1.6312 | val_roc_auc : 0.7956 | data_load_times : 43.84 | batch_run_times : 45.02\n",
      "[2022-11-23 22:15:25] 3799136884.py[  85] : INFO  2-41 | lr : 0.000100 | val_loss : 1.5881 | val_roc_auc : 0.8015 | data_load_times : 46.26 | batch_run_times : 47.50\n",
      "[2022-11-23 22:16:12] 3799136884.py[  85] : INFO  2-42 | lr : 0.000100 | val_loss : 1.5916 | val_roc_auc : 0.7899 | data_load_times : 43.32 | batch_run_times : 44.33\n",
      "[2022-11-23 22:16:59] 3799136884.py[  85] : INFO  2-43 | lr : 0.000100 | val_loss : 1.5220 | val_roc_auc : 0.8134 | data_load_times : 46.29 | batch_run_times : 47.31\n",
      "[2022-11-23 22:17:46] 3799136884.py[  85] : INFO  2-44 | lr : 0.000100 | val_loss : 1.6204 | val_roc_auc : 0.8149 | data_load_times : 44.57 | batch_run_times : 45.66\n",
      "[2022-11-23 22:18:32] 3799136884.py[  85] : INFO  2-45 | lr : 0.000099 | val_loss : 1.5483 | val_roc_auc : 0.7966 | data_load_times : 43.53 | batch_run_times : 44.56\n",
      "Epoch 00046: early stopping triggered.\n",
      "[2022-11-23 22:18:33] 4182638920.py[ 125] : INFO  Best scores: [1.4631307125091553, 1.4292718172073364, 1.4782034158706665]\n",
      "[2022-11-23 22:18:33] 4182638920.py[ 126] : INFO  Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialise hyperparameters\n",
    "hparams = init_hparams()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "log_notes = \"decreased gradient_clip_val to 0.5\"\n",
    "\n",
    "# Initialise logger\n",
    "logger = init_logger(hparams.log_name, hparams.log_dir)\n",
    "\n",
    "# Log parameters\n",
    "logger.info(f\"backbone: {hparams.backbone}\")\n",
    "logger.info(f\"device_name: {hparams.device_name}\")\n",
    "logger.info(f\"gpus: {hparams.gpus}\")\n",
    "logger.info(f\"n_workers: {hparams.n_workers}\")\n",
    "logger.info(f\"image_size: {hparams.image_size}\")\n",
    "logger.info(f\"seed: {hparams.seed}\")\n",
    "logger.info(f\"min_epochs: {hparams.min_epochs}\")\n",
    "logger.info(f\"max_epochs: {hparams.max_epochs}\")\n",
    "logger.info(f\"patience: {hparams.patience}\")\n",
    "logger.info(f\"train_batch_size: {hparams.train_batch_size}\")\n",
    "logger.info(f\"val_batch_size: {hparams.val_batch_size}\")\n",
    "logger.info(f\"n_splits: {hparams.n_splits}\")\n",
    "logger.info(f\"test_size: {hparams.test_size}\")\n",
    "logger.info(f\"precision: {hparams.precision}\")\n",
    "logger.info(f\"gradient_clip_val: {hparams.gradient_clip_val}\")\n",
    "logger.info(f\"log_dir: {hparams.log_dir}\")\n",
    "logger.info(f\"log_name: {hparams.log_name}\")\n",
    "\n",
    "# Log any notes if they exist\n",
    "if \"log_notes\" in locals():\n",
    "    logger.info(f\"Notes: {log_notes}\")\n",
    "\n",
    "\n",
    "# Create transform pipeline\n",
    "transforms = generate_transforms(hparams.image_size)\n",
    "\n",
    "# List for validation scores \n",
    "val_loss_scores = []\n",
    "\n",
    "# Initialise cross validation\n",
    "folds = StratifiedKFold(n_splits=hparams.n_splits, shuffle=True, random_state=hparams.seed)\n",
    "\n",
    "# Start cross validation\n",
    "for fold_i, (train_index, val_index) in enumerate(folds.split(metadata[[\"img_path\"]], metadata[[\"label\"]])):\n",
    "    hparams.fold_i = fold_i\n",
    "    # Split train images and validation sets\n",
    "    train_data = metadata.iloc[train_index][[\"img_path\", \"label\"]].reset_index(drop=True)\n",
    "    train_data = pd.get_dummies(train_data, columns=[\"label\"], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "    val_data = metadata.iloc[val_index][[\"img_path\", \"label\"]].reset_index(drop=True)\n",
    "    val_data = pd.get_dummies(val_data, columns=[\"label\"], prefix=\"\", prefix_sep=\"\")\n",
    "    \n",
    "    logger.info(f\"Fold {fold_i} num train records: {train_data.shape[0]}\")\n",
    "    logger.info(f\"Fold {fold_i} num val records: {val_data.shape[0]}\")\n",
    "    \n",
    "    train_dataloader, val_dataloader = generate_dataloaders(hparams, train_data, val_data, transforms)\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        save_top_k=2,\n",
    "        mode=\"min\",\n",
    "        filepath=os.path.join(\n",
    "            hparams.log_dir, \n",
    "            hparams.log_name, \n",
    "            f\"fold={fold_i}\" + \"-{epoch}-{val_loss:.4f}-{val_roc_auc:.4f}\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\", \n",
    "        patience=hparams.patience, \n",
    "        mode=\"min\", \n",
    "        verbose=hparams.verbose\n",
    "    )\n",
    "    \n",
    "    # Instance Model, Trainer and train model\n",
    "    model = CoolSystem(hparams)\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=hparams.gpus,\n",
    "        min_epochs=hparams.min_epochs,\n",
    "        max_epochs=hparams.max_epochs,\n",
    "        early_stop_callback=early_stop_callback,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        progress_bar_refresh_rate=0,\n",
    "        precision=hparams.precision,\n",
    "        num_sanity_val_steps=0,\n",
    "        profiler=False,\n",
    "        weights_summary=None,\n",
    "        gradient_clip_val=hparams.gradient_clip_val,\n",
    "        default_root_dir=os.path.join(hparams.log_dir, hparams.log_name)\n",
    "    )\n",
    "    \n",
    "    # Fit model\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "            \n",
    "    # Save val scores\n",
    "    val_loss_scores.append(checkpoint_callback.best)\n",
    "    \n",
    "    # Cleanup\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "val_loss_scores = [i.item() for i in val_loss_scores]\n",
    "\n",
    "# Add val scores to csv with all scores\n",
    "if os.path.isfile(\"../logs/scores.csv\") == False:\n",
    "    pd.DataFrame(columns=[\"name\", \"scores\", \"mean_score\"]).to_csv(\"../logs/scores.csv\", index=False)\n",
    "    \n",
    "# Append to current scores csv\n",
    "all_scores_df = pd.concat([\n",
    "    pd.read_csv(\"../logs/scores.csv\"),\n",
    "    pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"name\": [hparams.log_name],\n",
    "            \"scores\": [val_loss_scores],\n",
    "            \"mean_score\": [np.mean(val_loss_scores)]\n",
    "        }\n",
    "    )],\n",
    "    ignore_index=True\n",
    ")\n",
    "# Write all scores df to csv\n",
    "all_scores_df.to_csv(\"../logs/scores.csv\", index=False)\n",
    "\n",
    "logger.info(f\"Best scores: {val_loss_scores}\")\n",
    "logger.info(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aee771",
   "metadata": {},
   "source": [
    "## Validation Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7feb0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [05:24,  3.25s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get model run path and define chosen fold\n",
    "log_dir = \"../logs/logs\"\n",
    "#model_run = \"2022_11_08_14:57:52\"\n",
    "model_run = hparams.log_name\n",
    "model_run_path = os.path.join(log_dir, model_run)\n",
    "#best_fold = 1\n",
    "best_fold = val_loss_scores.index(min(val_loss_scores))\n",
    "\n",
    "# Get best model for chosen fold\n",
    "model_run_dir = os.listdir(model_run_path)\n",
    "model_folds = [i for i in model_run_dir if i.startswith(f\"fold={best_fold}\")]\n",
    "model_folds_scores = [float(i.split(\"val_loss=\")[1].split(\"-\")[0]) for i in model_folds]\n",
    "model_name = model_folds[model_folds_scores.index(min(model_folds_scores))]\n",
    "model_path = os.path.join(model_run_path, model_name)\n",
    "\n",
    "# Load fold's model\n",
    "model = CoolSystem(hparams)\n",
    "model.load_state_dict(\n",
    "    torch.load(model_path)[\"state_dict\"]\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# Retrieve validation indices for chosen fold\n",
    "for fold_i, (train_index, val_index) in enumerate(folds.split(metadata[[\"img_path\"]], metadata[[\"label\"]])):\n",
    "    if fold_i == best_fold:\n",
    "        break\n",
    "\n",
    "# Select fold validation images\n",
    "X_val = torch.from_numpy(X_train[val_index]).permute(0, 3, 1, 2).float()\n",
    "\n",
    "# Create predictions looped by batch\n",
    "counter = 0\n",
    "val_i_batch = []\n",
    "val_idx_batch = []\n",
    "scores_df = pd.DataFrame()\n",
    "\n",
    "for i, idx in tqdm(enumerate(val_index)):\n",
    "    counter += 1\n",
    "    val_i_batch.append(i) # arrays don't preserve index so need ordered index values\n",
    "    val_idx_batch.append(idx) # for preserved index\n",
    "    \n",
    "    # Run inference for val_batch_size\n",
    "    if counter == hparams.val_batch_size:\n",
    "        preds = model(X_val[val_i_batch])\n",
    "        \n",
    "        # Create activation output\n",
    "        log_softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        # Convert raw output to probabilities\n",
    "        preds = np.exp(log_softmax(preds).detach().numpy())\n",
    "\n",
    "        # Create df with img paths and predicted label probs\n",
    "        scores_df_batch = pd.DataFrame(preds, columns=val_data.columns[1:])\n",
    "        scores_df_batch = pd.merge(\n",
    "            metadata.iloc[val_idx_batch, 1:3].reset_index(drop=True),\n",
    "            scores_df_batch, \n",
    "            left_index=True,\n",
    "            right_index=True\n",
    "        )\n",
    "        scores_df = pd.concat([scores_df, scores_df_batch], ignore_index=True, axis=0)\n",
    "\n",
    "        # Cleanup\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # Reset counter and batch\n",
    "        counter = 0\n",
    "        val_i_batch = []\n",
    "        val_idx_batch = []\n",
    "        \n",
    "    # Run inference for remaining batch\n",
    "    elif idx == val_index[-1]:\n",
    "        preds = model(X_val[val_i_batch])\n",
    "        \n",
    "        # Create activation output\n",
    "        log_softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        # Convert raw output to probabilities\n",
    "        preds = np.exp(log_softmax(preds).detach().numpy())\n",
    "\n",
    "        # Create df with img paths and predicted label probs\n",
    "        scores_df_batch = pd.DataFrame(preds, columns=val_data.columns[1:])\n",
    "        scores_df_batch = pd.merge(\n",
    "            metadata.iloc[val_idx_batch, 1:3].reset_index(drop=True),\n",
    "            scores_df_batch, \n",
    "            left_index=True,\n",
    "            right_index=True\n",
    "        )\n",
    "        scores_df = pd.concat([scores_df, scores_df_batch], ignore_index=True, axis=0)\n",
    "\n",
    "        # Cleanup\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "# Write predictions to log\n",
    "scores_df.to_csv(\n",
    "    os.path.join(model_run_path, f\"{model_run}_preds_fold_{best_fold}.csv\"),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fc3edc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>ant</th>\n",
       "      <th>bedbug</th>\n",
       "      <th>bee</th>\n",
       "      <th>horsefly</th>\n",
       "      <th>mite</th>\n",
       "      <th>mosquito</th>\n",
       "      <th>none</th>\n",
       "      <th>tick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/cleaned/none/6eac051b9c45ff6821ec86752...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.199594</td>\n",
       "      <td>0.179132</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.177215</td>\n",
       "      <td>0.122495</td>\n",
       "      <td>0.069613</td>\n",
       "      <td>0.087695</td>\n",
       "      <td>0.067611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/cleaned/none/fc72767f8520df9b2b8394107...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.199738</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0.092610</td>\n",
       "      <td>0.194288</td>\n",
       "      <td>0.117436</td>\n",
       "      <td>0.066435</td>\n",
       "      <td>0.084611</td>\n",
       "      <td>0.065015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/cleaned/none/49850884a00703afe5aab78c3...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.211779</td>\n",
       "      <td>0.174707</td>\n",
       "      <td>0.095123</td>\n",
       "      <td>0.180009</td>\n",
       "      <td>0.121242</td>\n",
       "      <td>0.067141</td>\n",
       "      <td>0.084959</td>\n",
       "      <td>0.065040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/cleaned/none/8dab219e5fa4d9a05d42b6f3a...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.200346</td>\n",
       "      <td>0.179968</td>\n",
       "      <td>0.094964</td>\n",
       "      <td>0.182751</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.069074</td>\n",
       "      <td>0.086861</td>\n",
       "      <td>0.066567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/cleaned/none/d9c0f49c789a29fb55370319e...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.192123</td>\n",
       "      <td>0.181109</td>\n",
       "      <td>0.097990</td>\n",
       "      <td>0.174168</td>\n",
       "      <td>0.123287</td>\n",
       "      <td>0.071402</td>\n",
       "      <td>0.089708</td>\n",
       "      <td>0.070213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>../data/cleaned/ant/b7d95c4a5fe54f5bbfb3442ceb...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.200831</td>\n",
       "      <td>0.177721</td>\n",
       "      <td>0.097698</td>\n",
       "      <td>0.173661</td>\n",
       "      <td>0.124476</td>\n",
       "      <td>0.069470</td>\n",
       "      <td>0.087910</td>\n",
       "      <td>0.068233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>../data/cleaned/ant/8fadf11644c8c4877b64bb61cb...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.199049</td>\n",
       "      <td>0.178787</td>\n",
       "      <td>0.097005</td>\n",
       "      <td>0.176380</td>\n",
       "      <td>0.122680</td>\n",
       "      <td>0.070051</td>\n",
       "      <td>0.088188</td>\n",
       "      <td>0.067861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>../data/cleaned/ant/ab1b890b774b4cc6b71459a595...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.189615</td>\n",
       "      <td>0.181847</td>\n",
       "      <td>0.098680</td>\n",
       "      <td>0.171040</td>\n",
       "      <td>0.124264</td>\n",
       "      <td>0.072378</td>\n",
       "      <td>0.090936</td>\n",
       "      <td>0.071240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>../data/cleaned/ant/d170bac72faf6447bd8d192744...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.193033</td>\n",
       "      <td>0.181599</td>\n",
       "      <td>0.097713</td>\n",
       "      <td>0.175282</td>\n",
       "      <td>0.123042</td>\n",
       "      <td>0.071082</td>\n",
       "      <td>0.088928</td>\n",
       "      <td>0.069321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>../data/cleaned/ant/df654f18291b8f1c20659e4621...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.200272</td>\n",
       "      <td>0.178834</td>\n",
       "      <td>0.096604</td>\n",
       "      <td>0.176485</td>\n",
       "      <td>0.122902</td>\n",
       "      <td>0.069555</td>\n",
       "      <td>0.087853</td>\n",
       "      <td>0.067495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             img_path label       ant  \\\n",
       "0   ../data/cleaned/none/6eac051b9c45ff6821ec86752...  none  0.199594   \n",
       "1   ../data/cleaned/none/fc72767f8520df9b2b8394107...  none  0.199738   \n",
       "2   ../data/cleaned/none/49850884a00703afe5aab78c3...  none  0.211779   \n",
       "3   ../data/cleaned/none/8dab219e5fa4d9a05d42b6f3a...  none  0.200346   \n",
       "4   ../data/cleaned/none/d9c0f49c789a29fb55370319e...  none  0.192123   \n",
       "..                                                ...   ...       ...   \n",
       "95  ../data/cleaned/ant/b7d95c4a5fe54f5bbfb3442ceb...   ant  0.200831   \n",
       "96  ../data/cleaned/ant/8fadf11644c8c4877b64bb61cb...   ant  0.199049   \n",
       "97  ../data/cleaned/ant/ab1b890b774b4cc6b71459a595...   ant  0.189615   \n",
       "98  ../data/cleaned/ant/d170bac72faf6447bd8d192744...   ant  0.193033   \n",
       "99  ../data/cleaned/ant/df654f18291b8f1c20659e4621...   ant  0.200272   \n",
       "\n",
       "      bedbug       bee  horsefly      mite  mosquito      none      tick  \n",
       "0   0.179132  0.096645  0.177215  0.122495  0.069613  0.087695  0.067611  \n",
       "1   0.179867  0.092610  0.194288  0.117436  0.066435  0.084611  0.065015  \n",
       "2   0.174707  0.095123  0.180009  0.121242  0.067141  0.084959  0.065040  \n",
       "3   0.179968  0.094964  0.182751  0.119469  0.069074  0.086861  0.066567  \n",
       "4   0.181109  0.097990  0.174168  0.123287  0.071402  0.089708  0.070213  \n",
       "..       ...       ...       ...       ...       ...       ...       ...  \n",
       "95  0.177721  0.097698  0.173661  0.124476  0.069470  0.087910  0.068233  \n",
       "96  0.178787  0.097005  0.176380  0.122680  0.070051  0.088188  0.067861  \n",
       "97  0.181847  0.098680  0.171040  0.124264  0.072378  0.090936  0.071240  \n",
       "98  0.181599  0.097713  0.175282  0.123042  0.071082  0.088928  0.069321  \n",
       "99  0.178834  0.096604  0.176485  0.122902  0.069555  0.087853  0.067495  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a910bef3",
   "metadata": {},
   "source": [
    "## Validation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b4293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 unique image paths.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(scores_df['img_path'].unique())} unique image paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6565caec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation label counts:\n",
      "bedbug      19\n",
      "tick        18\n",
      "mosquito    16\n",
      "ant         16\n",
      "none         9\n",
      "horsefly     8\n",
      "mite         7\n",
      "bee          7\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation label counts:\")\n",
    "print(scores_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f8676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction counts:\n",
      "ant    100\n",
      "Name: pred_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation prediction counts:\")\n",
    "print(\n",
    "    pd.melt(\n",
    "        scores_df,\n",
    "        id_vars=[\"img_path\", \"label\"],\n",
    "        value_vars=[\"ant\", \"bedbug\", \"bee\", \"horsefly\", \"mite\", \"mosquito\" ,\"none\", \"tick\"],\n",
    "        var_name=\"pred_label\",\n",
    "        value_name=\"pred_prob\"\n",
    "    ).sort_values([\"img_path\", \"pred_prob\"], ascending=False) \\\n",
    "    .groupby([\"img_path\", \"label\"]).first()[\"pred_label\"] \\\n",
    "    .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24bf48d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>0.25</th>\n",
       "      <th>median</th>\n",
       "      <th>0.75</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ant</th>\n",
       "      <td>0.199900</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.188495</td>\n",
       "      <td>0.194659</td>\n",
       "      <td>0.199329</td>\n",
       "      <td>0.203630</td>\n",
       "      <td>0.221213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedbug</th>\n",
       "      <td>0.179407</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.171533</td>\n",
       "      <td>0.177821</td>\n",
       "      <td>0.179512</td>\n",
       "      <td>0.181023</td>\n",
       "      <td>0.185112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bee</th>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.092610</td>\n",
       "      <td>0.095749</td>\n",
       "      <td>0.097073</td>\n",
       "      <td>0.097668</td>\n",
       "      <td>0.098680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsefly</th>\n",
       "      <td>0.176606</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>0.170636</td>\n",
       "      <td>0.173639</td>\n",
       "      <td>0.175626</td>\n",
       "      <td>0.178308</td>\n",
       "      <td>0.194288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mite</th>\n",
       "      <td>0.122535</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.116238</td>\n",
       "      <td>0.121634</td>\n",
       "      <td>0.123049</td>\n",
       "      <td>0.124008</td>\n",
       "      <td>0.124980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mosquito</th>\n",
       "      <td>0.069644</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.065665</td>\n",
       "      <td>0.068604</td>\n",
       "      <td>0.069802</td>\n",
       "      <td>0.070717</td>\n",
       "      <td>0.072880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>0.087705</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>0.086364</td>\n",
       "      <td>0.087930</td>\n",
       "      <td>0.088979</td>\n",
       "      <td>0.091231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tick</th>\n",
       "      <td>0.067621</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.063009</td>\n",
       "      <td>0.066332</td>\n",
       "      <td>0.067964</td>\n",
       "      <td>0.068993</td>\n",
       "      <td>0.071240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean       std       min      0.25    median      0.75       max\n",
       "ant       0.199900  0.006673  0.188495  0.194659  0.199329  0.203630  0.221213\n",
       "bedbug    0.179407  0.002472  0.171533  0.177821  0.179512  0.181023  0.185112\n",
       "bee       0.096582  0.001493  0.092610  0.095749  0.097073  0.097668  0.098680\n",
       "horsefly  0.176606  0.004302  0.170636  0.173639  0.175626  0.178308  0.194288\n",
       "mite      0.122535  0.001997  0.116238  0.121634  0.123049  0.124008  0.124980\n",
       "mosquito  0.069644  0.001532  0.065665  0.068604  0.069802  0.070717  0.072880\n",
       "none      0.087705  0.001705  0.083456  0.086364  0.087930  0.088979  0.091231\n",
       "tick      0.067621  0.001882  0.063009  0.066332  0.067964  0.068993  0.071240"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability stats by label\n",
    "pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].mean(), columns=[\"mean\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].std(), columns=[\"std\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].min(), columns=[\"min\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].quantile(0.25)),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].median(), columns=[\"median\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].quantile(0.75)),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].max(), columns=[\"max\"])\n",
    "    ], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92d47fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">pred_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_label</th>\n",
       "      <th>ant</th>\n",
       "      <th>bedbug</th>\n",
       "      <th>bee</th>\n",
       "      <th>horsefly</th>\n",
       "      <th>mite</th>\n",
       "      <th>mosquito</th>\n",
       "      <th>none</th>\n",
       "      <th>tick</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ant</th>\n",
       "      <td>0.202127</td>\n",
       "      <td>0.178731</td>\n",
       "      <td>0.096133</td>\n",
       "      <td>0.177521</td>\n",
       "      <td>0.122194</td>\n",
       "      <td>0.069180</td>\n",
       "      <td>0.087174</td>\n",
       "      <td>0.066941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedbug</th>\n",
       "      <td>0.200962</td>\n",
       "      <td>0.179077</td>\n",
       "      <td>0.096468</td>\n",
       "      <td>0.177048</td>\n",
       "      <td>0.122363</td>\n",
       "      <td>0.069387</td>\n",
       "      <td>0.087324</td>\n",
       "      <td>0.067370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bee</th>\n",
       "      <td>0.195422</td>\n",
       "      <td>0.181255</td>\n",
       "      <td>0.096886</td>\n",
       "      <td>0.176624</td>\n",
       "      <td>0.122258</td>\n",
       "      <td>0.070567</td>\n",
       "      <td>0.088531</td>\n",
       "      <td>0.068458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsefly</th>\n",
       "      <td>0.199415</td>\n",
       "      <td>0.180163</td>\n",
       "      <td>0.096397</td>\n",
       "      <td>0.176407</td>\n",
       "      <td>0.122492</td>\n",
       "      <td>0.069691</td>\n",
       "      <td>0.087932</td>\n",
       "      <td>0.067502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mite</th>\n",
       "      <td>0.202051</td>\n",
       "      <td>0.179027</td>\n",
       "      <td>0.096289</td>\n",
       "      <td>0.176395</td>\n",
       "      <td>0.122491</td>\n",
       "      <td>0.069328</td>\n",
       "      <td>0.087424</td>\n",
       "      <td>0.066995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mosquito</th>\n",
       "      <td>0.197185</td>\n",
       "      <td>0.179948</td>\n",
       "      <td>0.097340</td>\n",
       "      <td>0.174679</td>\n",
       "      <td>0.123302</td>\n",
       "      <td>0.070385</td>\n",
       "      <td>0.088579</td>\n",
       "      <td>0.068581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>0.200798</td>\n",
       "      <td>0.178829</td>\n",
       "      <td>0.095862</td>\n",
       "      <td>0.179979</td>\n",
       "      <td>0.121492</td>\n",
       "      <td>0.068884</td>\n",
       "      <td>0.086986</td>\n",
       "      <td>0.067169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tick</th>\n",
       "      <td>0.199886</td>\n",
       "      <td>0.179255</td>\n",
       "      <td>0.096865</td>\n",
       "      <td>0.175516</td>\n",
       "      <td>0.123005</td>\n",
       "      <td>0.069791</td>\n",
       "      <td>0.087848</td>\n",
       "      <td>0.067834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred_prob                                                    \\\n",
       "pred_label       ant    bedbug       bee  horsefly      mite  mosquito   \n",
       "label                                                                    \n",
       "ant         0.202127  0.178731  0.096133  0.177521  0.122194  0.069180   \n",
       "bedbug      0.200962  0.179077  0.096468  0.177048  0.122363  0.069387   \n",
       "bee         0.195422  0.181255  0.096886  0.176624  0.122258  0.070567   \n",
       "horsefly    0.199415  0.180163  0.096397  0.176407  0.122492  0.069691   \n",
       "mite        0.202051  0.179027  0.096289  0.176395  0.122491  0.069328   \n",
       "mosquito    0.197185  0.179948  0.097340  0.174679  0.123302  0.070385   \n",
       "none        0.200798  0.178829  0.095862  0.179979  0.121492  0.068884   \n",
       "tick        0.199886  0.179255  0.096865  0.175516  0.123005  0.069791   \n",
       "\n",
       "                                \n",
       "pred_label      none      tick  \n",
       "label                           \n",
       "ant         0.087174  0.066941  \n",
       "bedbug      0.087324  0.067370  \n",
       "bee         0.088531  0.068458  \n",
       "horsefly    0.087932  0.067502  \n",
       "mite        0.087424  0.066995  \n",
       "mosquito    0.088579  0.068581  \n",
       "none        0.086986  0.067169  \n",
       "tick        0.087848  0.067834  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.melt(\n",
    "    scores_df,\n",
    "    id_vars=[\"img_path\", \"label\"],\n",
    "    value_vars=[\"ant\", \"bedbug\", \"bee\", \"horsefly\", \"mite\", \"mosquito\" ,\"none\", \"tick\"],\n",
    "    var_name=\"pred_label\",\n",
    "    value_name=\"pred_prob\"\n",
    ").pivot_table(\n",
    "    index=[\"label\"],\n",
    "    columns=[\"pred_label\"],\n",
    "    aggfunc=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "980e4931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/24aca08f4aeea83c077a9721c85b5a6ff8ef7d3d.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>ant</td>\n",
       "      <td>0.201319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/26b8fb30b3ddd29f8e5763b8b9a63cda83006c7a.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>ant</td>\n",
       "      <td>0.197799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/448b50c6778952be3df52a6a26affeff4844b7f4.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>ant</td>\n",
       "      <td>0.202395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/451d80e25d8f18e8a68174ff8ff651c435bd4700.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>ant</td>\n",
       "      <td>0.207965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/51782d78019c7b5be5333e7bc2dab3469f88fec7.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>ant</td>\n",
       "      <td>0.200533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/c99e1bba324bc3b31bfab79473a50baeb0c87a2a.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>ant</td>\n",
       "      <td>0.190451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/d842edcf4167941990cb0b05c8a3c58db001c8d6.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>ant</td>\n",
       "      <td>0.203257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/ebeb916d8413d0b3387c84896fb99ddf6eb2fe13.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>ant</td>\n",
       "      <td>0.204682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/f4beab1b01a8c5d7674b2392b230515d74ae34ea.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>ant</td>\n",
       "      <td>0.197454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/f82e692ff747a6f88cc6c68e97cb69cbb5df4aab.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>ant</td>\n",
       "      <td>0.203545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         pred_label  pred_prob\n",
       "img_path                                           label                      \n",
       "../data/cleaned/ant/24aca08f4aeea83c077a9721c85... ant          ant   0.201319\n",
       "../data/cleaned/ant/26b8fb30b3ddd29f8e5763b8b9a... ant          ant   0.197799\n",
       "../data/cleaned/ant/448b50c6778952be3df52a6a26a... ant          ant   0.202395\n",
       "../data/cleaned/ant/451d80e25d8f18e8a68174ff8ff... ant          ant   0.207965\n",
       "../data/cleaned/ant/51782d78019c7b5be5333e7bc2d... ant          ant   0.200533\n",
       "...                                                             ...        ...\n",
       "../data/cleaned/tick/c99e1bba324bc3b31bfab79473... tick         ant   0.190451\n",
       "../data/cleaned/tick/d842edcf4167941990cb0b05c8... tick         ant   0.203257\n",
       "../data/cleaned/tick/ebeb916d8413d0b3387c84896f... tick         ant   0.204682\n",
       "../data/cleaned/tick/f4beab1b01a8c5d7674b2392b2... tick         ant   0.197454\n",
       "../data/cleaned/tick/f82e692ff747a6f88cc6c68e97... tick         ant   0.203545\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.melt(\n",
    "    scores_df,\n",
    "    id_vars=[\"img_path\", \"label\"],\n",
    "    value_vars=[\"ant\", \"bedbug\", \"bee\", \"horsefly\", \"mite\", \"mosquito\" ,\"none\", \"tick\"],\n",
    "    var_name=\"pred_label\",\n",
    "    value_name=\"pred_prob\"\n",
    ").sort_values([\"img_path\", \"pred_prob\"], ascending=False).groupby([\"img_path\", \"label\"]).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249a0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613be570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88807ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biteme",
   "language": "python",
   "name": "biteme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
