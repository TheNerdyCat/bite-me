{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef0d2692",
   "metadata": {},
   "source": [
    "# BiteMe | Train\n",
    "\n",
    "This notebook includes the most important part of the project - the modelling. The notebook tests methodologies for training, and in it the chosen algorithm is decided. Validation also occurs before final testing, which is conducted in the test notebook. This stage is highly iterative, so all model artefacts, logs and configurations are recorded and saved to disk automatically. This initial setup of what will eventually become MLOps for the final product will be really useful, and helps keep track of what is successful and what isn't.\n",
    "\n",
    "Models to try:\n",
    "\n",
    " - [DenseNet121](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet161](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet169](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet201](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet201](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DualPathNet68](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet92](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet98](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet107](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet113](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [FBResNet152](https://github.com/Cadene/pretrained-models.pytorch#facebook-resnet)\n",
    " - [InceptionResNetV2](https://github.com/Cadene/pretrained-models.pytorch#inception)\n",
    " - [InceptionV4](https://github.com/Cadene/pretrained-models.pytorch#inception)\n",
    " - [NASNet-A-Large](https://github.com/Cadene/pretrained-models.pytorch#nasnet)\n",
    " - [PNASNet-5-Large](https://github.com/Cadene/pretrained-models.pytorch#pnasnet)\n",
    " - [PolyNet](https://github.com/Cadene/pretrained-models.pytorch#polynet)\n",
    " - [ResNeXt101_32x4d](https://github.com/Cadene/pretrained-models.pytorch#resnext)\n",
    " - [ResNeXt101_64x4d](https://github.com/Cadene/pretrained-models.pytorch#resnext)\n",
    " - [ResNet101](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [ResNet152](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [ResNet50](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [SENet154](https://github.com/Cadene/pretrained-models.pytorch#senet)\n",
    " - [SE-ResNet50](https://github.com/Cadene/pretrained-models.pytorch#senet)\n",
    " - [SE-ResNet101](https://github.com/Cadene/pretrained-models.pytorch#senet)\n",
    " - [SE-ResNet152](https://github.com/Cadene/pretrained-models.pytorch#senet)\n",
    " - [SE-ResNeXt50_32x4d](https://github.com/Cadene/pretrained-models.pytorch#senet)\n",
    " - [SE-ResNeXt101_32x4d](https://github.com/Cadene/pretrained-models.pytorch#senet)\n",
    " - [SqueezeNet1_0](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [SqueezeNet1_1](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [VGG16](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [VGG19](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [VGG16_BN](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [VGG19_BN](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [Xception](https://github.com/Cadene/pretrained-models.pytorch#xception)\n",
    "\n",
    "\n",
    "- efficientnet_b0\n",
    "- efficientnet_b1\n",
    "- efficientnet_b2\n",
    "- efficientnet_b3\n",
    "- efficientnet_b4\n",
    "- efficientnet_b5\n",
    "\n",
    "Initial model work is done by using simple, typical image recognition models (CNN architectures) to see how effective these models can be for the problem. Although I don't expect them to be particularly successful, it's important to establish baselines and take a holistic approach to modelling when it's possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be8b5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from argparse import ArgumentParser\n",
    "import datetime\n",
    "from time import time\n",
    "import gc\n",
    "\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "import torch\n",
    "import pretrainedmodels\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Local imports\n",
    "sys.path.append(\"..\")\n",
    "from utils.dataset import generate_transforms, generate_dataloaders\n",
    "from models.models import se_resnet50\n",
    "from utils.loss_function import CrossEntropyLossOneHot\n",
    "from utils.lrs_scheduler import WarmRestart, warm_restart\n",
    "from utils.utils import read_images, augs, get_augs, seed_reproducer, init_logger\n",
    "from utils.constants import *\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a79a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7059b14d2aa03ed6c4de11afa32591995181d31c.jpg</td>\n",
       "      <td>../data/cleaned/none/7059b14d2aa03ed6c4de11afa...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea1b100b581fcdb7ddfae52cc62347a99e304ba4.jpg</td>\n",
       "      <td>../data/cleaned/none/ea1b100b581fcdb7ddfae52cc...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6eac051b9c45ff6821ec8675216f371711b7cea9.jpg</td>\n",
       "      <td>../data/cleaned/none/6eac051b9c45ff6821ec86752...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fc72767f8520df9b2b83941077dc0ee013eb9399.jpg</td>\n",
       "      <td>../data/cleaned/none/fc72767f8520df9b2b8394107...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cf812984268e2aec9a167d3ebe1026f610dd862b.jpg</td>\n",
       "      <td>../data/cleaned/none/cf812984268e2aec9a167d3eb...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       img_name  \\\n",
       "0  7059b14d2aa03ed6c4de11afa32591995181d31c.jpg   \n",
       "1  ea1b100b581fcdb7ddfae52cc62347a99e304ba4.jpg   \n",
       "3  6eac051b9c45ff6821ec8675216f371711b7cea9.jpg   \n",
       "4  fc72767f8520df9b2b83941077dc0ee013eb9399.jpg   \n",
       "5  cf812984268e2aec9a167d3ebe1026f610dd862b.jpg   \n",
       "\n",
       "                                            img_path label  split  \n",
       "0  ../data/cleaned/none/7059b14d2aa03ed6c4de11afa...  none  train  \n",
       "1  ../data/cleaned/none/ea1b100b581fcdb7ddfae52cc...  none  train  \n",
       "3  ../data/cleaned/none/6eac051b9c45ff6821ec86752...  none  train  \n",
       "4  ../data/cleaned/none/fc72767f8520df9b2b8394107...  none  train  \n",
       "5  ../data/cleaned/none/cf812984268e2aec9a167d3eb...  none  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define directories\n",
    "base_dir_path = \"../\"\n",
    "\n",
    "data_dir_path = os.path.join(base_dir_path, \"data\")\n",
    "data_preprocessed_dir_path = os.path.join(data_dir_path, \"preprocessed\")\n",
    "data_preprocessed_train_dir_path = os.path.join(data_dir_path, \"preprocessed/train\")\n",
    "\n",
    "data_dir = os.listdir(data_dir_path)\n",
    "data_preprocessed_dir = os.listdir(data_preprocessed_dir_path)\n",
    "data_preprocessed_train_dir = os.listdir(data_preprocessed_train_dir_path)\n",
    "\n",
    "metadata_preprocessed_path = os.path.join(data_preprocessed_dir_path, \"metadata.csv\")\n",
    "metadata = pd.read_csv(metadata_preprocessed_path)\n",
    "# Subset to train only\n",
    "metadata = metadata.loc[metadata.split == \"train\"]\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4dde582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from: ../data/preprocessed/train\n",
      "Rows set to 1024\n",
      "Columns set to 1024\n",
      "Channels set to 3\n",
      "Writing images is set to: False\n",
      "Reading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 51.42it/s]\n",
      "100%|███████████████████████████████████████████| 26/26 [00:00<00:00, 27.18it/s]\n",
      "100%|███████████████████████████████████████████| 21/21 [00:01<00:00, 19.01it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:01<00:00, 14.77it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:02<00:00, 11.83it/s]\n",
      "100%|███████████████████████████████████████████| 22/22 [00:02<00:00,  9.94it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:02<00:00,  8.58it/s]\n",
      "100%|███████████████████████████████████████████| 23/23 [00:03<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image reading complete.\n",
      "Image array shape: (192, 1024, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read in train images\n",
    "X_train = read_images(\n",
    "    data_dir_path=data_preprocessed_train_dir_path, \n",
    "    rows=ROWS, \n",
    "    cols=COLS, \n",
    "    channels=CHANNELS, \n",
    "    write_images=False, \n",
    "    output_data_dir_path=None,\n",
    "    verbose=VERBOSE\n",
    ")\n",
    "\n",
    "# Get labels\n",
    "y_train = np.array(pd.get_dummies(metadata[\"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9eb1b2",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac202af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose augmentations to use in preprocessing\n",
    "# For full list see helpers.py\n",
    "#augs_to_select = [\n",
    "#    \"Resize\",\n",
    "#    \"HorizontalFlip\", \n",
    "#    \"VerticalFlip\",\n",
    "#    \"Normalize\"\n",
    "#]\n",
    "## Subset augs based on those selected\n",
    "#AUGS = dict((aug_name, augs[aug_name]) for aug_name in augs_to_select)\n",
    "\n",
    "\n",
    "def init_hparams():\n",
    "    \"\"\"\n",
    "    Initialise hyperparameters for modelling.\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    hparams : argparse.Namespace\n",
    "        Parsed hyperparameters\n",
    "    \"\"\"\n",
    "    parser = ArgumentParser(add_help=False)\n",
    "    parser.add_argument(\"-backbone\", \"--backbone\", type=str, default=MODEL_NAME)\n",
    "    parser.add_argument(\"-device_name\", type=str, default=DEVICE_NAME)\n",
    "    parser.add_argument(\"--gpus\", default=[0])\n",
    "    parser.add_argument(\"--n_workers\", type=int, default=N_WORKERS)\n",
    "    parser.add_argument(\"--image_size\", nargs=\"+\", default=[ROWS, COLS])\n",
    "    parser.add_argument(\"--seed\", type=int, default=SEED)\n",
    "    parser.add_argument(\"--min_epochs\", type=int, default=MIN_EPOCHS)\n",
    "    parser.add_argument(\"--max_epochs\", type=int, default=MAX_EPOCHS)\n",
    "    parser.add_argument(\"--patience\", type=str, default=PATIENCE)    \n",
    "    parser.add_argument(\"-tbs\", \"--train_batch_size\", type=int, default=TRAIN_BATCH_SIZE)\n",
    "    parser.add_argument(\"-vbs\", \"--val_batch_size\", type=int, default=VAL_BATCH_SIZE)\n",
    "    parser.add_argument(\"--n_splits\", type=int, default=N_SPLITS)\n",
    "    parser.add_argument(\"--test_size\", type=float, default=TEST_SIZE)\n",
    "    parser.add_argument(\"--precision\", type=int, default=PRECISION)\n",
    "    parser.add_argument(\"--gradient_clip_val\", type=float, default=GRADIENT_CLIP_VAL)\n",
    "    parser.add_argument(\"--verbose\", type=str, default=VERBOSE)\n",
    "    parser.add_argument(\"--log_dir\", type=str, default=LOG_DIR)\n",
    "    parser.add_argument(\"--log_name\", type=str, default=LOG_NAME)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        hparams, unknown = parser.parse_known_args()\n",
    "    except:\n",
    "        hparams, unknown = parser.parse_args([])\n",
    "\n",
    "    if len(hparams.gpus) == 1:\n",
    "        hparams.gpus = [int(hparams.gpus[0])]\n",
    "    else:\n",
    "        hparams.gpus = [int(gpu) for gpu in hparams.gpus]\n",
    "\n",
    "    hparams.image_size = [int(size) for size in hparams.image_size]\n",
    "    \n",
    "    return hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca739edd",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b5b9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoolSystem(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "\n",
    "        seed_reproducer(self.hparams.seed)\n",
    "\n",
    "        self.model = se_resnet50()\n",
    "        self.criterion = CrossEntropyLossOneHot()\n",
    "        self.logger_kun = init_logger(\n",
    "            hparams.log_name, \n",
    "            hparams.log_dir\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0\n",
    "        )\n",
    "        self.scheduler = WarmRestart(self.optimizer, T_max=10, T_mult=1, eta_min=1e-5)\n",
    "        return [self.optimizer], [self.scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        step_start_time = time()\n",
    "        images, labels, data_load_time = batch\n",
    "\n",
    "        scores = self(images)\n",
    "        loss = self.criterion(scores, labels)\n",
    "\n",
    "        data_load_time = torch.sum(data_load_time)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"data_load_time\": data_load_time,\n",
    "            \"batch_run_time\": torch.Tensor([time() - step_start_time + data_load_time]).to(\n",
    "                data_load_time.device\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        # outputs is the return of training_step\n",
    "        train_loss_mean = torch.stack([output[\"loss\"] for output in outputs]).mean()\n",
    "        self.data_load_times = torch.stack([output[\"data_load_time\"] for output in outputs]).sum()\n",
    "        self.batch_run_times = torch.stack([output[\"batch_run_time\"] for output in outputs]).sum()\n",
    "\n",
    "        self.current_epoch += 1\n",
    "        if self.current_epoch < (self.trainer.max_epochs - 4):\n",
    "            self.scheduler = warm_restart(self.scheduler, T_mult=2)\n",
    "\n",
    "        return {\"train_loss\": train_loss_mean}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        step_start_time = time()\n",
    "        images, labels, data_load_time = batch\n",
    "        data_load_time = torch.sum(data_load_time)\n",
    "        scores = self(images)\n",
    "        loss = self.criterion(scores, labels)\n",
    "\n",
    "        # must return key -> val_loss\n",
    "        return {\n",
    "            \"val_loss\": loss,\n",
    "            \"scores\": scores,\n",
    "            \"labels\": labels,\n",
    "            \"data_load_time\": data_load_time,\n",
    "            \"batch_run_time\": torch.Tensor([time() - step_start_time + data_load_time]).to(\n",
    "                data_load_time.device\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # compute loss\n",
    "        val_loss_mean = torch.stack([output[\"val_loss\"] for output in outputs]).mean()\n",
    "        self.data_load_times = torch.stack([output[\"data_load_time\"] for output in outputs]).sum()\n",
    "        self.batch_run_times = torch.stack([output[\"batch_run_time\"] for output in outputs]).sum()\n",
    "\n",
    "        # compute roc_auc\n",
    "        scores_all = torch.cat([output[\"scores\"] for output in outputs]).cpu()\n",
    "        labels_all = torch.round(torch.cat([output[\"labels\"] for output in outputs]).cpu())\n",
    "        val_roc_auc = torch.tensor(roc_auc_score(labels_all, scores_all))\n",
    "\n",
    "        # terminal logs\n",
    "        self.logger_kun.info(\n",
    "            f\"{self.hparams.fold_i}-{self.current_epoch} | \"\n",
    "            f\"lr : {self.scheduler.get_lr()[0]:.6f} | \"\n",
    "            f\"val_loss : {val_loss_mean:.4f} | \"\n",
    "            f\"val_roc_auc : {val_roc_auc:.4f} | \"\n",
    "            f\"data_load_times : {self.data_load_times:.2f} | \"\n",
    "            f\"batch_run_times : {self.batch_run_times:.2f}\"\n",
    "        )\n",
    "\n",
    "        return {\"val_loss\": val_loss_mean, \"val_roc_auc\": val_roc_auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd3fde",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c68f6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-12 18:59:26] 3786432242.py[  25] : INFO  Fold 0 num train records: 128\n",
      "[2022-09-12 18:59:26] 3786432242.py[  26] : INFO  Fold 0 num val records: 64\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/edwardsims/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009333133697509766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 102502400,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4cfba3f8aff408e8900c00ab4f764f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "[2022-09-12 19:00:04] 2105417623.py[  84] : INFO  0-0 | lr : 0.001000 | val_loss : 2.0778 | val_roc_auc : 0.5328 | data_load_times : 34.32 | batch_run_times : 34.48\n",
      "[2022-09-12 19:00:35] 2105417623.py[  84] : INFO  0-1 | lr : 0.000976 | val_loss : 2.0893 | val_roc_auc : 0.5040 | data_load_times : 35.36 | batch_run_times : 35.47\n",
      "[2022-09-12 19:01:05] 2105417623.py[  84] : INFO  0-2 | lr : 0.000905 | val_loss : 2.0651 | val_roc_auc : 0.5660 | data_load_times : 37.83 | batch_run_times : 37.93\n",
      "[2022-09-12 19:01:35] 2105417623.py[  84] : INFO  0-3 | lr : 0.000796 | val_loss : 2.0520 | val_roc_auc : 0.5628 | data_load_times : 39.47 | batch_run_times : 39.64\n",
      "[2022-09-12 19:02:06] 2105417623.py[  84] : INFO  0-4 | lr : 0.000658 | val_loss : 2.0721 | val_roc_auc : 0.5243 | data_load_times : 38.40 | batch_run_times : 38.51\n",
      "[2022-09-12 19:02:37] 2105417623.py[  84] : INFO  0-5 | lr : 0.000505 | val_loss : 2.0799 | val_roc_auc : 0.5408 | data_load_times : 38.41 | batch_run_times : 38.55\n",
      "[2022-09-12 19:03:08] 2105417623.py[  84] : INFO  0-6 | lr : 0.000352 | val_loss : 2.0909 | val_roc_auc : 0.4784 | data_load_times : 38.18 | batch_run_times : 38.29\n",
      "[2022-09-12 19:03:38] 2105417623.py[  84] : INFO  0-7 | lr : 0.000214 | val_loss : 2.0876 | val_roc_auc : 0.4735 | data_load_times : 38.28 | batch_run_times : 38.39\n",
      "[2022-09-12 19:04:08] 2105417623.py[  84] : INFO  0-8 | lr : 0.000105 | val_loss : 2.0712 | val_roc_auc : 0.5291 | data_load_times : 38.55 | batch_run_times : 38.72\n",
      "[2022-09-12 19:04:39] 2105417623.py[  84] : INFO  0-9 | lr : 0.000034 | val_loss : 2.0905 | val_roc_auc : 0.4772 | data_load_times : 39.71 | batch_run_times : 39.84\n",
      "[2022-09-12 19:05:09] 2105417623.py[  84] : INFO  0-10 | lr : 0.001000 | val_loss : 2.0819 | val_roc_auc : 0.5018 | data_load_times : 35.35 | batch_run_times : 35.47\n",
      "[2022-09-12 19:05:39] 2105417623.py[  84] : INFO  0-11 | lr : 0.000976 | val_loss : 2.0910 | val_roc_auc : 0.5402 | data_load_times : 37.94 | batch_run_times : 38.05\n",
      "[2022-09-12 19:06:09] 2105417623.py[  84] : INFO  0-12 | lr : 0.000905 | val_loss : 2.0916 | val_roc_auc : 0.4870 | data_load_times : 37.49 | batch_run_times : 37.62\n",
      "[2022-09-12 19:06:39] 2105417623.py[  84] : INFO  0-13 | lr : 0.000796 | val_loss : 2.0879 | val_roc_auc : 0.5395 | data_load_times : 37.50 | batch_run_times : 37.63\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:07:09] 2105417623.py[  84] : INFO  0-14 | lr : 0.000658 | val_loss : 2.0477 | val_roc_auc : 0.5603 | data_load_times : 38.25 | batch_run_times : 38.39\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:07:40] 2105417623.py[  84] : INFO  0-15 | lr : 0.000505 | val_loss : 2.0336 | val_roc_auc : 0.6006 | data_load_times : 37.51 | batch_run_times : 37.62\n",
      "[2022-09-12 19:08:10] 2105417623.py[  84] : INFO  0-16 | lr : 0.000352 | val_loss : 2.0753 | val_roc_auc : 0.5410 | data_load_times : 40.14 | batch_run_times : 40.26\n",
      "[2022-09-12 19:08:41] 2105417623.py[  84] : INFO  0-17 | lr : 0.000214 | val_loss : 2.0658 | val_roc_auc : 0.5396 | data_load_times : 37.03 | batch_run_times : 37.16\n",
      "[2022-09-12 19:09:11] 2105417623.py[  84] : INFO  0-18 | lr : 0.000105 | val_loss : 2.0444 | val_roc_auc : 0.5579 | data_load_times : 39.71 | batch_run_times : 39.82\n",
      "[2022-09-12 19:09:41] 2105417623.py[  84] : INFO  0-19 | lr : 0.000034 | val_loss : 2.0506 | val_roc_auc : 0.5553 | data_load_times : 34.82 | batch_run_times : 34.93\n",
      "[2022-09-12 19:10:11] 2105417623.py[  84] : INFO  0-20 | lr : 0.001000 | val_loss : 2.0941 | val_roc_auc : 0.4994 | data_load_times : 36.30 | batch_run_times : 36.42\n",
      "[2022-09-12 19:10:42] 2105417623.py[  84] : INFO  0-21 | lr : 0.000976 | val_loss : 2.0517 | val_roc_auc : 0.5776 | data_load_times : 36.95 | batch_run_times : 37.07\n",
      "[2022-09-12 19:11:12] 2105417623.py[  84] : INFO  0-22 | lr : 0.000905 | val_loss : 2.0473 | val_roc_auc : 0.5541 | data_load_times : 38.27 | batch_run_times : 38.39\n",
      "[2022-09-12 19:11:43] 2105417623.py[  84] : INFO  0-23 | lr : 0.000796 | val_loss : 2.0828 | val_roc_auc : 0.5354 | data_load_times : 37.61 | batch_run_times : 37.74\n",
      "[2022-09-12 19:12:13] 2105417623.py[  84] : INFO  0-24 | lr : 0.000658 | val_loss : 2.0671 | val_roc_auc : 0.5580 | data_load_times : 39.42 | batch_run_times : 39.54\n",
      "[2022-09-12 19:12:43] 2105417623.py[  84] : INFO  0-25 | lr : 0.000505 | val_loss : 2.0278 | val_roc_auc : 0.6169 | data_load_times : 36.70 | batch_run_times : 36.81\n",
      "[2022-09-12 19:13:12] 2105417623.py[  84] : INFO  0-26 | lr : 0.000352 | val_loss : 2.0501 | val_roc_auc : 0.5206 | data_load_times : 34.30 | batch_run_times : 34.42\n",
      "[2022-09-12 19:13:43] 2105417623.py[  84] : INFO  0-27 | lr : 0.000214 | val_loss : 2.0077 | val_roc_auc : 0.6332 | data_load_times : 38.06 | batch_run_times : 38.17\n",
      "[2022-09-12 19:14:14] 2105417623.py[  84] : INFO  0-28 | lr : 0.000105 | val_loss : 1.9873 | val_roc_auc : 0.6408 | data_load_times : 39.18 | batch_run_times : 39.36\n",
      "[2022-09-12 19:14:44] 2105417623.py[  84] : INFO  0-29 | lr : 0.000034 | val_loss : 2.0154 | val_roc_auc : 0.5918 | data_load_times : 36.04 | batch_run_times : 36.18\n",
      "[2022-09-12 19:15:15] 2105417623.py[  84] : INFO  0-30 | lr : 0.001000 | val_loss : 2.0024 | val_roc_auc : 0.6585 | data_load_times : 42.50 | batch_run_times : 42.60\n",
      "[2022-09-12 19:15:45] 2105417623.py[  84] : INFO  0-31 | lr : 0.000976 | val_loss : 2.0395 | val_roc_auc : 0.5968 | data_load_times : 37.70 | batch_run_times : 37.81\n",
      "[2022-09-12 19:16:15] 2105417623.py[  84] : INFO  0-32 | lr : 0.000905 | val_loss : 2.0456 | val_roc_auc : 0.5651 | data_load_times : 35.14 | batch_run_times : 35.26\n",
      "[2022-09-12 19:16:45] 2105417623.py[  84] : INFO  0-33 | lr : 0.000796 | val_loss : 2.0495 | val_roc_auc : 0.5814 | data_load_times : 39.00 | batch_run_times : 39.18\n",
      "[2022-09-12 19:17:16] 2105417623.py[  84] : INFO  0-34 | lr : 0.000658 | val_loss : 2.0432 | val_roc_auc : 0.5641 | data_load_times : 36.14 | batch_run_times : 36.25\n",
      "[2022-09-12 19:17:47] 2105417623.py[  84] : INFO  0-35 | lr : 0.000505 | val_loss : 2.0652 | val_roc_auc : 0.5620 | data_load_times : 38.78 | batch_run_times : 38.91\n",
      "[2022-09-12 19:18:17] 2105417623.py[  84] : INFO  0-36 | lr : 0.000352 | val_loss : 2.0103 | val_roc_auc : 0.6076 | data_load_times : 36.43 | batch_run_times : 36.56\n",
      "[2022-09-12 19:18:47] 2105417623.py[  84] : INFO  0-37 | lr : 0.000214 | val_loss : 2.0368 | val_roc_auc : 0.6175 | data_load_times : 36.17 | batch_run_times : 36.30\n",
      "[2022-09-12 19:19:17] 2105417623.py[  84] : INFO  0-38 | lr : 0.000105 | val_loss : 2.0019 | val_roc_auc : 0.6150 | data_load_times : 39.18 | batch_run_times : 39.31\n",
      "[2022-09-12 19:19:48] 2105417623.py[  84] : INFO  0-39 | lr : 0.000034 | val_loss : 2.0078 | val_roc_auc : 0.6036 | data_load_times : 37.23 | batch_run_times : 37.35\n",
      "[2022-09-12 19:20:18] 2105417623.py[  84] : INFO  0-40 | lr : 0.001000 | val_loss : 2.0286 | val_roc_auc : 0.6077 | data_load_times : 37.55 | batch_run_times : 37.68\n",
      "[2022-09-12 19:20:48] 2105417623.py[  84] : INFO  0-41 | lr : 0.000976 | val_loss : 2.0132 | val_roc_auc : 0.6156 | data_load_times : 37.72 | batch_run_times : 37.85\n",
      "Epoch 00042: early stopping triggered.\n",
      "[2022-09-12 19:20:48] 3786432242.py[  25] : INFO  Fold 1 num train records: 128\n",
      "[2022-09-12 19:20:48] 3786432242.py[  26] : INFO  Fold 1 num val records: 64\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "[2022-09-12 19:21:19] 2105417623.py[  84] : INFO  1-0 | lr : 0.001000 | val_loss : 2.0580 | val_roc_auc : 0.5635 | data_load_times : 34.41 | batch_run_times : 34.52\n",
      "[2022-09-12 19:21:51] 2105417623.py[  84] : INFO  1-1 | lr : 0.000976 | val_loss : 2.0751 | val_roc_auc : 0.5802 | data_load_times : 37.72 | batch_run_times : 37.84\n",
      "[2022-09-12 19:22:23] 2105417623.py[  84] : INFO  1-2 | lr : 0.000905 | val_loss : 2.1278 | val_roc_auc : 0.4605 | data_load_times : 41.98 | batch_run_times : 42.10\n",
      "[2022-09-12 19:22:53] 2105417623.py[  84] : INFO  1-3 | lr : 0.000796 | val_loss : 2.0820 | val_roc_auc : 0.5118 | data_load_times : 36.78 | batch_run_times : 36.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-12 19:23:25] 2105417623.py[  84] : INFO  1-4 | lr : 0.000658 | val_loss : 2.0767 | val_roc_auc : 0.4904 | data_load_times : 38.54 | batch_run_times : 38.67\n",
      "[2022-09-12 19:23:57] 2105417623.py[  84] : INFO  1-5 | lr : 0.000505 | val_loss : 2.0494 | val_roc_auc : 0.5942 | data_load_times : 41.41 | batch_run_times : 41.53\n",
      "[2022-09-12 19:24:29] 2105417623.py[  84] : INFO  1-6 | lr : 0.000352 | val_loss : 2.0679 | val_roc_auc : 0.5385 | data_load_times : 36.22 | batch_run_times : 36.34\n",
      "[2022-09-12 19:25:01] 2105417623.py[  84] : INFO  1-7 | lr : 0.000214 | val_loss : 2.0396 | val_roc_auc : 0.5632 | data_load_times : 39.86 | batch_run_times : 39.98\n",
      "[2022-09-12 19:25:33] 2105417623.py[  84] : INFO  1-8 | lr : 0.000105 | val_loss : 2.1009 | val_roc_auc : 0.5120 | data_load_times : 41.21 | batch_run_times : 41.32\n",
      "[2022-09-12 19:26:04] 2105417623.py[  84] : INFO  1-9 | lr : 0.000034 | val_loss : 2.1045 | val_roc_auc : 0.4878 | data_load_times : 40.12 | batch_run_times : 40.23\n",
      "[2022-09-12 19:26:35] 2105417623.py[  84] : INFO  1-10 | lr : 0.001000 | val_loss : 2.0609 | val_roc_auc : 0.5637 | data_load_times : 39.25 | batch_run_times : 39.38\n",
      "[2022-09-12 19:27:06] 2105417623.py[  84] : INFO  1-11 | lr : 0.000976 | val_loss : 2.0677 | val_roc_auc : 0.5330 | data_load_times : 38.94 | batch_run_times : 39.06\n",
      "[2022-09-12 19:27:37] 2105417623.py[  84] : INFO  1-12 | lr : 0.000905 | val_loss : 2.0912 | val_roc_auc : 0.5498 | data_load_times : 34.70 | batch_run_times : 34.86\n",
      "[2022-09-12 19:28:09] 2105417623.py[  84] : INFO  1-13 | lr : 0.000796 | val_loss : 2.0675 | val_roc_auc : 0.5575 | data_load_times : 37.83 | batch_run_times : 37.95\n",
      "[2022-09-12 19:28:40] 2105417623.py[  84] : INFO  1-14 | lr : 0.000658 | val_loss : 2.0865 | val_roc_auc : 0.5358 | data_load_times : 37.79 | batch_run_times : 37.92\n",
      "[2022-09-12 19:29:11] 2105417623.py[  84] : INFO  1-15 | lr : 0.000505 | val_loss : 2.0998 | val_roc_auc : 0.5290 | data_load_times : 37.40 | batch_run_times : 37.52\n",
      "[2022-09-12 19:29:42] 2105417623.py[  84] : INFO  1-16 | lr : 0.000352 | val_loss : 2.0793 | val_roc_auc : 0.5596 | data_load_times : 37.83 | batch_run_times : 37.96\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:30:15] 2105417623.py[  84] : INFO  1-17 | lr : 0.000214 | val_loss : 2.0523 | val_roc_auc : 0.5727 | data_load_times : 38.71 | batch_run_times : 38.82\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:30:46] 2105417623.py[  84] : INFO  1-18 | lr : 0.000105 | val_loss : 2.0912 | val_roc_auc : 0.5407 | data_load_times : 40.59 | batch_run_times : 40.70\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:31:17] 2105417623.py[  84] : INFO  1-19 | lr : 0.000034 | val_loss : 2.0437 | val_roc_auc : 0.5900 | data_load_times : 38.30 | batch_run_times : 38.42\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:31:48] 2105417623.py[  84] : INFO  1-20 | lr : 0.001000 | val_loss : 2.0534 | val_roc_auc : 0.5836 | data_load_times : 39.56 | batch_run_times : 39.83\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:32:20] 2105417623.py[  84] : INFO  1-21 | lr : 0.000976 | val_loss : 2.0550 | val_roc_auc : 0.5643 | data_load_times : 36.15 | batch_run_times : 36.35\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:32:51] 2105417623.py[  84] : INFO  1-22 | lr : 0.000905 | val_loss : 2.1522 | val_roc_auc : 0.5567 | data_load_times : 37.50 | batch_run_times : 37.65\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:33:22] 2105417623.py[  84] : INFO  1-23 | lr : 0.000796 | val_loss : 2.0526 | val_roc_auc : 0.5979 | data_load_times : 37.46 | batch_run_times : 37.59\n",
      "[2022-09-12 19:33:53] 2105417623.py[  84] : INFO  1-24 | lr : 0.000658 | val_loss : 2.0466 | val_roc_auc : 0.5718 | data_load_times : 36.04 | batch_run_times : 36.16\n",
      "[2022-09-12 19:34:24] 2105417623.py[  84] : INFO  1-25 | lr : 0.000505 | val_loss : 1.9589 | val_roc_auc : 0.6186 | data_load_times : 39.82 | batch_run_times : 39.93\n",
      "[2022-09-12 19:34:56] 2105417623.py[  84] : INFO  1-26 | lr : 0.000352 | val_loss : 2.0467 | val_roc_auc : 0.5890 | data_load_times : 41.03 | batch_run_times : 41.14\n",
      "[2022-09-12 19:35:28] 2105417623.py[  84] : INFO  1-27 | lr : 0.000214 | val_loss : 2.0076 | val_roc_auc : 0.6260 | data_load_times : 41.22 | batch_run_times : 41.34\n",
      "[2022-09-12 19:36:00] 2105417623.py[  84] : INFO  1-28 | lr : 0.000105 | val_loss : 2.0148 | val_roc_auc : 0.6375 | data_load_times : 39.92 | batch_run_times : 40.15\n",
      "[2022-09-12 19:36:32] 2105417623.py[  84] : INFO  1-29 | lr : 0.000034 | val_loss : 2.0339 | val_roc_auc : 0.6278 | data_load_times : 39.01 | batch_run_times : 39.13\n",
      "[2022-09-12 19:37:03] 2105417623.py[  84] : INFO  1-30 | lr : 0.001000 | val_loss : 2.2212 | val_roc_auc : 0.4883 | data_load_times : 38.30 | batch_run_times : 38.43\n",
      "[2022-09-12 19:37:35] 2105417623.py[  84] : INFO  1-31 | lr : 0.000976 | val_loss : 2.0854 | val_roc_auc : 0.5406 | data_load_times : 42.30 | batch_run_times : 42.41\n",
      "[2022-09-12 19:38:06] 2105417623.py[  84] : INFO  1-32 | lr : 0.000905 | val_loss : 1.9773 | val_roc_auc : 0.6173 | data_load_times : 39.16 | batch_run_times : 39.29\n",
      "[2022-09-12 19:38:38] 2105417623.py[  84] : INFO  1-33 | lr : 0.000796 | val_loss : 2.1394 | val_roc_auc : 0.5659 | data_load_times : 36.61 | batch_run_times : 36.72\n",
      "[2022-09-12 19:39:08] 2105417623.py[  84] : INFO  1-34 | lr : 0.000658 | val_loss : 2.0005 | val_roc_auc : 0.5984 | data_load_times : 38.60 | batch_run_times : 38.72\n",
      "[2022-09-12 19:39:40] 2105417623.py[  84] : INFO  1-35 | lr : 0.000505 | val_loss : 2.0849 | val_roc_auc : 0.5899 | data_load_times : 37.26 | batch_run_times : 37.38\n",
      "[2022-09-12 19:40:11] 2105417623.py[  84] : INFO  1-36 | lr : 0.000352 | val_loss : 2.0602 | val_roc_auc : 0.6051 | data_load_times : 42.59 | batch_run_times : 42.73\n",
      "[2022-09-12 19:40:43] 2105417623.py[  84] : INFO  1-37 | lr : 0.000214 | val_loss : 2.1868 | val_roc_auc : 0.5340 | data_load_times : 39.21 | batch_run_times : 39.34\n",
      "[2022-09-12 19:41:13] 2105417623.py[  84] : INFO  1-38 | lr : 0.000105 | val_loss : 2.0400 | val_roc_auc : 0.5588 | data_load_times : 36.18 | batch_run_times : 36.30\n",
      "[2022-09-12 19:41:45] 2105417623.py[  84] : INFO  1-39 | lr : 0.000034 | val_loss : 2.0699 | val_roc_auc : 0.5857 | data_load_times : 37.09 | batch_run_times : 37.20\n",
      "Epoch 00040: early stopping triggered.\n",
      "[2022-09-12 19:41:45] 3786432242.py[  25] : INFO  Fold 2 num train records: 128\n",
      "[2022-09-12 19:41:45] 3786432242.py[  26] : INFO  Fold 2 num val records: 64\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "[2022-09-12 19:42:16] 2105417623.py[  84] : INFO  2-0 | lr : 0.001000 | val_loss : 2.0756 | val_roc_auc : 0.5838 | data_load_times : 38.50 | batch_run_times : 38.63\n",
      "[2022-09-12 19:42:48] 2105417623.py[  84] : INFO  2-1 | lr : 0.000976 | val_loss : 2.1061 | val_roc_auc : 0.5131 | data_load_times : 39.45 | batch_run_times : 39.62\n",
      "[2022-09-12 19:43:20] 2105417623.py[  84] : INFO  2-2 | lr : 0.000905 | val_loss : 2.0743 | val_roc_auc : 0.5684 | data_load_times : 38.00 | batch_run_times : 38.12\n",
      "[2022-09-12 19:43:52] 2105417623.py[  84] : INFO  2-3 | lr : 0.000796 | val_loss : 2.0623 | val_roc_auc : 0.5884 | data_load_times : 37.79 | batch_run_times : 37.90\n",
      "[2022-09-12 19:44:23] 2105417623.py[  84] : INFO  2-4 | lr : 0.000658 | val_loss : 2.0461 | val_roc_auc : 0.6019 | data_load_times : 38.05 | batch_run_times : 38.20\n",
      "[2022-09-12 19:44:56] 2105417623.py[  84] : INFO  2-5 | lr : 0.000505 | val_loss : 2.0494 | val_roc_auc : 0.5610 | data_load_times : 40.78 | batch_run_times : 40.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-12 19:45:27] 2105417623.py[  84] : INFO  2-6 | lr : 0.000352 | val_loss : 2.0675 | val_roc_auc : 0.5051 | data_load_times : 37.79 | batch_run_times : 37.91\n",
      "[2022-09-12 19:45:58] 2105417623.py[  84] : INFO  2-7 | lr : 0.000214 | val_loss : 2.0339 | val_roc_auc : 0.5937 | data_load_times : 39.65 | batch_run_times : 39.79\n",
      "[2022-09-12 19:46:31] 2105417623.py[  84] : INFO  2-8 | lr : 0.000105 | val_loss : 2.0724 | val_roc_auc : 0.5631 | data_load_times : 39.46 | batch_run_times : 39.56\n",
      "[2022-09-12 19:47:02] 2105417623.py[  84] : INFO  2-9 | lr : 0.000034 | val_loss : 2.0722 | val_roc_auc : 0.5399 | data_load_times : 34.92 | batch_run_times : 35.04\n",
      "[2022-09-12 19:47:32] 2105417623.py[  84] : INFO  2-10 | lr : 0.001000 | val_loss : 2.1230 | val_roc_auc : 0.5293 | data_load_times : 36.49 | batch_run_times : 36.62\n",
      "[2022-09-12 19:48:03] 2105417623.py[  84] : INFO  2-11 | lr : 0.000976 | val_loss : 2.0135 | val_roc_auc : 0.5865 | data_load_times : 36.94 | batch_run_times : 37.06\n",
      "[2022-09-12 19:48:35] 2105417623.py[  84] : INFO  2-12 | lr : 0.000905 | val_loss : 2.0434 | val_roc_auc : 0.6257 | data_load_times : 37.65 | batch_run_times : 37.79\n",
      "[2022-09-12 19:49:06] 2105417623.py[  84] : INFO  2-13 | lr : 0.000796 | val_loss : 2.0446 | val_roc_auc : 0.5656 | data_load_times : 37.47 | batch_run_times : 37.61\n",
      "[2022-09-12 19:49:37] 2105417623.py[  84] : INFO  2-14 | lr : 0.000658 | val_loss : 2.0413 | val_roc_auc : 0.5912 | data_load_times : 38.28 | batch_run_times : 38.42\n",
      "[2022-09-12 19:50:08] 2105417623.py[  84] : INFO  2-15 | lr : 0.000505 | val_loss : 2.0337 | val_roc_auc : 0.5600 | data_load_times : 35.73 | batch_run_times : 35.84\n",
      "[2022-09-12 19:50:40] 2105417623.py[  84] : INFO  2-16 | lr : 0.000352 | val_loss : 2.0074 | val_roc_auc : 0.6075 | data_load_times : 37.48 | batch_run_times : 37.61\n",
      "[2022-09-12 19:51:11] 2105417623.py[  84] : INFO  2-17 | lr : 0.000214 | val_loss : 2.0621 | val_roc_auc : 0.5399 | data_load_times : 39.91 | batch_run_times : 40.03\n",
      "[2022-09-12 19:51:42] 2105417623.py[  84] : INFO  2-18 | lr : 0.000105 | val_loss : 2.0978 | val_roc_auc : 0.5164 | data_load_times : 41.02 | batch_run_times : 41.14\n",
      "[2022-09-12 19:52:14] 2105417623.py[  84] : INFO  2-19 | lr : 0.000034 | val_loss : 2.0407 | val_roc_auc : 0.5633 | data_load_times : 38.22 | batch_run_times : 38.34\n",
      "[2022-09-12 19:52:45] 2105417623.py[  84] : INFO  2-20 | lr : 0.001000 | val_loss : 2.0154 | val_roc_auc : 0.5852 | data_load_times : 40.35 | batch_run_times : 40.47\n",
      "[2022-09-12 19:53:16] 2105417623.py[  84] : INFO  2-21 | lr : 0.000976 | val_loss : 2.0650 | val_roc_auc : 0.5555 | data_load_times : 39.41 | batch_run_times : 39.53\n",
      "[2022-09-12 19:53:47] 2105417623.py[  84] : INFO  2-22 | lr : 0.000905 | val_loss : 2.0791 | val_roc_auc : 0.5695 | data_load_times : 37.34 | batch_run_times : 37.46\n",
      "[2022-09-12 19:54:17] 2105417623.py[  84] : INFO  2-23 | lr : 0.000796 | val_loss : 2.0598 | val_roc_auc : 0.5490 | data_load_times : 39.34 | batch_run_times : 39.48\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:54:48] 2105417623.py[  84] : INFO  2-24 | lr : 0.000658 | val_loss : 2.0889 | val_roc_auc : 0.5263 | data_load_times : 37.61 | batch_run_times : 37.72\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:55:20] 2105417623.py[  84] : INFO  2-25 | lr : 0.000505 | val_loss : 2.0675 | val_roc_auc : 0.5576 | data_load_times : 38.90 | batch_run_times : 39.02\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:55:51] 2105417623.py[  84] : INFO  2-26 | lr : 0.000352 | val_loss : 2.0701 | val_roc_auc : 0.5501 | data_load_times : 40.35 | batch_run_times : 40.47\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:56:22] 2105417623.py[  84] : INFO  2-27 | lr : 0.000214 | val_loss : 2.0780 | val_roc_auc : 0.5466 | data_load_times : 39.74 | batch_run_times : 39.87\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:56:54] 2105417623.py[  84] : INFO  2-28 | lr : 0.000105 | val_loss : 2.0436 | val_roc_auc : 0.5836 | data_load_times : 40.65 | batch_run_times : 40.76\n",
      "Trainer was signaled to stop but required minimum epochs (30) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-09-12 19:57:25] 2105417623.py[  84] : INFO  2-29 | lr : 0.000034 | val_loss : 2.0839 | val_roc_auc : 0.5539 | data_load_times : 37.60 | batch_run_times : 37.71\n",
      "Epoch 00030: early stopping triggered.\n",
      "[2022-09-12 19:57:25] 3786432242.py[ 122] : INFO  Best scores: [0.658525308299157, 0.6375331528394851, 0.6257034780369484]\n",
      "[2022-09-12 19:57:25] 3786432242.py[ 123] : INFO  Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialise hyperparameters\n",
    "hparams = init_hparams()\n",
    "# Initialise logger\n",
    "logger = init_logger(hparams.log_name, hparams.log_dir)\n",
    "\n",
    "# Create transform pipeline\n",
    "transforms = generate_transforms(hparams.image_size)\n",
    "\n",
    "# List for validation scores \n",
    "valid_roc_auc_scores = []\n",
    "\n",
    "# Initialise cross validation\n",
    "folds = StratifiedKFold(n_splits=hparams.n_splits, shuffle=True, random_state=hparams.seed)\n",
    "\n",
    "# Start cross validation\n",
    "for fold_i, (train_index, val_index) in enumerate(folds.split(metadata[[\"img_path\"]], metadata[[\"label\"]])):\n",
    "    hparams.fold_i = fold_i\n",
    "    # Split train images and validation sets\n",
    "    train_data = metadata.iloc[train_index][[\"img_path\", \"label\"]].reset_index(drop=True)\n",
    "    train_data = pd.get_dummies(train_data, columns=[\"label\"], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "    val_data = metadata.iloc[val_index][[\"img_path\", \"label\"]].reset_index(drop=True)\n",
    "    val_data = pd.get_dummies(val_data, columns=[\"label\"], prefix=\"\", prefix_sep=\"\")\n",
    "    \n",
    "    logger.info(f\"Fold {fold_i} num train records: {train_data.shape[0]}\")\n",
    "    logger.info(f\"Fold {fold_i} num val records: {val_data.shape[0]}\")\n",
    "    \n",
    "    train_dataloader, val_dataloader = generate_dataloaders(hparams, train_data, val_data, transforms)\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_roc_auc\",\n",
    "        save_top_k=2,\n",
    "        mode=\"max\",\n",
    "        filepath=os.path.join(\n",
    "            hparams.log_dir, \n",
    "            hparams.log_name, \n",
    "            f\"fold={fold_i}\" + \"-{epoch}-{val_loss:.4f}-{val_roc_auc:.4f}\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor=\"val_roc_auc\", \n",
    "        patience=hparams.patience, \n",
    "        mode=\"max\", \n",
    "        verbose=hparams.verbose\n",
    "    )\n",
    "    \n",
    "    # Instance Model, Trainer and train model\n",
    "    model = CoolSystem(hparams)\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=hparams.gpus,\n",
    "        min_epochs=hparams.min_epochs,\n",
    "        max_epochs=hparams.max_epochs,\n",
    "        early_stop_callback=early_stop_callback,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        progress_bar_refresh_rate=0,\n",
    "        precision=hparams.precision,\n",
    "        num_sanity_val_steps=0,\n",
    "        profiler=False,\n",
    "        weights_summary=None,\n",
    "        gradient_clip_val=hparams.gradient_clip_val,\n",
    "        default_root_dir=os.path.join(hparams.log_dir, hparams.log_name)\n",
    "    )\n",
    "    \n",
    "    # Fit model\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "        \n",
    "    # Generate model output for validation \n",
    "    #preds = model(\n",
    "    #    torch.from_numpy(X_train[val_index]).permute(0, 3, 1, 2).float()\n",
    "    #)\n",
    "#\n",
    "    ## Create activation output\n",
    "    #log_softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "#\n",
    "    ## Convert raw output to probabilities\n",
    "    #preds = np.exp(log_softmax(preds).detach().numpy())\n",
    "#\n",
    "    ## Create df with img paths and predicted label probs\n",
    "    #scores_df = pd.DataFrame(preds, columns=val_data.columns[1:])\n",
    "    #scores_df = pd.merge(\n",
    "    #    metadata.iloc[val_index, 1:3].reset_index(drop=True),\n",
    "    #    scores_df, \n",
    "    #    left_index=True,\n",
    "    #    right_index=True\n",
    "    #)\n",
    "    ## Write predictions to log\n",
    "    #scores_df.to_csv(\n",
    "    #    os.path.join(hparams.log_dir, hparams.log_name, f\"{hparams.log_name}_preds_fold_{fold_i}.csv\"),\n",
    "    #    index=False\n",
    "    #)\n",
    "    \n",
    "    # Save val scores\n",
    "    valid_roc_auc_scores.append(checkpoint_callback.best)\n",
    "    \n",
    "    # Cleanup\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "valid_roc_auc_scores = [i.item() for i in valid_roc_auc_scores]\n",
    "\n",
    "# Add val scores to csv with all scores\n",
    "if os.path.isfile(\"../logs/scores.csv\") == False:\n",
    "    pd.DataFrame(columns=[\"name\", \"scores\", \"mean_score\"]).to_csv(\"../logs/scores.csv\", index=False)\n",
    "    \n",
    "# Append to current scores csv\n",
    "all_scores_df = pd.concat([\n",
    "    pd.read_csv(\"../logs/scores.csv\"),\n",
    "    pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"name\": [hparams.log_name],\n",
    "            \"scores\": [valid_roc_auc_scores],\n",
    "            \"mean_score\": [np.mean(valid_roc_auc_scores)]\n",
    "        }\n",
    "    )],\n",
    "    ignore_index=True\n",
    ")\n",
    "# Write all scores df to csv\n",
    "all_scores_df.to_csv(\"../logs/scores.csv\", index=False)\n",
    "\n",
    "logger.info(f\"Best scores: {valid_roc_auc_scores}\")\n",
    "logger.info(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f58ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b82c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc5c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99894102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b516d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a64dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909149b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491e3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e8882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7feb0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b645a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biteme",
   "language": "python",
   "name": "biteme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
