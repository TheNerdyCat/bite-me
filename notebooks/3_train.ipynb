{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef0d2692",
   "metadata": {},
   "source": [
    "# BiteMe | Train\n",
    "\n",
    "This notebook includes the most important part of the project - the modelling. The notebook tests methodologies for training, and in it the chosen algorithm is decided. Validation also occurs before final testing, which is conducted in the test notebook. This stage is highly iterative, so all model artefacts, logs and configurations are recorded and saved to disk automatically. This initial setup of what will eventually become MLOps for the final product will be really useful, and helps keep track of what is successful and what isn't.\n",
    "\n",
    "Models to try:\n",
    "\n",
    "~~[SE-ResNet50](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[SE-ResNet101](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[SE-ResNet152](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[SENet154](https://github.com/Cadene/pretrained-models.pytorch#senet)~~\n",
    "~~[ResNet34](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[ResNet50](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[ResNet101](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[ResNet152](https://github.com/Cadene/pretrained-models.pytorch#torchvision)~~\n",
    "~~[FBResNet152](https://github.com/Cadene/pretrained-models.pytorch#facebook-resnet)~~\n",
    "~~[PolyNet](https://github.com/Cadene/pretrained-models.pytorch#polynet)~~\n",
    "~~[InceptionV4](https://github.com/Cadene/pretrained-models.pytorch#inception)~~\n",
    "~~[BNInception](https://github.com/Cadene/pretrained-models.pytorch#bninception)~~\n",
    "~~[InceptionResNetV2](https://github.com/Cadene/pretrained-models.pytorch#inception)~~\n",
    "~~[Xception](https://github.com/Cadene/pretrained-models.pytorch#xception)~~\n",
    " - [ResNeXt101_32x4d](https://github.com/Cadene/pretrained-models.pytorch#resnext)\n",
    " - [ResNeXt101_64x4d](https://github.com/Cadene/pretrained-models.pytorch#resnext)\n",
    " - [SE-ResNeXt50_32x4d](https://github.com/Cadene/pretrained-models.pytorch#senet)\n",
    " - [SE-ResNeXt101_32x4d](https://github.com/Cadene/pretrained-models.pytorch#senet)\n",
    " - [DenseNet121](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet161](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet169](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DenseNet201](https://github.com/Cadene/pretrained-models.pytorch#torchvision)\n",
    " - [DualPathNet68](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet92](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet98](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet107](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    " - [DualPathNet131](https://github.com/Cadene/pretrained-models.pytorch#dualpathnetworks)\n",
    "\n",
    "\n",
    " - efficientnet_b0\n",
    " - efficientnet_b1\n",
    " - efficientnet_b2\n",
    " - efficientnet_b3\n",
    " - efficientnet_b4\n",
    " - efficientnet_b5\n",
    "\n",
    "Initial model work is done by using simple, typical image recognition models (CNN architectures) to see how effective these models can be for the problem. Although I don't expect them to be particularly successful, it's important to establish baselines and take a holistic approach to modelling when it's possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be8b5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from argparse import ArgumentParser\n",
    "import datetime\n",
    "from time import time\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "import torch\n",
    "import pretrainedmodels\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Local imports\n",
    "sys.path.append(\"..\")\n",
    "from utils.dataset import generate_transforms, generate_dataloaders\n",
    "from models.models import *\n",
    "from utils.loss_function import CrossEntropyLossOneHot\n",
    "from utils.lrs_scheduler import WarmRestart, warm_restart\n",
    "from utils.utils import read_images, augs, get_augs, seed_reproducer, init_logger\n",
    "from utils.constants import *\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a79a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7059b14d2aa03ed6c4de11afa32591995181d31c.jpg</td>\n",
       "      <td>../data/cleaned/none/7059b14d2aa03ed6c4de11afa...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea1b100b581fcdb7ddfae52cc62347a99e304ba4.jpg</td>\n",
       "      <td>../data/cleaned/none/ea1b100b581fcdb7ddfae52cc...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6eac051b9c45ff6821ec8675216f371711b7cea9.jpg</td>\n",
       "      <td>../data/cleaned/none/6eac051b9c45ff6821ec86752...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fc72767f8520df9b2b83941077dc0ee013eb9399.jpg</td>\n",
       "      <td>../data/cleaned/none/fc72767f8520df9b2b8394107...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49850884a00703afe5aab78c3ce074d2d4acae30.jpg</td>\n",
       "      <td>../data/cleaned/none/49850884a00703afe5aab78c3...</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       img_name  \\\n",
       "0  7059b14d2aa03ed6c4de11afa32591995181d31c.jpg   \n",
       "1  ea1b100b581fcdb7ddfae52cc62347a99e304ba4.jpg   \n",
       "2  6eac051b9c45ff6821ec8675216f371711b7cea9.jpg   \n",
       "3  fc72767f8520df9b2b83941077dc0ee013eb9399.jpg   \n",
       "4  49850884a00703afe5aab78c3ce074d2d4acae30.jpg   \n",
       "\n",
       "                                            img_path label  split  \n",
       "0  ../data/cleaned/none/7059b14d2aa03ed6c4de11afa...  none  train  \n",
       "1  ../data/cleaned/none/ea1b100b581fcdb7ddfae52cc...  none  train  \n",
       "2  ../data/cleaned/none/6eac051b9c45ff6821ec86752...  none  train  \n",
       "3  ../data/cleaned/none/fc72767f8520df9b2b8394107...  none  train  \n",
       "4  ../data/cleaned/none/49850884a00703afe5aab78c3...  none  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define directories\n",
    "base_dir_path = \"../\"\n",
    "\n",
    "data_dir_path = os.path.join(base_dir_path, \"data\")\n",
    "data_preprocessed_dir_path = os.path.join(data_dir_path, \"preprocessed\")\n",
    "data_preprocessed_train_dir_path = os.path.join(data_dir_path, \"preprocessed/train\")\n",
    "\n",
    "data_dir = os.listdir(data_dir_path)\n",
    "data_preprocessed_dir = os.listdir(data_preprocessed_dir_path)\n",
    "data_preprocessed_train_dir = os.listdir(data_preprocessed_train_dir_path)\n",
    "\n",
    "metadata_preprocessed_path = os.path.join(data_preprocessed_dir_path, \"metadata.csv\")\n",
    "metadata = pd.read_csv(metadata_preprocessed_path)\n",
    "# Subset to train only\n",
    "metadata = metadata.loc[metadata.split == \"train\"]\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4dde582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from: ../data/preprocessed/train\n",
      "Rows set to 1024\n",
      "Columns set to 1024\n",
      "Channels set to 3\n",
      "Writing images is set to: False\n",
      "Reading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 48.00it/s]\n",
      "100%|███████████████████████████████████████████| 55/55 [00:02<00:00, 20.58it/s]\n",
      "100%|███████████████████████████████████████████| 21/21 [00:01<00:00, 13.34it/s]\n",
      "100%|███████████████████████████████████████████| 46/46 [00:04<00:00, 10.33it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  8.24it/s]\n",
      "100%|███████████████████████████████████████████| 21/21 [00:02<00:00,  7.29it/s]\n",
      "100%|███████████████████████████████████████████| 58/58 [00:09<00:00,  6.12it/s]\n",
      "100%|███████████████████████████████████████████| 46/46 [00:09<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image reading complete.\n",
      "Image array shape: (299, 1024, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read in train images\n",
    "X_train = read_images(\n",
    "    data_dir_path=data_preprocessed_train_dir_path, \n",
    "    rows=ROWS, \n",
    "    cols=COLS, \n",
    "    channels=CHANNELS, \n",
    "    write_images=False, \n",
    "    output_data_dir_path=None,\n",
    "    verbose=VERBOSE\n",
    ")\n",
    "\n",
    "# Get labels\n",
    "y_train = np.array(pd.get_dummies(metadata[\"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9eb1b2",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac202af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose augmentations to use in preprocessing\n",
    "# For full list see helpers.py\n",
    "#augs_to_select = [\n",
    "#    \"Resize\",\n",
    "#    \"HorizontalFlip\", \n",
    "#    \"VerticalFlip\",\n",
    "#    \"Normalize\"\n",
    "#]\n",
    "## Subset augs based on those selected\n",
    "#AUGS = dict((aug_name, augs[aug_name]) for aug_name in augs_to_select)\n",
    "\n",
    "\n",
    "def init_hparams():\n",
    "    \"\"\"\n",
    "    Initialise hyperparameters for modelling.\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    hparams : argparse.Namespace\n",
    "        Parsed hyperparameters\n",
    "    \"\"\"\n",
    "    parser = ArgumentParser(add_help=False)\n",
    "    parser.add_argument(\"-backbone\", \"--backbone\", type=str, default=MODEL_NAME)\n",
    "    parser.add_argument(\"-device_name\", type=str, default=DEVICE_NAME)\n",
    "    parser.add_argument(\"--gpus\", default=[0])\n",
    "    parser.add_argument(\"--n_workers\", type=int, default=N_WORKERS)\n",
    "    parser.add_argument(\"--image_size\", nargs=\"+\", default=[ROWS, COLS])\n",
    "    parser.add_argument(\"--seed\", type=int, default=SEED)\n",
    "    parser.add_argument(\"--min_epochs\", type=int, default=MIN_EPOCHS)\n",
    "    parser.add_argument(\"--max_epochs\", type=int, default=MAX_EPOCHS)\n",
    "    parser.add_argument(\"--patience\", type=str, default=PATIENCE)    \n",
    "    parser.add_argument(\"-tbs\", \"--train_batch_size\", type=int, default=TRAIN_BATCH_SIZE)\n",
    "    parser.add_argument(\"-vbs\", \"--val_batch_size\", type=int, default=VAL_BATCH_SIZE)\n",
    "    parser.add_argument(\"--n_splits\", type=int, default=N_SPLITS)\n",
    "    parser.add_argument(\"--test_size\", type=float, default=TEST_SIZE)\n",
    "    parser.add_argument(\"--lr\", type=float, default=LEARNING_RATE)\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=WEIGHT_DECAY)\n",
    "    parser.add_argument(\"--epsilon\", type=float, default=EPSILON)\n",
    "    parser.add_argument(\"--amsgrad\", type=bool, default=AMSGRAD)\n",
    "    parser.add_argument(\"--betas\", default=BETAS)\n",
    "    parser.add_argument(\"--eta_min\", type=float, default=ETA_MIN)\n",
    "    parser.add_argument(\"--precision\", type=int, default=PRECISION)\n",
    "    parser.add_argument(\"--gradient_clip_val\", type=float, default=GRADIENT_CLIP_VAL)\n",
    "    parser.add_argument(\"--verbose\", type=str, default=VERBOSE)\n",
    "    parser.add_argument(\"--log_dir\", type=str, default=LOG_DIR)\n",
    "    parser.add_argument(\"--log_name\", type=str, default=LOG_NAME)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        hparams, unknown = parser.parse_known_args()\n",
    "    except:\n",
    "        hparams, unknown = parser.parse_args([])\n",
    "\n",
    "    if len(hparams.gpus) == 1:\n",
    "        hparams.gpus = [int(hparams.gpus[0])]\n",
    "    else:\n",
    "        hparams.gpus = [int(gpu) for gpu in hparams.gpus]\n",
    "\n",
    "    hparams.image_size = [int(size) for size in hparams.image_size]\n",
    "    \n",
    "    return hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca739edd",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b5b9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoolSystem(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "\n",
    "        seed_reproducer(self.hparams.seed)\n",
    "\n",
    "        self.model = resnext101_32x4d()\n",
    "        self.criterion = CrossEntropyLossOneHot()\n",
    "        self.logger_kun = init_logger(\n",
    "            hparams.log_name, \n",
    "            hparams.log_dir\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.parameters(), \n",
    "            lr=self.hparams.lr, \n",
    "            betas=self.hparams.betas, \n",
    "            eps=self.hparams.epsilon, \n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "            amsgrad=self.hparams.amsgrad\n",
    "        )\n",
    "        self.scheduler = WarmRestart(\n",
    "            self.optimizer, \n",
    "            T_max=15, \n",
    "            T_mult=3, \n",
    "            eta_min=self.hparams.eta_min\n",
    "        )\n",
    "        return [self.optimizer], [self.scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        step_start_time = time()\n",
    "        images, labels, data_load_time = batch\n",
    "\n",
    "        scores = self(images)\n",
    "        loss = self.criterion(scores, labels)\n",
    "\n",
    "        data_load_time = torch.sum(data_load_time)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"data_load_time\": data_load_time,\n",
    "            \"batch_run_time\": torch.Tensor([time() - step_start_time + data_load_time]).to(\n",
    "                data_load_time.device\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        # outputs is the return of training_step\n",
    "        train_loss_mean = torch.stack([output[\"loss\"] for output in outputs]).mean()\n",
    "        self.data_load_times = torch.stack([output[\"data_load_time\"] for output in outputs]).sum()\n",
    "        self.batch_run_times = torch.stack([output[\"batch_run_time\"] for output in outputs]).sum()\n",
    "\n",
    "        self.current_epoch += 1\n",
    "        if self.current_epoch < (self.trainer.max_epochs - 4):\n",
    "            self.scheduler = warm_restart(self.scheduler, T_mult=2)\n",
    "\n",
    "        return {\"train_loss\": train_loss_mean}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        step_start_time = time()\n",
    "        images, labels, data_load_time = batch\n",
    "        data_load_time = torch.sum(data_load_time)\n",
    "        scores = self(images)\n",
    "        loss = self.criterion(scores, labels)\n",
    "\n",
    "        # must return key -> val_loss\n",
    "        return {\n",
    "            \"val_loss\": loss,\n",
    "            \"scores\": scores,\n",
    "            \"labels\": labels,\n",
    "            \"data_load_time\": data_load_time,\n",
    "            \"batch_run_time\": torch.Tensor([time() - step_start_time + data_load_time]).to(\n",
    "                data_load_time.device\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # compute loss\n",
    "        val_loss_mean = torch.stack([output[\"val_loss\"] for output in outputs]).mean()\n",
    "        self.data_load_times = torch.stack([output[\"data_load_time\"] for output in outputs]).sum()\n",
    "        self.batch_run_times = torch.stack([output[\"batch_run_time\"] for output in outputs]).sum()\n",
    "\n",
    "        # compute roc_auc\n",
    "        scores_all = torch.cat([output[\"scores\"] for output in outputs]).cpu()\n",
    "        labels_all = torch.round(torch.cat([output[\"labels\"] for output in outputs]).cpu())\n",
    "\n",
    "        val_roc_auc = torch.tensor(roc_auc_score(labels_all, scores_all))\n",
    "\n",
    "        # terminal logs\n",
    "        self.logger_kun.info(\n",
    "            f\"{self.hparams.fold_i}-{self.current_epoch} | \"\n",
    "            f\"lr : {self.scheduler.get_lr()[0]:.6f} | \"\n",
    "            f\"val_loss : {val_loss_mean:.4f} | \"\n",
    "            f\"val_roc_auc : {val_roc_auc:.4f} | \"\n",
    "            f\"data_load_times : {self.data_load_times:.2f} | \"\n",
    "            f\"batch_run_times : {self.batch_run_times:.2f}\"\n",
    "        )\n",
    "\n",
    "        return {\"val_loss\": val_loss_mean, \"val_roc_auc\": val_roc_auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd3fde",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c68f6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-04 17:38:04] 128199480.py[  11] : INFO  backbone: resnext101_32x4d\n",
      "[2022-12-04 17:38:04] 128199480.py[  12] : INFO  device_name: NVIDIA GeForce RTX 3090\n",
      "[2022-12-04 17:38:04] 128199480.py[  13] : INFO  gpus: [0]\n",
      "[2022-12-04 17:38:04] 128199480.py[  14] : INFO  n_workers: 128\n",
      "[2022-12-04 17:38:04] 128199480.py[  15] : INFO  image_size: [1024, 1024]\n",
      "[2022-12-04 17:38:04] 128199480.py[  16] : INFO  seed: 14\n",
      "[2022-12-04 17:38:04] 128199480.py[  17] : INFO  min_epochs: 75\n",
      "[2022-12-04 17:38:04] 128199480.py[  18] : INFO  max_epochs: 100\n",
      "[2022-12-04 17:38:04] 128199480.py[  19] : INFO  patience: 11\n",
      "[2022-12-04 17:38:04] 128199480.py[  20] : INFO  train_batch_size: 4\n",
      "[2022-12-04 17:38:04] 128199480.py[  21] : INFO  val_batch_size: 4\n",
      "[2022-12-04 17:38:04] 128199480.py[  22] : INFO  n_splits: 3\n",
      "[2022-12-04 17:38:04] 128199480.py[  23] : INFO  test_size: 0.1\n",
      "[2022-12-04 17:38:04] 128199480.py[  24] : INFO  learning rate: 0.0001\n",
      "[2022-12-04 17:38:04] 128199480.py[  25] : INFO  weight_decay: 0\n",
      "[2022-12-04 17:38:04] 128199480.py[  26] : INFO  epsilon: 1e-08\n",
      "[2022-12-04 17:38:04] 128199480.py[  27] : INFO  amsgrad: True\n",
      "[2022-12-04 17:38:04] 128199480.py[  28] : INFO  betas: (0.9, 0.999)\n",
      "[2022-12-04 17:38:04] 128199480.py[  29] : INFO  precision: 16\n",
      "[2022-12-04 17:38:04] 128199480.py[  30] : INFO  gradient_clip_val: 1.0\n",
      "[2022-12-04 17:38:04] 128199480.py[  31] : INFO  eta_min: 5e-06\n",
      "[2022-12-04 17:38:04] 128199480.py[  32] : INFO  log_dir: ../logs/logs\n",
      "[2022-12-04 17:38:04] 128199480.py[  33] : INFO  log_name: 2022_12_04_17:37:29\n",
      "[2022-12-04 17:38:04] 128199480.py[  37] : INFO  Notes: patience/min_epochs/max_epochs decreased to 11/75/100, amsgrad changed to true\n",
      "[2022-12-04 17:38:04] 128199480.py[  59] : INFO  Fold 0 num train records: 199\n",
      "[2022-12-04 17:38:04] 128199480.py[  60] : INFO  Fold 0 num val records: 100\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "[2022-12-04 17:38:49] 2786500167.py[  95] : INFO  0-0 | lr : 0.000100 | val_loss : 2.0422 | val_roc_auc : 0.7166 | data_load_times : 44.67 | batch_run_times : 45.03\n",
      "[2022-12-04 17:39:32] 2786500167.py[  95] : INFO  0-1 | lr : 0.000099 | val_loss : 2.0075 | val_roc_auc : 0.7454 | data_load_times : 46.34 | batch_run_times : 46.72\n",
      "[2022-12-04 17:40:15] 2786500167.py[  95] : INFO  0-2 | lr : 0.000096 | val_loss : 1.9372 | val_roc_auc : 0.7787 | data_load_times : 47.75 | batch_run_times : 48.13\n",
      "[2022-12-04 17:40:59] 2786500167.py[  95] : INFO  0-3 | lr : 0.000091 | val_loss : 1.9109 | val_roc_auc : 0.7855 | data_load_times : 46.07 | batch_run_times : 46.45\n",
      "[2022-12-04 17:41:42] 2786500167.py[  95] : INFO  0-4 | lr : 0.000084 | val_loss : 1.8589 | val_roc_auc : 0.8064 | data_load_times : 44.49 | batch_run_times : 44.96\n",
      "[2022-12-04 17:42:26] 2786500167.py[  95] : INFO  0-5 | lr : 0.000076 | val_loss : 1.8935 | val_roc_auc : 0.7623 | data_load_times : 43.88 | batch_run_times : 44.27\n",
      "[2022-12-04 17:43:09] 2786500167.py[  95] : INFO  0-6 | lr : 0.000067 | val_loss : 1.8326 | val_roc_auc : 0.7842 | data_load_times : 44.97 | batch_run_times : 45.35\n",
      "[2022-12-04 17:43:53] 2786500167.py[  95] : INFO  0-7 | lr : 0.000057 | val_loss : 1.7908 | val_roc_auc : 0.7938 | data_load_times : 44.78 | batch_run_times : 45.17\n",
      "[2022-12-04 17:44:37] 2786500167.py[  95] : INFO  0-8 | lr : 0.000048 | val_loss : 1.7431 | val_roc_auc : 0.8285 | data_load_times : 46.18 | batch_run_times : 46.55\n",
      "[2022-12-04 17:45:20] 2786500167.py[  95] : INFO  0-9 | lr : 0.000038 | val_loss : 1.7063 | val_roc_auc : 0.8407 | data_load_times : 46.72 | batch_run_times : 47.12\n",
      "[2022-12-04 17:46:04] 2786500167.py[  95] : INFO  0-10 | lr : 0.000029 | val_loss : 1.7222 | val_roc_auc : 0.8292 | data_load_times : 44.92 | batch_run_times : 45.30\n",
      "[2022-12-04 17:46:48] 2786500167.py[  95] : INFO  0-11 | lr : 0.000021 | val_loss : 1.7072 | val_roc_auc : 0.8358 | data_load_times : 46.10 | batch_run_times : 46.49\n",
      "[2022-12-04 17:47:32] 2786500167.py[  95] : INFO  0-12 | lr : 0.000014 | val_loss : 1.6945 | val_roc_auc : 0.8329 | data_load_times : 46.12 | batch_run_times : 46.51\n",
      "[2022-12-04 17:48:15] 2786500167.py[  95] : INFO  0-13 | lr : 0.000009 | val_loss : 1.6841 | val_roc_auc : 0.8309 | data_load_times : 45.61 | batch_run_times : 45.99\n",
      "[2022-12-04 17:48:59] 2786500167.py[  95] : INFO  0-14 | lr : 0.000006 | val_loss : 1.6985 | val_roc_auc : 0.8264 | data_load_times : 46.81 | batch_run_times : 47.19\n",
      "[2022-12-04 17:49:42] 2786500167.py[  95] : INFO  0-15 | lr : 0.000100 | val_loss : 1.6803 | val_roc_auc : 0.8264 | data_load_times : 43.74 | batch_run_times : 44.16\n",
      "[2022-12-04 17:50:26] 2786500167.py[  95] : INFO  0-16 | lr : 0.000100 | val_loss : 1.7670 | val_roc_auc : 0.7715 | data_load_times : 47.82 | batch_run_times : 48.30\n",
      "[2022-12-04 17:51:09] 2786500167.py[  95] : INFO  0-17 | lr : 0.000100 | val_loss : 1.7180 | val_roc_auc : 0.7897 | data_load_times : 46.17 | batch_run_times : 46.57\n",
      "[2022-12-04 17:51:52] 2786500167.py[  95] : INFO  0-18 | lr : 0.000099 | val_loss : 1.7054 | val_roc_auc : 0.7974 | data_load_times : 44.77 | batch_run_times : 45.23\n",
      "[2022-12-04 17:52:34] 2786500167.py[  95] : INFO  0-19 | lr : 0.000098 | val_loss : 1.6647 | val_roc_auc : 0.8066 | data_load_times : 47.81 | batch_run_times : 48.21\n",
      "[2022-12-04 17:53:18] 2786500167.py[  95] : INFO  0-20 | lr : 0.000097 | val_loss : 1.6551 | val_roc_auc : 0.7942 | data_load_times : 45.45 | batch_run_times : 45.84\n",
      "[2022-12-04 17:54:01] 2786500167.py[  95] : INFO  0-21 | lr : 0.000096 | val_loss : 1.7180 | val_roc_auc : 0.7754 | data_load_times : 46.23 | batch_run_times : 46.63\n",
      "[2022-12-04 17:54:44] 2786500167.py[  95] : INFO  0-22 | lr : 0.000094 | val_loss : 1.5802 | val_roc_auc : 0.8343 | data_load_times : 46.05 | batch_run_times : 46.51\n",
      "[2022-12-04 17:55:28] 2786500167.py[  95] : INFO  0-23 | lr : 0.000093 | val_loss : 1.6030 | val_roc_auc : 0.8140 | data_load_times : 45.88 | batch_run_times : 46.27\n",
      "[2022-12-04 17:56:11] 2786500167.py[  95] : INFO  0-24 | lr : 0.000091 | val_loss : 1.6724 | val_roc_auc : 0.7705 | data_load_times : 46.14 | batch_run_times : 46.58\n",
      "[2022-12-04 17:56:54] 2786500167.py[  95] : INFO  0-25 | lr : 0.000089 | val_loss : 1.5928 | val_roc_auc : 0.8011 | data_load_times : 45.78 | batch_run_times : 46.15\n",
      "[2022-12-04 17:57:38] 2786500167.py[  95] : INFO  0-26 | lr : 0.000087 | val_loss : 1.5371 | val_roc_auc : 0.8043 | data_load_times : 46.64 | batch_run_times : 47.05\n",
      "[2022-12-04 17:58:21] 2786500167.py[  95] : INFO  0-27 | lr : 0.000084 | val_loss : 1.5000 | val_roc_auc : 0.8330 | data_load_times : 45.21 | batch_run_times : 45.60\n",
      "[2022-12-04 17:59:06] 2786500167.py[  95] : INFO  0-28 | lr : 0.000082 | val_loss : 1.5551 | val_roc_auc : 0.8125 | data_load_times : 46.16 | batch_run_times : 46.54\n",
      "[2022-12-04 17:59:48] 2786500167.py[  95] : INFO  0-29 | lr : 0.000079 | val_loss : 1.5056 | val_roc_auc : 0.8217 | data_load_times : 46.56 | batch_run_times : 46.94\n",
      "[2022-12-04 18:00:32] 2786500167.py[  95] : INFO  0-30 | lr : 0.000076 | val_loss : 1.5054 | val_roc_auc : 0.8315 | data_load_times : 44.73 | batch_run_times : 45.10\n",
      "[2022-12-04 18:01:16] 2786500167.py[  95] : INFO  0-31 | lr : 0.000073 | val_loss : 1.5171 | val_roc_auc : 0.8296 | data_load_times : 45.25 | batch_run_times : 45.65\n",
      "[2022-12-04 18:01:59] 2786500167.py[  95] : INFO  0-32 | lr : 0.000070 | val_loss : 1.4905 | val_roc_auc : 0.8212 | data_load_times : 45.38 | batch_run_times : 45.76\n",
      "[2022-12-04 18:02:43] 2786500167.py[  95] : INFO  0-33 | lr : 0.000067 | val_loss : 1.4851 | val_roc_auc : 0.8235 | data_load_times : 46.31 | batch_run_times : 46.72\n",
      "[2022-12-04 18:03:27] 2786500167.py[  95] : INFO  0-34 | lr : 0.000064 | val_loss : 1.5303 | val_roc_auc : 0.7930 | data_load_times : 45.96 | batch_run_times : 46.34\n",
      "[2022-12-04 18:04:10] 2786500167.py[  95] : INFO  0-35 | lr : 0.000061 | val_loss : 1.4955 | val_roc_auc : 0.8144 | data_load_times : 46.33 | batch_run_times : 46.72\n",
      "[2022-12-04 18:04:53] 2786500167.py[  95] : INFO  0-36 | lr : 0.000057 | val_loss : 1.4078 | val_roc_auc : 0.8336 | data_load_times : 45.89 | batch_run_times : 46.26\n",
      "[2022-12-04 18:05:37] 2786500167.py[  95] : INFO  0-37 | lr : 0.000054 | val_loss : 1.4585 | val_roc_auc : 0.8410 | data_load_times : 47.65 | batch_run_times : 48.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-04 18:06:21] 2786500167.py[  95] : INFO  0-38 | lr : 0.000051 | val_loss : 1.4469 | val_roc_auc : 0.8223 | data_load_times : 45.54 | batch_run_times : 45.93\n",
      "[2022-12-04 18:07:05] 2786500167.py[  95] : INFO  0-39 | lr : 0.000048 | val_loss : 1.4414 | val_roc_auc : 0.8340 | data_load_times : 46.12 | batch_run_times : 46.57\n",
      "[2022-12-04 18:07:49] 2786500167.py[  95] : INFO  0-40 | lr : 0.000044 | val_loss : 1.4386 | val_roc_auc : 0.8383 | data_load_times : 47.41 | batch_run_times : 47.79\n",
      "[2022-12-04 18:08:33] 2786500167.py[  95] : INFO  0-41 | lr : 0.000041 | val_loss : 1.3977 | val_roc_auc : 0.8416 | data_load_times : 46.18 | batch_run_times : 46.56\n",
      "[2022-12-04 18:09:16] 2786500167.py[  95] : INFO  0-42 | lr : 0.000038 | val_loss : 1.4468 | val_roc_auc : 0.8127 | data_load_times : 48.46 | batch_run_times : 49.03\n",
      "[2022-12-04 18:09:59] 2786500167.py[  95] : INFO  0-43 | lr : 0.000035 | val_loss : 1.3952 | val_roc_auc : 0.8327 | data_load_times : 45.22 | batch_run_times : 45.61\n",
      "[2022-12-04 18:10:44] 2786500167.py[  95] : INFO  0-44 | lr : 0.000032 | val_loss : 1.4116 | val_roc_auc : 0.8264 | data_load_times : 46.22 | batch_run_times : 46.60\n",
      "[2022-12-04 18:11:26] 2786500167.py[  95] : INFO  0-45 | lr : 0.000029 | val_loss : 1.4216 | val_roc_auc : 0.8266 | data_load_times : 46.16 | batch_run_times : 46.55\n",
      "[2022-12-04 18:12:09] 2786500167.py[  95] : INFO  0-46 | lr : 0.000026 | val_loss : 1.3961 | val_roc_auc : 0.8295 | data_load_times : 44.59 | batch_run_times : 44.98\n",
      "[2022-12-04 18:12:52] 2786500167.py[  95] : INFO  0-47 | lr : 0.000023 | val_loss : 1.4270 | val_roc_auc : 0.8220 | data_load_times : 46.64 | batch_run_times : 47.04\n",
      "[2022-12-04 18:13:36] 2786500167.py[  95] : INFO  0-48 | lr : 0.000021 | val_loss : 1.3918 | val_roc_auc : 0.8514 | data_load_times : 47.22 | batch_run_times : 47.60\n",
      "[2022-12-04 18:14:20] 2786500167.py[  95] : INFO  0-49 | lr : 0.000018 | val_loss : 1.4287 | val_roc_auc : 0.8204 | data_load_times : 45.23 | batch_run_times : 45.62\n",
      "[2022-12-04 18:15:02] 2786500167.py[  95] : INFO  0-50 | lr : 0.000016 | val_loss : 1.3709 | val_roc_auc : 0.8383 | data_load_times : 46.00 | batch_run_times : 46.44\n",
      "[2022-12-04 18:15:47] 2786500167.py[  95] : INFO  0-51 | lr : 0.000014 | val_loss : 1.4259 | val_roc_auc : 0.8380 | data_load_times : 45.74 | batch_run_times : 46.14\n",
      "[2022-12-04 18:16:30] 2786500167.py[  95] : INFO  0-52 | lr : 0.000012 | val_loss : 1.3621 | val_roc_auc : 0.8430 | data_load_times : 46.82 | batch_run_times : 47.20\n",
      "[2022-12-04 18:17:13] 2786500167.py[  95] : INFO  0-53 | lr : 0.000011 | val_loss : 1.3967 | val_roc_auc : 0.8308 | data_load_times : 46.86 | batch_run_times : 47.28\n",
      "[2022-12-04 18:17:56] 2786500167.py[  95] : INFO  0-54 | lr : 0.000009 | val_loss : 1.3920 | val_roc_auc : 0.8334 | data_load_times : 44.97 | batch_run_times : 45.52\n",
      "[2022-12-04 18:18:39] 2786500167.py[  95] : INFO  0-55 | lr : 0.000008 | val_loss : 1.3640 | val_roc_auc : 0.8336 | data_load_times : 45.40 | batch_run_times : 45.79\n",
      "[2022-12-04 18:19:23] 2786500167.py[  95] : INFO  0-56 | lr : 0.000007 | val_loss : 1.3455 | val_roc_auc : 0.8388 | data_load_times : 47.31 | batch_run_times : 47.69\n",
      "[2022-12-04 18:20:06] 2786500167.py[  95] : INFO  0-57 | lr : 0.000006 | val_loss : 1.3538 | val_roc_auc : 0.8322 | data_load_times : 45.48 | batch_run_times : 45.86\n",
      "[2022-12-04 18:20:50] 2786500167.py[  95] : INFO  0-58 | lr : 0.000005 | val_loss : 1.4301 | val_roc_auc : 0.8325 | data_load_times : 47.20 | batch_run_times : 47.59\n",
      "[2022-12-04 18:21:33] 2786500167.py[  95] : INFO  0-59 | lr : 0.000005 | val_loss : 1.3600 | val_roc_auc : 0.8426 | data_load_times : 44.74 | batch_run_times : 45.12\n",
      "[2022-12-04 18:22:15] 2786500167.py[  95] : INFO  0-60 | lr : 0.000100 | val_loss : 1.5288 | val_roc_auc : 0.8072 | data_load_times : 47.27 | batch_run_times : 47.66\n",
      "[2022-12-04 18:22:58] 2786500167.py[  95] : INFO  0-61 | lr : 0.000100 | val_loss : 1.4236 | val_roc_auc : 0.8091 | data_load_times : 45.10 | batch_run_times : 45.51\n",
      "[2022-12-04 18:23:41] 2786500167.py[  95] : INFO  0-62 | lr : 0.000100 | val_loss : 1.4487 | val_roc_auc : 0.8065 | data_load_times : 46.51 | batch_run_times : 46.91\n",
      "[2022-12-04 18:24:24] 2786500167.py[  95] : INFO  0-63 | lr : 0.000100 | val_loss : 1.4780 | val_roc_auc : 0.8072 | data_load_times : 45.59 | batch_run_times : 45.97\n",
      "[2022-12-04 18:25:07] 2786500167.py[  95] : INFO  0-64 | lr : 0.000100 | val_loss : 1.4586 | val_roc_auc : 0.8230 | data_load_times : 45.50 | batch_run_times : 45.93\n",
      "[2022-12-04 18:25:50] 2786500167.py[  95] : INFO  0-65 | lr : 0.000100 | val_loss : 1.4423 | val_roc_auc : 0.8338 | data_load_times : 44.07 | batch_run_times : 44.45\n",
      "[2022-12-04 18:26:33] 2786500167.py[  95] : INFO  0-66 | lr : 0.000100 | val_loss : 1.3991 | val_roc_auc : 0.8293 | data_load_times : 46.59 | batch_run_times : 47.00\n",
      "[2022-12-04 18:27:15] 2786500167.py[  95] : INFO  0-67 | lr : 0.000099 | val_loss : 1.4721 | val_roc_auc : 0.8406 | data_load_times : 45.20 | batch_run_times : 45.62\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 18:27:59] 2786500167.py[  95] : INFO  0-68 | lr : 0.000099 | val_loss : 1.5489 | val_roc_auc : 0.7921 | data_load_times : 45.99 | batch_run_times : 46.36\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 18:28:42] 2786500167.py[  95] : INFO  0-69 | lr : 0.000099 | val_loss : 1.4610 | val_roc_auc : 0.8344 | data_load_times : 50.09 | batch_run_times : 50.47\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 18:29:24] 2786500167.py[  95] : INFO  0-70 | lr : 0.000099 | val_loss : 1.5548 | val_roc_auc : 0.7946 | data_load_times : 44.08 | batch_run_times : 44.66\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 18:30:08] 2786500167.py[  95] : INFO  0-71 | lr : 0.000098 | val_loss : 1.4592 | val_roc_auc : 0.8108 | data_load_times : 47.81 | batch_run_times : 48.23\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 18:30:51] 2786500167.py[  95] : INFO  0-72 | lr : 0.000098 | val_loss : 1.4967 | val_roc_auc : 0.7794 | data_load_times : 46.79 | batch_run_times : 47.16\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 18:31:34] 2786500167.py[  95] : INFO  0-73 | lr : 0.000098 | val_loss : 1.5991 | val_roc_auc : 0.7816 | data_load_times : 43.88 | batch_run_times : 44.26\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 18:32:17] 2786500167.py[  95] : INFO  0-74 | lr : 0.000098 | val_loss : 1.4224 | val_roc_auc : 0.8190 | data_load_times : 46.15 | batch_run_times : 46.58\n",
      "Epoch 00075: early stopping triggered.\n",
      "[2022-12-04 18:32:18] 128199480.py[  59] : INFO  Fold 1 num train records: 199\n",
      "[2022-12-04 18:32:18] 128199480.py[  60] : INFO  Fold 1 num val records: 100\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "[2022-12-04 18:33:03] 2786500167.py[  95] : INFO  1-0 | lr : 0.000100 | val_loss : 2.0531 | val_roc_auc : 0.6899 | data_load_times : 49.69 | batch_run_times : 50.07\n",
      "[2022-12-04 18:33:47] 2786500167.py[  95] : INFO  1-1 | lr : 0.000099 | val_loss : 1.9757 | val_roc_auc : 0.7645 | data_load_times : 43.08 | batch_run_times : 43.51\n",
      "[2022-12-04 18:34:32] 2786500167.py[  95] : INFO  1-2 | lr : 0.000096 | val_loss : 1.9442 | val_roc_auc : 0.7925 | data_load_times : 45.33 | batch_run_times : 45.71\n",
      "[2022-12-04 18:35:16] 2786500167.py[  95] : INFO  1-3 | lr : 0.000091 | val_loss : 1.8970 | val_roc_auc : 0.7956 | data_load_times : 46.53 | batch_run_times : 46.93\n",
      "[2022-12-04 18:36:00] 2786500167.py[  95] : INFO  1-4 | lr : 0.000084 | val_loss : 1.8546 | val_roc_auc : 0.8073 | data_load_times : 46.02 | batch_run_times : 46.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-04 18:36:45] 2786500167.py[  95] : INFO  1-5 | lr : 0.000076 | val_loss : 1.8982 | val_roc_auc : 0.7846 | data_load_times : 45.77 | batch_run_times : 46.15\n",
      "[2022-12-04 18:37:29] 2786500167.py[  95] : INFO  1-6 | lr : 0.000067 | val_loss : 1.7872 | val_roc_auc : 0.8554 | data_load_times : 43.61 | batch_run_times : 44.00\n",
      "[2022-12-04 18:38:13] 2786500167.py[  95] : INFO  1-7 | lr : 0.000057 | val_loss : 1.7390 | val_roc_auc : 0.8708 | data_load_times : 45.05 | batch_run_times : 45.45\n",
      "[2022-12-04 18:38:58] 2786500167.py[  95] : INFO  1-8 | lr : 0.000048 | val_loss : 1.7378 | val_roc_auc : 0.8485 | data_load_times : 46.06 | batch_run_times : 46.43\n",
      "[2022-12-04 18:39:43] 2786500167.py[  95] : INFO  1-9 | lr : 0.000038 | val_loss : 1.6998 | val_roc_auc : 0.8504 | data_load_times : 45.64 | batch_run_times : 46.02\n",
      "[2022-12-04 18:40:28] 2786500167.py[  95] : INFO  1-10 | lr : 0.000029 | val_loss : 1.6963 | val_roc_auc : 0.8595 | data_load_times : 45.16 | batch_run_times : 45.62\n",
      "[2022-12-04 18:41:13] 2786500167.py[  95] : INFO  1-11 | lr : 0.000021 | val_loss : 1.6743 | val_roc_auc : 0.8679 | data_load_times : 44.63 | batch_run_times : 45.06\n",
      "[2022-12-04 18:41:59] 2786500167.py[  95] : INFO  1-12 | lr : 0.000014 | val_loss : 1.6619 | val_roc_auc : 0.8731 | data_load_times : 43.49 | batch_run_times : 43.87\n",
      "[2022-12-04 18:42:43] 2786500167.py[  95] : INFO  1-13 | lr : 0.000009 | val_loss : 1.6703 | val_roc_auc : 0.8641 | data_load_times : 43.50 | batch_run_times : 43.89\n",
      "[2022-12-04 18:43:27] 2786500167.py[  95] : INFO  1-14 | lr : 0.000006 | val_loss : 1.6768 | val_roc_auc : 0.8718 | data_load_times : 46.25 | batch_run_times : 46.62\n",
      "[2022-12-04 18:44:11] 2786500167.py[  95] : INFO  1-15 | lr : 0.000100 | val_loss : 1.6802 | val_roc_auc : 0.8546 | data_load_times : 47.35 | batch_run_times : 47.78\n",
      "[2022-12-04 18:44:55] 2786500167.py[  95] : INFO  1-16 | lr : 0.000100 | val_loss : 1.6704 | val_roc_auc : 0.8482 | data_load_times : 45.93 | batch_run_times : 46.31\n",
      "[2022-12-04 18:45:39] 2786500167.py[  95] : INFO  1-17 | lr : 0.000100 | val_loss : 1.6624 | val_roc_auc : 0.8624 | data_load_times : 45.01 | batch_run_times : 45.39\n",
      "[2022-12-04 18:46:23] 2786500167.py[  95] : INFO  1-18 | lr : 0.000099 | val_loss : 1.6180 | val_roc_auc : 0.8558 | data_load_times : 44.26 | batch_run_times : 44.64\n",
      "[2022-12-04 18:47:08] 2786500167.py[  95] : INFO  1-19 | lr : 0.000098 | val_loss : 1.6753 | val_roc_auc : 0.8308 | data_load_times : 46.77 | batch_run_times : 47.15\n",
      "[2022-12-04 18:47:51] 2786500167.py[  95] : INFO  1-20 | lr : 0.000097 | val_loss : 1.6204 | val_roc_auc : 0.8336 | data_load_times : 45.80 | batch_run_times : 46.21\n",
      "[2022-12-04 18:48:35] 2786500167.py[  95] : INFO  1-21 | lr : 0.000096 | val_loss : 1.5667 | val_roc_auc : 0.8594 | data_load_times : 46.83 | batch_run_times : 47.21\n",
      "[2022-12-04 18:49:20] 2786500167.py[  95] : INFO  1-22 | lr : 0.000094 | val_loss : 1.5950 | val_roc_auc : 0.8298 | data_load_times : 46.32 | batch_run_times : 46.72\n",
      "[2022-12-04 18:50:04] 2786500167.py[  95] : INFO  1-23 | lr : 0.000093 | val_loss : 1.5314 | val_roc_auc : 0.8510 | data_load_times : 46.65 | batch_run_times : 47.03\n",
      "[2022-12-04 18:50:49] 2786500167.py[  95] : INFO  1-24 | lr : 0.000091 | val_loss : 1.5110 | val_roc_auc : 0.8599 | data_load_times : 44.43 | batch_run_times : 44.82\n",
      "[2022-12-04 18:51:34] 2786500167.py[  95] : INFO  1-25 | lr : 0.000089 | val_loss : 1.5742 | val_roc_auc : 0.8433 | data_load_times : 45.77 | batch_run_times : 46.15\n",
      "[2022-12-04 18:52:18] 2786500167.py[  95] : INFO  1-26 | lr : 0.000087 | val_loss : 1.4802 | val_roc_auc : 0.8459 | data_load_times : 47.00 | batch_run_times : 47.41\n",
      "[2022-12-04 18:53:03] 2786500167.py[  95] : INFO  1-27 | lr : 0.000084 | val_loss : 1.4448 | val_roc_auc : 0.8587 | data_load_times : 46.81 | batch_run_times : 47.24\n",
      "[2022-12-04 18:53:48] 2786500167.py[  95] : INFO  1-28 | lr : 0.000082 | val_loss : 1.4616 | val_roc_auc : 0.8523 | data_load_times : 47.49 | batch_run_times : 47.86\n",
      "[2022-12-04 18:54:32] 2786500167.py[  95] : INFO  1-29 | lr : 0.000079 | val_loss : 1.4596 | val_roc_auc : 0.8544 | data_load_times : 43.75 | batch_run_times : 44.13\n",
      "[2022-12-04 18:55:17] 2786500167.py[  95] : INFO  1-30 | lr : 0.000076 | val_loss : 1.3793 | val_roc_auc : 0.8617 | data_load_times : 40.76 | batch_run_times : 41.47\n",
      "[2022-12-04 18:56:02] 2786500167.py[  95] : INFO  1-31 | lr : 0.000073 | val_loss : 1.4475 | val_roc_auc : 0.8597 | data_load_times : 47.03 | batch_run_times : 47.41\n",
      "[2022-12-04 18:56:46] 2786500167.py[  95] : INFO  1-32 | lr : 0.000070 | val_loss : 1.4273 | val_roc_auc : 0.8577 | data_load_times : 43.73 | batch_run_times : 44.21\n",
      "[2022-12-04 18:57:30] 2786500167.py[  95] : INFO  1-33 | lr : 0.000067 | val_loss : 1.4852 | val_roc_auc : 0.8348 | data_load_times : 45.04 | batch_run_times : 45.55\n",
      "[2022-12-04 18:58:14] 2786500167.py[  95] : INFO  1-34 | lr : 0.000064 | val_loss : 1.4255 | val_roc_auc : 0.8439 | data_load_times : 45.68 | batch_run_times : 46.13\n",
      "[2022-12-04 18:58:59] 2786500167.py[  95] : INFO  1-35 | lr : 0.000061 | val_loss : 1.3920 | val_roc_auc : 0.8460 | data_load_times : 45.23 | batch_run_times : 45.64\n",
      "[2022-12-04 18:59:44] 2786500167.py[  95] : INFO  1-36 | lr : 0.000057 | val_loss : 1.4171 | val_roc_auc : 0.8558 | data_load_times : 46.82 | batch_run_times : 47.26\n",
      "[2022-12-04 19:00:27] 2786500167.py[  95] : INFO  1-37 | lr : 0.000054 | val_loss : 1.4456 | val_roc_auc : 0.8569 | data_load_times : 43.02 | batch_run_times : 43.42\n",
      "[2022-12-04 19:01:11] 2786500167.py[  95] : INFO  1-38 | lr : 0.000051 | val_loss : 1.4161 | val_roc_auc : 0.8452 | data_load_times : 46.07 | batch_run_times : 46.47\n",
      "[2022-12-04 19:01:54] 2786500167.py[  95] : INFO  1-39 | lr : 0.000048 | val_loss : 1.3492 | val_roc_auc : 0.8456 | data_load_times : 46.91 | batch_run_times : 47.39\n",
      "[2022-12-04 19:02:39] 2786500167.py[  95] : INFO  1-40 | lr : 0.000044 | val_loss : 1.3580 | val_roc_auc : 0.8389 | data_load_times : 45.12 | batch_run_times : 45.62\n",
      "[2022-12-04 19:03:23] 2786500167.py[  95] : INFO  1-41 | lr : 0.000041 | val_loss : 1.3563 | val_roc_auc : 0.8598 | data_load_times : 45.07 | batch_run_times : 45.75\n",
      "[2022-12-04 19:04:08] 2786500167.py[  95] : INFO  1-42 | lr : 0.000038 | val_loss : 1.3752 | val_roc_auc : 0.8542 | data_load_times : 45.63 | batch_run_times : 46.01\n",
      "[2022-12-04 19:04:53] 2786500167.py[  95] : INFO  1-43 | lr : 0.000035 | val_loss : 1.3854 | val_roc_auc : 0.8515 | data_load_times : 47.10 | batch_run_times : 47.49\n",
      "[2022-12-04 19:05:37] 2786500167.py[  95] : INFO  1-44 | lr : 0.000032 | val_loss : 1.3394 | val_roc_auc : 0.8584 | data_load_times : 46.04 | batch_run_times : 46.42\n",
      "[2022-12-04 19:06:21] 2786500167.py[  95] : INFO  1-45 | lr : 0.000029 | val_loss : 1.3798 | val_roc_auc : 0.8448 | data_load_times : 45.39 | batch_run_times : 45.76\n",
      "[2022-12-04 19:07:05] 2786500167.py[  95] : INFO  1-46 | lr : 0.000026 | val_loss : 1.2706 | val_roc_auc : 0.8757 | data_load_times : 45.61 | batch_run_times : 46.04\n",
      "[2022-12-04 19:07:51] 2786500167.py[  95] : INFO  1-47 | lr : 0.000023 | val_loss : 1.3602 | val_roc_auc : 0.8512 | data_load_times : 45.06 | batch_run_times : 45.42\n",
      "[2022-12-04 19:08:35] 2786500167.py[  95] : INFO  1-48 | lr : 0.000021 | val_loss : 1.3644 | val_roc_auc : 0.8504 | data_load_times : 44.67 | batch_run_times : 45.05\n",
      "[2022-12-04 19:09:18] 2786500167.py[  95] : INFO  1-49 | lr : 0.000018 | val_loss : 1.2978 | val_roc_auc : 0.8640 | data_load_times : 46.94 | batch_run_times : 47.32\n",
      "[2022-12-04 19:10:03] 2786500167.py[  95] : INFO  1-50 | lr : 0.000016 | val_loss : 1.3229 | val_roc_auc : 0.8582 | data_load_times : 44.73 | batch_run_times : 45.11\n",
      "[2022-12-04 19:10:47] 2786500167.py[  95] : INFO  1-51 | lr : 0.000014 | val_loss : 1.3966 | val_roc_auc : 0.8523 | data_load_times : 45.35 | batch_run_times : 45.88\n",
      "[2022-12-04 19:11:30] 2786500167.py[  95] : INFO  1-52 | lr : 0.000012 | val_loss : 1.3617 | val_roc_auc : 0.8538 | data_load_times : 44.04 | batch_run_times : 44.46\n",
      "[2022-12-04 19:12:14] 2786500167.py[  95] : INFO  1-53 | lr : 0.000011 | val_loss : 1.3395 | val_roc_auc : 0.8602 | data_load_times : 44.72 | batch_run_times : 45.09\n",
      "[2022-12-04 19:12:58] 2786500167.py[  95] : INFO  1-54 | lr : 0.000009 | val_loss : 1.3450 | val_roc_auc : 0.8483 | data_load_times : 49.43 | batch_run_times : 49.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-04 19:13:42] 2786500167.py[  95] : INFO  1-55 | lr : 0.000008 | val_loss : 1.3175 | val_roc_auc : 0.8533 | data_load_times : 45.93 | batch_run_times : 46.37\n",
      "[2022-12-04 19:14:26] 2786500167.py[  95] : INFO  1-56 | lr : 0.000007 | val_loss : 1.3262 | val_roc_auc : 0.8594 | data_load_times : 37.67 | batch_run_times : 38.33\n",
      "[2022-12-04 19:15:10] 2786500167.py[  95] : INFO  1-57 | lr : 0.000006 | val_loss : 1.3547 | val_roc_auc : 0.8594 | data_load_times : 46.26 | batch_run_times : 46.67\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:15:54] 2786500167.py[  95] : INFO  1-58 | lr : 0.000005 | val_loss : 1.3471 | val_roc_auc : 0.8554 | data_load_times : 44.94 | batch_run_times : 45.31\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:16:38] 2786500167.py[  95] : INFO  1-59 | lr : 0.000005 | val_loss : 1.3928 | val_roc_auc : 0.8528 | data_load_times : 45.16 | batch_run_times : 45.64\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:17:21] 2786500167.py[  95] : INFO  1-60 | lr : 0.000100 | val_loss : 1.4510 | val_roc_auc : 0.8245 | data_load_times : 44.89 | batch_run_times : 45.31\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:18:06] 2786500167.py[  95] : INFO  1-61 | lr : 0.000100 | val_loss : 1.3974 | val_roc_auc : 0.8409 | data_load_times : 44.42 | batch_run_times : 44.82\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:18:50] 2786500167.py[  95] : INFO  1-62 | lr : 0.000100 | val_loss : 1.5238 | val_roc_auc : 0.8176 | data_load_times : 44.70 | batch_run_times : 45.09\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:19:34] 2786500167.py[  95] : INFO  1-63 | lr : 0.000100 | val_loss : 1.3114 | val_roc_auc : 0.8697 | data_load_times : 44.70 | batch_run_times : 45.37\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:20:18] 2786500167.py[  95] : INFO  1-64 | lr : 0.000100 | val_loss : 1.3770 | val_roc_auc : 0.8341 | data_load_times : 47.09 | batch_run_times : 47.47\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:21:02] 2786500167.py[  95] : INFO  1-65 | lr : 0.000100 | val_loss : 1.3118 | val_roc_auc : 0.8370 | data_load_times : 46.47 | batch_run_times : 46.88\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:21:45] 2786500167.py[  95] : INFO  1-66 | lr : 0.000100 | val_loss : 1.4171 | val_roc_auc : 0.8391 | data_load_times : 43.89 | batch_run_times : 44.29\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:22:30] 2786500167.py[  95] : INFO  1-67 | lr : 0.000099 | val_loss : 1.3593 | val_roc_auc : 0.8568 | data_load_times : 46.13 | batch_run_times : 46.53\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:23:13] 2786500167.py[  95] : INFO  1-68 | lr : 0.000099 | val_loss : 1.4307 | val_roc_auc : 0.8411 | data_load_times : 45.34 | batch_run_times : 45.74\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:23:58] 2786500167.py[  95] : INFO  1-69 | lr : 0.000099 | val_loss : 1.4201 | val_roc_auc : 0.8425 | data_load_times : 46.85 | batch_run_times : 47.36\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:24:42] 2786500167.py[  95] : INFO  1-70 | lr : 0.000099 | val_loss : 1.4897 | val_roc_auc : 0.8440 | data_load_times : 47.55 | batch_run_times : 48.26\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:25:26] 2786500167.py[  95] : INFO  1-71 | lr : 0.000098 | val_loss : 1.4696 | val_roc_auc : 0.8357 | data_load_times : 46.42 | batch_run_times : 46.82\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:26:09] 2786500167.py[  95] : INFO  1-72 | lr : 0.000098 | val_loss : 1.4508 | val_roc_auc : 0.8398 | data_load_times : 46.04 | batch_run_times : 46.47\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:26:53] 2786500167.py[  95] : INFO  1-73 | lr : 0.000098 | val_loss : 1.2768 | val_roc_auc : 0.8753 | data_load_times : 46.85 | batch_run_times : 47.23\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 19:27:38] 2786500167.py[  95] : INFO  1-74 | lr : 0.000098 | val_loss : 1.3629 | val_roc_auc : 0.8462 | data_load_times : 44.53 | batch_run_times : 44.91\n",
      "Epoch 00075: early stopping triggered.\n",
      "[2022-12-04 19:27:38] 128199480.py[  59] : INFO  Fold 2 num train records: 200\n",
      "[2022-12-04 19:27:38] 128199480.py[  60] : INFO  Fold 2 num val records: 99\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "[2022-12-04 19:28:22] 2786500167.py[  95] : INFO  2-0 | lr : 0.000100 | val_loss : 2.0613 | val_roc_auc : 0.6224 | data_load_times : 46.18 | batch_run_times : 46.63\n",
      "[2022-12-04 19:29:08] 2786500167.py[  95] : INFO  2-1 | lr : 0.000099 | val_loss : 2.0247 | val_roc_auc : 0.6856 | data_load_times : 44.74 | batch_run_times : 45.25\n",
      "[2022-12-04 19:29:53] 2786500167.py[  95] : INFO  2-2 | lr : 0.000096 | val_loss : 1.9744 | val_roc_auc : 0.7059 | data_load_times : 44.86 | batch_run_times : 45.32\n",
      "[2022-12-04 19:30:38] 2786500167.py[  95] : INFO  2-3 | lr : 0.000091 | val_loss : 1.9122 | val_roc_auc : 0.7495 | data_load_times : 45.81 | batch_run_times : 46.22\n",
      "[2022-12-04 19:31:24] 2786500167.py[  95] : INFO  2-4 | lr : 0.000084 | val_loss : 1.9055 | val_roc_auc : 0.7110 | data_load_times : 43.73 | batch_run_times : 44.12\n",
      "[2022-12-04 19:32:09] 2786500167.py[  95] : INFO  2-5 | lr : 0.000076 | val_loss : 1.8543 | val_roc_auc : 0.7582 | data_load_times : 46.50 | batch_run_times : 46.92\n",
      "[2022-12-04 19:32:54] 2786500167.py[  95] : INFO  2-6 | lr : 0.000067 | val_loss : 1.8060 | val_roc_auc : 0.8051 | data_load_times : 46.03 | batch_run_times : 46.42\n",
      "[2022-12-04 19:33:40] 2786500167.py[  95] : INFO  2-7 | lr : 0.000057 | val_loss : 1.8237 | val_roc_auc : 0.7793 | data_load_times : 45.12 | batch_run_times : 45.50\n",
      "[2022-12-04 19:34:25] 2786500167.py[  95] : INFO  2-8 | lr : 0.000048 | val_loss : 1.7960 | val_roc_auc : 0.7818 | data_load_times : 47.63 | batch_run_times : 48.08\n",
      "[2022-12-04 19:35:11] 2786500167.py[  95] : INFO  2-9 | lr : 0.000038 | val_loss : 1.7899 | val_roc_auc : 0.7883 | data_load_times : 43.45 | batch_run_times : 43.85\n",
      "[2022-12-04 19:35:56] 2786500167.py[  95] : INFO  2-10 | lr : 0.000029 | val_loss : 1.7573 | val_roc_auc : 0.7911 | data_load_times : 45.30 | batch_run_times : 45.67\n",
      "[2022-12-04 19:36:41] 2786500167.py[  95] : INFO  2-11 | lr : 0.000021 | val_loss : 1.7525 | val_roc_auc : 0.7971 | data_load_times : 45.66 | batch_run_times : 46.04\n",
      "[2022-12-04 19:37:26] 2786500167.py[  95] : INFO  2-12 | lr : 0.000014 | val_loss : 1.7716 | val_roc_auc : 0.7864 | data_load_times : 45.87 | batch_run_times : 46.42\n",
      "[2022-12-04 19:38:11] 2786500167.py[  95] : INFO  2-13 | lr : 0.000009 | val_loss : 1.7358 | val_roc_auc : 0.7946 | data_load_times : 46.13 | batch_run_times : 46.56\n",
      "[2022-12-04 19:38:56] 2786500167.py[  95] : INFO  2-14 | lr : 0.000006 | val_loss : 1.7452 | val_roc_auc : 0.7942 | data_load_times : 44.64 | batch_run_times : 45.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-12-04 19:39:41] 2786500167.py[  95] : INFO  2-15 | lr : 0.000100 | val_loss : 1.7644 | val_roc_auc : 0.7803 | data_load_times : 45.98 | batch_run_times : 46.35\n",
      "[2022-12-04 19:40:26] 2786500167.py[  95] : INFO  2-16 | lr : 0.000100 | val_loss : 1.7522 | val_roc_auc : 0.7796 | data_load_times : 46.44 | batch_run_times : 46.83\n",
      "[2022-12-04 19:41:11] 2786500167.py[  95] : INFO  2-17 | lr : 0.000100 | val_loss : 1.7187 | val_roc_auc : 0.7906 | data_load_times : 44.71 | batch_run_times : 45.07\n",
      "[2022-12-04 19:41:57] 2786500167.py[  95] : INFO  2-18 | lr : 0.000099 | val_loss : 1.7417 | val_roc_auc : 0.7633 | data_load_times : 44.06 | batch_run_times : 44.45\n",
      "[2022-12-04 19:42:41] 2786500167.py[  95] : INFO  2-19 | lr : 0.000098 | val_loss : 1.6833 | val_roc_auc : 0.8021 | data_load_times : 44.54 | batch_run_times : 44.93\n",
      "[2022-12-04 19:43:26] 2786500167.py[  95] : INFO  2-20 | lr : 0.000097 | val_loss : 1.6373 | val_roc_auc : 0.8256 | data_load_times : 46.20 | batch_run_times : 46.72\n",
      "[2022-12-04 19:44:12] 2786500167.py[  95] : INFO  2-21 | lr : 0.000096 | val_loss : 1.6800 | val_roc_auc : 0.8077 | data_load_times : 47.15 | batch_run_times : 47.54\n",
      "[2022-12-04 19:44:58] 2786500167.py[  95] : INFO  2-22 | lr : 0.000094 | val_loss : 1.6237 | val_roc_auc : 0.8213 | data_load_times : 47.81 | batch_run_times : 48.20\n",
      "[2022-12-04 19:45:42] 2786500167.py[  95] : INFO  2-23 | lr : 0.000093 | val_loss : 1.6292 | val_roc_auc : 0.7943 | data_load_times : 44.72 | batch_run_times : 45.10\n",
      "[2022-12-04 19:46:28] 2786500167.py[  95] : INFO  2-24 | lr : 0.000091 | val_loss : 1.7052 | val_roc_auc : 0.7757 | data_load_times : 46.75 | batch_run_times : 47.17\n",
      "[2022-12-04 19:47:12] 2786500167.py[  95] : INFO  2-25 | lr : 0.000089 | val_loss : 1.5535 | val_roc_auc : 0.8253 | data_load_times : 45.40 | batch_run_times : 45.82\n",
      "[2022-12-04 19:47:57] 2786500167.py[  95] : INFO  2-26 | lr : 0.000087 | val_loss : 1.5419 | val_roc_auc : 0.8244 | data_load_times : 47.87 | batch_run_times : 48.27\n",
      "[2022-12-04 19:48:43] 2786500167.py[  95] : INFO  2-27 | lr : 0.000084 | val_loss : 1.5750 | val_roc_auc : 0.8069 | data_load_times : 47.73 | batch_run_times : 48.17\n",
      "[2022-12-04 19:49:27] 2786500167.py[  95] : INFO  2-28 | lr : 0.000082 | val_loss : 1.5719 | val_roc_auc : 0.8076 | data_load_times : 44.09 | batch_run_times : 44.49\n",
      "[2022-12-04 19:50:12] 2786500167.py[  95] : INFO  2-29 | lr : 0.000079 | val_loss : 1.5415 | val_roc_auc : 0.8014 | data_load_times : 45.24 | batch_run_times : 45.66\n",
      "[2022-12-04 19:50:58] 2786500167.py[  95] : INFO  2-30 | lr : 0.000076 | val_loss : 1.5418 | val_roc_auc : 0.8181 | data_load_times : 44.63 | batch_run_times : 45.07\n",
      "[2022-12-04 19:51:43] 2786500167.py[  95] : INFO  2-31 | lr : 0.000073 | val_loss : 1.4854 | val_roc_auc : 0.8303 | data_load_times : 47.13 | batch_run_times : 47.51\n",
      "[2022-12-04 19:52:28] 2786500167.py[  95] : INFO  2-32 | lr : 0.000070 | val_loss : 1.4592 | val_roc_auc : 0.8509 | data_load_times : 44.13 | batch_run_times : 44.53\n",
      "[2022-12-04 19:53:14] 2786500167.py[  95] : INFO  2-33 | lr : 0.000067 | val_loss : 1.4399 | val_roc_auc : 0.8373 | data_load_times : 43.42 | batch_run_times : 43.84\n",
      "[2022-12-04 19:53:59] 2786500167.py[  95] : INFO  2-34 | lr : 0.000064 | val_loss : 1.3900 | val_roc_auc : 0.8565 | data_load_times : 45.27 | batch_run_times : 45.67\n",
      "[2022-12-04 19:54:45] 2786500167.py[  95] : INFO  2-35 | lr : 0.000061 | val_loss : 1.4346 | val_roc_auc : 0.8554 | data_load_times : 44.01 | batch_run_times : 44.42\n",
      "[2022-12-04 19:55:31] 2786500167.py[  95] : INFO  2-36 | lr : 0.000057 | val_loss : 1.4341 | val_roc_auc : 0.8520 | data_load_times : 45.34 | batch_run_times : 45.78\n",
      "[2022-12-04 19:56:16] 2786500167.py[  95] : INFO  2-37 | lr : 0.000054 | val_loss : 1.4433 | val_roc_auc : 0.8295 | data_load_times : 43.90 | batch_run_times : 44.38\n",
      "[2022-12-04 19:57:01] 2786500167.py[  95] : INFO  2-38 | lr : 0.000051 | val_loss : 1.4624 | val_roc_auc : 0.8239 | data_load_times : 46.33 | batch_run_times : 46.77\n",
      "[2022-12-04 19:57:44] 2786500167.py[  95] : INFO  2-39 | lr : 0.000048 | val_loss : 1.3768 | val_roc_auc : 0.8542 | data_load_times : 46.68 | batch_run_times : 47.09\n",
      "[2022-12-04 19:58:30] 2786500167.py[  95] : INFO  2-40 | lr : 0.000044 | val_loss : 1.4207 | val_roc_auc : 0.8436 | data_load_times : 45.01 | batch_run_times : 45.44\n",
      "[2022-12-04 19:59:14] 2786500167.py[  95] : INFO  2-41 | lr : 0.000041 | val_loss : 1.3554 | val_roc_auc : 0.8640 | data_load_times : 46.73 | batch_run_times : 47.12\n",
      "[2022-12-04 20:00:00] 2786500167.py[  95] : INFO  2-42 | lr : 0.000038 | val_loss : 1.3560 | val_roc_auc : 0.8386 | data_load_times : 46.09 | batch_run_times : 46.49\n",
      "[2022-12-04 20:00:46] 2786500167.py[  95] : INFO  2-43 | lr : 0.000035 | val_loss : 1.4824 | val_roc_auc : 0.8208 | data_load_times : 46.48 | batch_run_times : 46.89\n",
      "[2022-12-04 20:01:30] 2786500167.py[  95] : INFO  2-44 | lr : 0.000032 | val_loss : 1.3653 | val_roc_auc : 0.8426 | data_load_times : 48.32 | batch_run_times : 48.72\n",
      "[2022-12-04 20:02:14] 2786500167.py[  95] : INFO  2-45 | lr : 0.000029 | val_loss : 1.4003 | val_roc_auc : 0.8348 | data_load_times : 47.01 | batch_run_times : 47.40\n",
      "[2022-12-04 20:02:59] 2786500167.py[  95] : INFO  2-46 | lr : 0.000026 | val_loss : 1.3921 | val_roc_auc : 0.8470 | data_load_times : 46.45 | batch_run_times : 46.85\n",
      "[2022-12-04 20:03:43] 2786500167.py[  95] : INFO  2-47 | lr : 0.000023 | val_loss : 1.3534 | val_roc_auc : 0.8417 | data_load_times : 46.82 | batch_run_times : 47.22\n",
      "[2022-12-04 20:04:28] 2786500167.py[  95] : INFO  2-48 | lr : 0.000021 | val_loss : 1.3682 | val_roc_auc : 0.8474 | data_load_times : 46.89 | batch_run_times : 47.36\n",
      "[2022-12-04 20:05:13] 2786500167.py[  95] : INFO  2-49 | lr : 0.000018 | val_loss : 1.3275 | val_roc_auc : 0.8482 | data_load_times : 45.42 | batch_run_times : 45.87\n",
      "[2022-12-04 20:05:58] 2786500167.py[  95] : INFO  2-50 | lr : 0.000016 | val_loss : 1.3297 | val_roc_auc : 0.8540 | data_load_times : 45.08 | batch_run_times : 45.45\n",
      "[2022-12-04 20:06:43] 2786500167.py[  95] : INFO  2-51 | lr : 0.000014 | val_loss : 1.3009 | val_roc_auc : 0.8689 | data_load_times : 46.03 | batch_run_times : 46.58\n",
      "[2022-12-04 20:07:28] 2786500167.py[  95] : INFO  2-52 | lr : 0.000012 | val_loss : 1.3302 | val_roc_auc : 0.8509 | data_load_times : 43.66 | batch_run_times : 44.09\n",
      "[2022-12-04 20:08:13] 2786500167.py[  95] : INFO  2-53 | lr : 0.000011 | val_loss : 1.3765 | val_roc_auc : 0.8509 | data_load_times : 46.71 | batch_run_times : 47.11\n",
      "[2022-12-04 20:08:58] 2786500167.py[  95] : INFO  2-54 | lr : 0.000009 | val_loss : 1.3246 | val_roc_auc : 0.8575 | data_load_times : 46.25 | batch_run_times : 46.63\n",
      "[2022-12-04 20:09:43] 2786500167.py[  95] : INFO  2-55 | lr : 0.000008 | val_loss : 1.3490 | val_roc_auc : 0.8521 | data_load_times : 44.50 | batch_run_times : 44.91\n",
      "[2022-12-04 20:10:28] 2786500167.py[  95] : INFO  2-56 | lr : 0.000007 | val_loss : 1.3248 | val_roc_auc : 0.8585 | data_load_times : 46.79 | batch_run_times : 47.40\n",
      "[2022-12-04 20:11:13] 2786500167.py[  95] : INFO  2-57 | lr : 0.000006 | val_loss : 1.3180 | val_roc_auc : 0.8536 | data_load_times : 46.26 | batch_run_times : 46.88\n",
      "[2022-12-04 20:11:58] 2786500167.py[  95] : INFO  2-58 | lr : 0.000005 | val_loss : 1.3215 | val_roc_auc : 0.8528 | data_load_times : 45.05 | batch_run_times : 45.44\n",
      "[2022-12-04 20:12:43] 2786500167.py[  95] : INFO  2-59 | lr : 0.000005 | val_loss : 1.3576 | val_roc_auc : 0.8480 | data_load_times : 44.67 | batch_run_times : 45.05\n",
      "[2022-12-04 20:13:27] 2786500167.py[  95] : INFO  2-60 | lr : 0.000100 | val_loss : 1.5796 | val_roc_auc : 0.8114 | data_load_times : 47.43 | batch_run_times : 47.81\n",
      "[2022-12-04 20:14:12] 2786500167.py[  95] : INFO  2-61 | lr : 0.000100 | val_loss : 1.3246 | val_roc_auc : 0.8575 | data_load_times : 46.50 | batch_run_times : 46.90\n",
      "[2022-12-04 20:14:57] 2786500167.py[  95] : INFO  2-62 | lr : 0.000100 | val_loss : 1.3654 | val_roc_auc : 0.8361 | data_load_times : 46.29 | batch_run_times : 46.72\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 20:15:42] 2786500167.py[  95] : INFO  2-63 | lr : 0.000100 | val_loss : 1.4557 | val_roc_auc : 0.8089 | data_load_times : 45.37 | batch_run_times : 45.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 20:16:26] 2786500167.py[  95] : INFO  2-64 | lr : 0.000100 | val_loss : 1.3614 | val_roc_auc : 0.8361 | data_load_times : 46.44 | batch_run_times : 46.88\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 20:17:11] 2786500167.py[  95] : INFO  2-65 | lr : 0.000100 | val_loss : 1.4332 | val_roc_auc : 0.8323 | data_load_times : 43.15 | batch_run_times : 43.55\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 20:17:55] 2786500167.py[  95] : INFO  2-66 | lr : 0.000100 | val_loss : 1.4311 | val_roc_auc : 0.8332 | data_load_times : 46.80 | batch_run_times : 47.21\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 20:18:40] 2786500167.py[  95] : INFO  2-67 | lr : 0.000099 | val_loss : 1.4064 | val_roc_auc : 0.8230 | data_load_times : 45.14 | batch_run_times : 45.58\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 20:19:25] 2786500167.py[  95] : INFO  2-68 | lr : 0.000099 | val_loss : 1.5193 | val_roc_auc : 0.8079 | data_load_times : 46.06 | batch_run_times : 46.45\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 20:20:09] 2786500167.py[  95] : INFO  2-69 | lr : 0.000099 | val_loss : 1.4213 | val_roc_auc : 0.8181 | data_load_times : 46.26 | batch_run_times : 46.65\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 20:20:55] 2786500167.py[  95] : INFO  2-70 | lr : 0.000099 | val_loss : 1.4261 | val_roc_auc : 0.8271 | data_load_times : 48.52 | batch_run_times : 48.92\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 20:21:40] 2786500167.py[  95] : INFO  2-71 | lr : 0.000098 | val_loss : 1.4039 | val_roc_auc : 0.8263 | data_load_times : 48.20 | batch_run_times : 48.59\n",
      "Trainer was signaled to stop but required minimum epochs (75) or minimum steps (None) has not been met. Training will continue...\n",
      "[2022-12-04 20:22:25] 2786500167.py[  95] : INFO  2-72 | lr : 0.000098 | val_loss : 1.2897 | val_roc_auc : 0.8384 | data_load_times : 44.55 | batch_run_times : 44.95\n",
      "[2022-12-04 20:23:10] 2786500167.py[  95] : INFO  2-73 | lr : 0.000098 | val_loss : 1.3846 | val_roc_auc : 0.8255 | data_load_times : 45.52 | batch_run_times : 45.92\n",
      "[2022-12-04 20:23:54] 2786500167.py[  95] : INFO  2-74 | lr : 0.000098 | val_loss : 1.4499 | val_roc_auc : 0.8285 | data_load_times : 44.68 | batch_run_times : 45.06\n",
      "[2022-12-04 20:24:38] 2786500167.py[  95] : INFO  2-75 | lr : 0.000097 | val_loss : 1.5045 | val_roc_auc : 0.8183 | data_load_times : 44.91 | batch_run_times : 45.32\n",
      "[2022-12-04 20:25:22] 2786500167.py[  95] : INFO  2-76 | lr : 0.000097 | val_loss : 1.4263 | val_roc_auc : 0.8330 | data_load_times : 43.51 | batch_run_times : 43.92\n",
      "[2022-12-04 20:26:07] 2786500167.py[  95] : INFO  2-77 | lr : 0.000096 | val_loss : 1.4295 | val_roc_auc : 0.8452 | data_load_times : 44.96 | batch_run_times : 45.34\n",
      "[2022-12-04 20:26:52] 2786500167.py[  95] : INFO  2-78 | lr : 0.000096 | val_loss : 1.4386 | val_roc_auc : 0.8248 | data_load_times : 45.03 | batch_run_times : 45.42\n",
      "[2022-12-04 20:27:36] 2786500167.py[  95] : INFO  2-79 | lr : 0.000095 | val_loss : 1.4943 | val_roc_auc : 0.8278 | data_load_times : 45.41 | batch_run_times : 45.87\n",
      "[2022-12-04 20:28:20] 2786500167.py[  95] : INFO  2-80 | lr : 0.000095 | val_loss : 1.4499 | val_roc_auc : 0.8294 | data_load_times : 44.79 | batch_run_times : 45.21\n",
      "[2022-12-04 20:29:05] 2786500167.py[  95] : INFO  2-81 | lr : 0.000094 | val_loss : 1.4933 | val_roc_auc : 0.8158 | data_load_times : 45.24 | batch_run_times : 45.66\n",
      "[2022-12-04 20:29:49] 2786500167.py[  95] : INFO  2-82 | lr : 0.000094 | val_loss : 1.5574 | val_roc_auc : 0.7968 | data_load_times : 42.47 | batch_run_times : 42.87\n",
      "[2022-12-04 20:30:34] 2786500167.py[  95] : INFO  2-83 | lr : 0.000093 | val_loss : 1.6082 | val_roc_auc : 0.7947 | data_load_times : 44.39 | batch_run_times : 44.79\n",
      "Epoch 00084: early stopping triggered.\n",
      "[2022-12-04 20:30:35] 128199480.py[ 131] : INFO  Best scores: [1.3455458879470825, 1.2706029415130615, 1.2897377014160156]\n",
      "[2022-12-04 20:30:35] 128199480.py[ 132] : INFO  Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialise hyperparameters\n",
    "hparams = init_hparams()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "log_notes = \"patience/min_epochs/max_epochs decreased to 11/75/100, amsgrad changed to true\"\n",
    "\n",
    "# Initialise logger\n",
    "logger = init_logger(hparams.log_name, hparams.log_dir)\n",
    "\n",
    "# Log parameters\n",
    "logger.info(f\"backbone: {hparams.backbone}\")\n",
    "logger.info(f\"device_name: {hparams.device_name}\")\n",
    "logger.info(f\"gpus: {hparams.gpus}\")\n",
    "logger.info(f\"n_workers: {hparams.n_workers}\")\n",
    "logger.info(f\"image_size: {hparams.image_size}\")\n",
    "logger.info(f\"seed: {hparams.seed}\")\n",
    "logger.info(f\"min_epochs: {hparams.min_epochs}\")\n",
    "logger.info(f\"max_epochs: {hparams.max_epochs}\")\n",
    "logger.info(f\"patience: {hparams.patience}\")\n",
    "logger.info(f\"train_batch_size: {hparams.train_batch_size}\")\n",
    "logger.info(f\"val_batch_size: {hparams.val_batch_size}\")\n",
    "logger.info(f\"n_splits: {hparams.n_splits}\")\n",
    "logger.info(f\"test_size: {hparams.test_size}\")\n",
    "logger.info(f\"learning rate: {hparams.lr}\")\n",
    "logger.info(f\"weight_decay: {hparams.weight_decay}\")\n",
    "logger.info(f\"epsilon: {hparams.epsilon}\")\n",
    "logger.info(f\"amsgrad: {hparams.amsgrad}\")\n",
    "logger.info(f\"betas: {hparams.betas}\")\n",
    "logger.info(f\"precision: {hparams.precision}\")\n",
    "logger.info(f\"gradient_clip_val: {hparams.gradient_clip_val}\")\n",
    "logger.info(f\"eta_min: {hparams.eta_min}\")\n",
    "logger.info(f\"log_dir: {hparams.log_dir}\")\n",
    "logger.info(f\"log_name: {hparams.log_name}\")\n",
    "\n",
    "# Log any notes if they exist\n",
    "if \"log_notes\" in locals():\n",
    "    logger.info(f\"Notes: {log_notes}\")\n",
    "\n",
    "\n",
    "# Create transform pipeline\n",
    "transforms = generate_transforms(hparams.image_size)\n",
    "\n",
    "# List for validation scores \n",
    "val_loss_scores = []\n",
    "\n",
    "# Initialise cross validation\n",
    "folds = StratifiedKFold(n_splits=hparams.n_splits, shuffle=True, random_state=hparams.seed)\n",
    "\n",
    "# Start cross validation\n",
    "for fold_i, (train_index, val_index) in enumerate(folds.split(metadata[[\"img_path\"]], metadata[[\"label\"]])):\n",
    "    hparams.fold_i = fold_i\n",
    "    # Split train images and validation sets\n",
    "    train_data = metadata.iloc[train_index][[\"img_path\", \"label\"]].reset_index(drop=True)\n",
    "    train_data = pd.get_dummies(train_data, columns=[\"label\"], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "    val_data = metadata.iloc[val_index][[\"img_path\", \"label\"]].reset_index(drop=True)\n",
    "    val_data = pd.get_dummies(val_data, columns=[\"label\"], prefix=\"\", prefix_sep=\"\")\n",
    "    \n",
    "    logger.info(f\"Fold {fold_i} num train records: {train_data.shape[0]}\")\n",
    "    logger.info(f\"Fold {fold_i} num val records: {val_data.shape[0]}\")\n",
    "    \n",
    "    train_dataloader, val_dataloader = generate_dataloaders(hparams, train_data, val_data, transforms)\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        save_top_k=2,\n",
    "        mode=\"min\",\n",
    "        filepath=os.path.join(\n",
    "            hparams.log_dir, \n",
    "            hparams.log_name, \n",
    "            f\"fold={fold_i}\" + \"-{epoch}-{val_loss:.4f}-{val_roc_auc:.4f}\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\", \n",
    "        patience=hparams.patience, \n",
    "        mode=\"min\", \n",
    "        verbose=hparams.verbose\n",
    "    )\n",
    "    \n",
    "    # Instance Model, Trainer and train model\n",
    "    model = CoolSystem(hparams)\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=hparams.gpus,\n",
    "        min_epochs=hparams.min_epochs,\n",
    "        max_epochs=hparams.max_epochs,\n",
    "        early_stop_callback=early_stop_callback,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        progress_bar_refresh_rate=0,\n",
    "        precision=hparams.precision,\n",
    "        num_sanity_val_steps=0,\n",
    "        profiler=False,\n",
    "        weights_summary=None,\n",
    "        gradient_clip_val=hparams.gradient_clip_val,\n",
    "        default_root_dir=os.path.join(hparams.log_dir, hparams.log_name)\n",
    "    )\n",
    "    \n",
    "    # Fit model\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "            \n",
    "    # Save val scores\n",
    "    val_loss_scores.append(checkpoint_callback.best)\n",
    "    \n",
    "    # Cleanup\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "val_loss_scores = [i.item() for i in val_loss_scores]\n",
    "\n",
    "# Add val scores to csv with all scores\n",
    "if os.path.isfile(\"../logs/scores.csv\") == False:\n",
    "    pd.DataFrame(columns=[\"name\", \"scores\", \"mean_score\"]).to_csv(\"../logs/scores.csv\", index=False)\n",
    "    \n",
    "# Append to current scores csv\n",
    "all_scores_df = pd.concat([\n",
    "    pd.read_csv(\"../logs/scores.csv\"),\n",
    "    pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"name\": [hparams.log_name],\n",
    "            \"scores\": [val_loss_scores],\n",
    "            \"mean_score\": [np.mean(val_loss_scores)]\n",
    "        }\n",
    "    )],\n",
    "    ignore_index=True\n",
    ")\n",
    "# Write all scores df to csv\n",
    "all_scores_df.to_csv(\"../logs/scores.csv\", index=False)\n",
    "\n",
    "logger.info(f\"Best scores: {val_loss_scores}\")\n",
    "logger.info(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aee771",
   "metadata": {},
   "source": [
    "## Validation Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7feb0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [07:51,  4.71s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get model run path and define chosen fold\n",
    "log_dir = \"../logs/logs\"\n",
    "#model_run = \"2022_11_08_14:57:52\"\n",
    "model_run = hparams.log_name\n",
    "model_run_path = os.path.join(log_dir, model_run)\n",
    "#best_fold = 1\n",
    "best_fold = val_loss_scores.index(min(val_loss_scores))\n",
    "\n",
    "# Get best model for chosen fold\n",
    "model_run_dir = os.listdir(model_run_path)\n",
    "model_folds = [i for i in model_run_dir if i.startswith(f\"fold={best_fold}\")]\n",
    "model_folds_scores = [float(i.split(\"val_loss=\")[1].split(\"-\")[0]) for i in model_folds]\n",
    "model_name = model_folds[model_folds_scores.index(min(model_folds_scores))]\n",
    "model_path = os.path.join(model_run_path, model_name)\n",
    "\n",
    "# Load fold's model\n",
    "model = CoolSystem(hparams)\n",
    "model.load_state_dict(\n",
    "    torch.load(model_path)[\"state_dict\"]\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# Retrieve validation indices for chosen fold\n",
    "for fold_i, (train_index, val_index) in enumerate(folds.split(metadata[[\"img_path\"]], metadata[[\"label\"]])):\n",
    "    if fold_i == best_fold:\n",
    "        break\n",
    "\n",
    "# Select fold validation images\n",
    "X_val = torch.from_numpy(X_train[val_index]).permute(0, 3, 1, 2).float()\n",
    "\n",
    "# Create predictions looped by batch\n",
    "counter = 0\n",
    "val_i_batch = []\n",
    "val_idx_batch = []\n",
    "scores_df = pd.DataFrame()\n",
    "\n",
    "for i, idx in tqdm(enumerate(val_index)):\n",
    "    counter += 1\n",
    "    val_i_batch.append(i) # arrays don't preserve index so need ordered index values\n",
    "    val_idx_batch.append(idx) # for preserved index\n",
    "    \n",
    "    # Run inference for val_batch_size\n",
    "    if counter == hparams.val_batch_size:\n",
    "        preds = model(X_val[val_i_batch])\n",
    "        \n",
    "        # Create activation output\n",
    "        log_softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        # Convert raw output to probabilities\n",
    "        preds = np.exp(log_softmax(preds).detach().numpy())\n",
    "\n",
    "        # Create df with img paths and predicted label probs\n",
    "        scores_df_batch = pd.DataFrame(preds, columns=val_data.columns[1:])\n",
    "        scores_df_batch = pd.merge(\n",
    "            metadata.iloc[val_idx_batch, 1:3].reset_index(drop=True),\n",
    "            scores_df_batch, \n",
    "            left_index=True,\n",
    "            right_index=True\n",
    "        )\n",
    "        scores_df = pd.concat([scores_df, scores_df_batch], ignore_index=True, axis=0)\n",
    "\n",
    "        # Cleanup\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # Reset counter and batch\n",
    "        counter = 0\n",
    "        val_i_batch = []\n",
    "        val_idx_batch = []\n",
    "        \n",
    "    # Run inference for remaining batch\n",
    "    elif idx == val_index[-1]:\n",
    "        preds = model(X_val[val_i_batch])\n",
    "        \n",
    "        # Create activation output\n",
    "        log_softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        # Convert raw output to probabilities\n",
    "        preds = np.exp(log_softmax(preds).detach().numpy())\n",
    "\n",
    "        # Create df with img paths and predicted label probs\n",
    "        scores_df_batch = pd.DataFrame(preds, columns=val_data.columns[1:])\n",
    "        scores_df_batch = pd.merge(\n",
    "            metadata.iloc[val_idx_batch, 1:3].reset_index(drop=True),\n",
    "            scores_df_batch, \n",
    "            left_index=True,\n",
    "            right_index=True\n",
    "        )\n",
    "        scores_df = pd.concat([scores_df, scores_df_batch], ignore_index=True, axis=0)\n",
    "\n",
    "        # Cleanup\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "# Write predictions to log\n",
    "scores_df.to_csv(\n",
    "    os.path.join(model_run_path, f\"{model_run}_preds_fold_{best_fold}.csv\"),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fc3edc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>ant</th>\n",
       "      <th>bedbug</th>\n",
       "      <th>bee</th>\n",
       "      <th>horsefly</th>\n",
       "      <th>mite</th>\n",
       "      <th>mosquito</th>\n",
       "      <th>none</th>\n",
       "      <th>tick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/cleaned/none/6eac051b9c45ff6821ec86752...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.157181</td>\n",
       "      <td>0.171592</td>\n",
       "      <td>0.101942</td>\n",
       "      <td>0.135047</td>\n",
       "      <td>0.142920</td>\n",
       "      <td>0.094712</td>\n",
       "      <td>0.106189</td>\n",
       "      <td>0.090416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/cleaned/none/fc72767f8520df9b2b8394107...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.156795</td>\n",
       "      <td>0.174067</td>\n",
       "      <td>0.101753</td>\n",
       "      <td>0.137763</td>\n",
       "      <td>0.142289</td>\n",
       "      <td>0.094485</td>\n",
       "      <td>0.104688</td>\n",
       "      <td>0.088160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/cleaned/none/49850884a00703afe5aab78c3...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.155509</td>\n",
       "      <td>0.171901</td>\n",
       "      <td>0.102669</td>\n",
       "      <td>0.135296</td>\n",
       "      <td>0.143230</td>\n",
       "      <td>0.096477</td>\n",
       "      <td>0.104323</td>\n",
       "      <td>0.090595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/cleaned/none/8dab219e5fa4d9a05d42b6f3a...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.155182</td>\n",
       "      <td>0.171211</td>\n",
       "      <td>0.102641</td>\n",
       "      <td>0.134951</td>\n",
       "      <td>0.142560</td>\n",
       "      <td>0.096005</td>\n",
       "      <td>0.106050</td>\n",
       "      <td>0.091399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/cleaned/none/d9c0f49c789a29fb55370319e...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.169098</td>\n",
       "      <td>0.102976</td>\n",
       "      <td>0.133203</td>\n",
       "      <td>0.142510</td>\n",
       "      <td>0.096468</td>\n",
       "      <td>0.107006</td>\n",
       "      <td>0.092743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>../data/cleaned/ant/b7d95c4a5fe54f5bbfb3442ceb...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.156070</td>\n",
       "      <td>0.170976</td>\n",
       "      <td>0.102797</td>\n",
       "      <td>0.134621</td>\n",
       "      <td>0.143496</td>\n",
       "      <td>0.096506</td>\n",
       "      <td>0.104566</td>\n",
       "      <td>0.090967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>../data/cleaned/ant/8fadf11644c8c4877b64bb61cb...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.156352</td>\n",
       "      <td>0.170685</td>\n",
       "      <td>0.102686</td>\n",
       "      <td>0.134540</td>\n",
       "      <td>0.143557</td>\n",
       "      <td>0.095951</td>\n",
       "      <td>0.104864</td>\n",
       "      <td>0.091366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>../data/cleaned/ant/ab1b890b774b4cc6b71459a595...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.155295</td>\n",
       "      <td>0.168114</td>\n",
       "      <td>0.103171</td>\n",
       "      <td>0.132546</td>\n",
       "      <td>0.142086</td>\n",
       "      <td>0.096955</td>\n",
       "      <td>0.108024</td>\n",
       "      <td>0.093808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>../data/cleaned/ant/d170bac72faf6447bd8d192744...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.157170</td>\n",
       "      <td>0.171674</td>\n",
       "      <td>0.102061</td>\n",
       "      <td>0.135350</td>\n",
       "      <td>0.142550</td>\n",
       "      <td>0.095383</td>\n",
       "      <td>0.106186</td>\n",
       "      <td>0.089625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>../data/cleaned/ant/df654f18291b8f1c20659e4621...</td>\n",
       "      <td>ant</td>\n",
       "      <td>0.155341</td>\n",
       "      <td>0.170972</td>\n",
       "      <td>0.102876</td>\n",
       "      <td>0.134515</td>\n",
       "      <td>0.142732</td>\n",
       "      <td>0.096569</td>\n",
       "      <td>0.105617</td>\n",
       "      <td>0.091380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             img_path label       ant  \\\n",
       "0   ../data/cleaned/none/6eac051b9c45ff6821ec86752...  none  0.157181   \n",
       "1   ../data/cleaned/none/fc72767f8520df9b2b8394107...  none  0.156795   \n",
       "2   ../data/cleaned/none/49850884a00703afe5aab78c3...  none  0.155509   \n",
       "3   ../data/cleaned/none/8dab219e5fa4d9a05d42b6f3a...  none  0.155182   \n",
       "4   ../data/cleaned/none/d9c0f49c789a29fb55370319e...  none  0.155995   \n",
       "..                                                ...   ...       ...   \n",
       "95  ../data/cleaned/ant/b7d95c4a5fe54f5bbfb3442ceb...   ant  0.156070   \n",
       "96  ../data/cleaned/ant/8fadf11644c8c4877b64bb61cb...   ant  0.156352   \n",
       "97  ../data/cleaned/ant/ab1b890b774b4cc6b71459a595...   ant  0.155295   \n",
       "98  ../data/cleaned/ant/d170bac72faf6447bd8d192744...   ant  0.157170   \n",
       "99  ../data/cleaned/ant/df654f18291b8f1c20659e4621...   ant  0.155341   \n",
       "\n",
       "      bedbug       bee  horsefly      mite  mosquito      none      tick  \n",
       "0   0.171592  0.101942  0.135047  0.142920  0.094712  0.106189  0.090416  \n",
       "1   0.174067  0.101753  0.137763  0.142289  0.094485  0.104688  0.088160  \n",
       "2   0.171901  0.102669  0.135296  0.143230  0.096477  0.104323  0.090595  \n",
       "3   0.171211  0.102641  0.134951  0.142560  0.096005  0.106050  0.091399  \n",
       "4   0.169098  0.102976  0.133203  0.142510  0.096468  0.107006  0.092743  \n",
       "..       ...       ...       ...       ...       ...       ...       ...  \n",
       "95  0.170976  0.102797  0.134621  0.143496  0.096506  0.104566  0.090967  \n",
       "96  0.170685  0.102686  0.134540  0.143557  0.095951  0.104864  0.091366  \n",
       "97  0.168114  0.103171  0.132546  0.142086  0.096955  0.108024  0.093808  \n",
       "98  0.171674  0.102061  0.135350  0.142550  0.095383  0.106186  0.089625  \n",
       "99  0.170972  0.102876  0.134515  0.142732  0.096569  0.105617  0.091380  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a910bef3",
   "metadata": {},
   "source": [
    "## Validation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b4293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 unique image paths.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(scores_df['img_path'].unique())} unique image paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6565caec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation label counts:\n",
      "bedbug      19\n",
      "tick        18\n",
      "mosquito    16\n",
      "ant         16\n",
      "none         9\n",
      "horsefly     8\n",
      "mite         7\n",
      "bee          7\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation label counts:\")\n",
    "print(scores_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f8676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction counts:\n",
      "bedbug    100\n",
      "Name: pred_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation prediction counts:\")\n",
    "print(\n",
    "    pd.melt(\n",
    "        scores_df,\n",
    "        id_vars=[\"img_path\", \"label\"],\n",
    "        value_vars=[\"ant\", \"bedbug\", \"bee\", \"horsefly\", \"mite\", \"mosquito\" ,\"none\", \"tick\"],\n",
    "        var_name=\"pred_label\",\n",
    "        value_name=\"pred_prob\"\n",
    "    ).sort_values([\"img_path\", \"pred_prob\"], ascending=False) \\\n",
    "    .groupby([\"img_path\", \"label\"]).first()[\"pred_label\"] \\\n",
    "    .value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24bf48d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>0.25</th>\n",
       "      <th>median</th>\n",
       "      <th>0.75</th>\n",
       "      <th>max</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ant</th>\n",
       "      <td>0.156080</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.153455</td>\n",
       "      <td>0.155632</td>\n",
       "      <td>0.156085</td>\n",
       "      <td>0.156480</td>\n",
       "      <td>0.159257</td>\n",
       "      <td>0.005802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedbug</th>\n",
       "      <td>0.171089</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.168114</td>\n",
       "      <td>0.170134</td>\n",
       "      <td>0.170983</td>\n",
       "      <td>0.171685</td>\n",
       "      <td>0.176004</td>\n",
       "      <td>0.007891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bee</th>\n",
       "      <td>0.102579</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.102429</td>\n",
       "      <td>0.102658</td>\n",
       "      <td>0.102876</td>\n",
       "      <td>0.103554</td>\n",
       "      <td>0.003353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsefly</th>\n",
       "      <td>0.134666</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.132465</td>\n",
       "      <td>0.133895</td>\n",
       "      <td>0.134582</td>\n",
       "      <td>0.135249</td>\n",
       "      <td>0.138961</td>\n",
       "      <td>0.006496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mite</th>\n",
       "      <td>0.142823</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.141142</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.142850</td>\n",
       "      <td>0.143092</td>\n",
       "      <td>0.147121</td>\n",
       "      <td>0.005980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mosquito</th>\n",
       "      <td>0.096011</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.090462</td>\n",
       "      <td>0.095679</td>\n",
       "      <td>0.096073</td>\n",
       "      <td>0.096584</td>\n",
       "      <td>0.097796</td>\n",
       "      <td>0.007334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>0.105744</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.102856</td>\n",
       "      <td>0.104945</td>\n",
       "      <td>0.105798</td>\n",
       "      <td>0.106372</td>\n",
       "      <td>0.108368</td>\n",
       "      <td>0.005512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tick</th>\n",
       "      <td>0.091008</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.086169</td>\n",
       "      <td>0.090378</td>\n",
       "      <td>0.091209</td>\n",
       "      <td>0.091726</td>\n",
       "      <td>0.093808</td>\n",
       "      <td>0.007639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean       std       min      0.25    median      0.75  \\\n",
       "ant       0.156080  0.000804  0.153455  0.155632  0.156085  0.156480   \n",
       "bedbug    0.171089  0.001355  0.168114  0.170134  0.170983  0.171685   \n",
       "bee       0.102579  0.000520  0.100200  0.102429  0.102658  0.102876   \n",
       "horsefly  0.134666  0.001175  0.132465  0.133895  0.134582  0.135249   \n",
       "mite      0.142823  0.000652  0.141142  0.142500  0.142850  0.143092   \n",
       "mosquito  0.096011  0.000966  0.090462  0.095679  0.096073  0.096584   \n",
       "none      0.105744  0.001070  0.102856  0.104945  0.105798  0.106372   \n",
       "tick      0.091008  0.001301  0.086169  0.090378  0.091209  0.091726   \n",
       "\n",
       "               max     range  \n",
       "ant       0.159257  0.005802  \n",
       "bedbug    0.176004  0.007891  \n",
       "bee       0.103554  0.003353  \n",
       "horsefly  0.138961  0.006496  \n",
       "mite      0.147121  0.005980  \n",
       "mosquito  0.097796  0.007334  \n",
       "none      0.108368  0.005512  \n",
       "tick      0.093808  0.007639  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability stats by label\n",
    "pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].mean(), columns=[\"mean\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].std(), columns=[\"std\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].min(), columns=[\"min\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].quantile(0.25)),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].median(), columns=[\"median\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].quantile(0.75)),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].max(), columns=[\"max\"]),\n",
    "        pd.DataFrame(scores_df.iloc[:, 2:].max() - scores_df.iloc[:, 2:].min(), columns=[\"range\"])\n",
    "    ], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92d47fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">pred_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_label</th>\n",
       "      <th>ant</th>\n",
       "      <th>bedbug</th>\n",
       "      <th>bee</th>\n",
       "      <th>horsefly</th>\n",
       "      <th>mite</th>\n",
       "      <th>mosquito</th>\n",
       "      <th>none</th>\n",
       "      <th>tick</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ant</th>\n",
       "      <td>0.156292</td>\n",
       "      <td>0.171452</td>\n",
       "      <td>0.102459</td>\n",
       "      <td>0.135144</td>\n",
       "      <td>0.143237</td>\n",
       "      <td>0.095804</td>\n",
       "      <td>0.105142</td>\n",
       "      <td>0.090470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedbug</th>\n",
       "      <td>0.156064</td>\n",
       "      <td>0.171579</td>\n",
       "      <td>0.102525</td>\n",
       "      <td>0.134983</td>\n",
       "      <td>0.142824</td>\n",
       "      <td>0.096090</td>\n",
       "      <td>0.105357</td>\n",
       "      <td>0.090578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bee</th>\n",
       "      <td>0.156413</td>\n",
       "      <td>0.170648</td>\n",
       "      <td>0.102560</td>\n",
       "      <td>0.134425</td>\n",
       "      <td>0.142751</td>\n",
       "      <td>0.095857</td>\n",
       "      <td>0.106070</td>\n",
       "      <td>0.091275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsefly</th>\n",
       "      <td>0.155697</td>\n",
       "      <td>0.171144</td>\n",
       "      <td>0.102574</td>\n",
       "      <td>0.134640</td>\n",
       "      <td>0.142263</td>\n",
       "      <td>0.096003</td>\n",
       "      <td>0.106448</td>\n",
       "      <td>0.091231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mite</th>\n",
       "      <td>0.155780</td>\n",
       "      <td>0.171025</td>\n",
       "      <td>0.102646</td>\n",
       "      <td>0.134429</td>\n",
       "      <td>0.142830</td>\n",
       "      <td>0.096069</td>\n",
       "      <td>0.105871</td>\n",
       "      <td>0.091350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mosquito</th>\n",
       "      <td>0.156085</td>\n",
       "      <td>0.170422</td>\n",
       "      <td>0.102790</td>\n",
       "      <td>0.134131</td>\n",
       "      <td>0.142905</td>\n",
       "      <td>0.096321</td>\n",
       "      <td>0.105822</td>\n",
       "      <td>0.091525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>0.155751</td>\n",
       "      <td>0.171207</td>\n",
       "      <td>0.102620</td>\n",
       "      <td>0.134934</td>\n",
       "      <td>0.142591</td>\n",
       "      <td>0.095997</td>\n",
       "      <td>0.105813</td>\n",
       "      <td>0.091087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tick</th>\n",
       "      <td>0.156224</td>\n",
       "      <td>0.170956</td>\n",
       "      <td>0.102517</td>\n",
       "      <td>0.134446</td>\n",
       "      <td>0.142773</td>\n",
       "      <td>0.095885</td>\n",
       "      <td>0.106094</td>\n",
       "      <td>0.091105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred_prob                                                    \\\n",
       "pred_label       ant    bedbug       bee  horsefly      mite  mosquito   \n",
       "label                                                                    \n",
       "ant         0.156292  0.171452  0.102459  0.135144  0.143237  0.095804   \n",
       "bedbug      0.156064  0.171579  0.102525  0.134983  0.142824  0.096090   \n",
       "bee         0.156413  0.170648  0.102560  0.134425  0.142751  0.095857   \n",
       "horsefly    0.155697  0.171144  0.102574  0.134640  0.142263  0.096003   \n",
       "mite        0.155780  0.171025  0.102646  0.134429  0.142830  0.096069   \n",
       "mosquito    0.156085  0.170422  0.102790  0.134131  0.142905  0.096321   \n",
       "none        0.155751  0.171207  0.102620  0.134934  0.142591  0.095997   \n",
       "tick        0.156224  0.170956  0.102517  0.134446  0.142773  0.095885   \n",
       "\n",
       "                                \n",
       "pred_label      none      tick  \n",
       "label                           \n",
       "ant         0.105142  0.090470  \n",
       "bedbug      0.105357  0.090578  \n",
       "bee         0.106070  0.091275  \n",
       "horsefly    0.106448  0.091231  \n",
       "mite        0.105871  0.091350  \n",
       "mosquito    0.105822  0.091525  \n",
       "none        0.105813  0.091087  \n",
       "tick        0.106094  0.091105  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.melt(\n",
    "    scores_df,\n",
    "    id_vars=[\"img_path\", \"label\"],\n",
    "    value_vars=[\"ant\", \"bedbug\", \"bee\", \"horsefly\", \"mite\", \"mosquito\" ,\"none\", \"tick\"],\n",
    "    var_name=\"pred_label\",\n",
    "    value_name=\"pred_prob\"\n",
    ").pivot_table(\n",
    "    index=[\"label\"],\n",
    "    columns=[\"pred_label\"],\n",
    "    aggfunc=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "980e4931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/24aca08f4aeea83c077a9721c85b5a6ff8ef7d3d.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>bedbug</td>\n",
       "      <td>0.170619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/26b8fb30b3ddd29f8e5763b8b9a63cda83006c7a.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>bedbug</td>\n",
       "      <td>0.172482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/448b50c6778952be3df52a6a26affeff4844b7f4.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>bedbug</td>\n",
       "      <td>0.171213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/451d80e25d8f18e8a68174ff8ff651c435bd4700.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>bedbug</td>\n",
       "      <td>0.171935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/ant/51782d78019c7b5be5333e7bc2dab3469f88fec7.jpg</th>\n",
       "      <th>ant</th>\n",
       "      <td>bedbug</td>\n",
       "      <td>0.171627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/c99e1bba324bc3b31bfab79473a50baeb0c87a2a.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>bedbug</td>\n",
       "      <td>0.171142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/d842edcf4167941990cb0b05c8a3c58db001c8d6.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>bedbug</td>\n",
       "      <td>0.170778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/ebeb916d8413d0b3387c84896fb99ddf6eb2fe13.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>bedbug</td>\n",
       "      <td>0.174221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/f4beab1b01a8c5d7674b2392b230515d74ae34ea.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>bedbug</td>\n",
       "      <td>0.171608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/cleaned/tick/f82e692ff747a6f88cc6c68e97cb69cbb5df4aab.jpg</th>\n",
       "      <th>tick</th>\n",
       "      <td>bedbug</td>\n",
       "      <td>0.172523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         pred_label  pred_prob\n",
       "img_path                                           label                      \n",
       "../data/cleaned/ant/24aca08f4aeea83c077a9721c85... ant       bedbug   0.170619\n",
       "../data/cleaned/ant/26b8fb30b3ddd29f8e5763b8b9a... ant       bedbug   0.172482\n",
       "../data/cleaned/ant/448b50c6778952be3df52a6a26a... ant       bedbug   0.171213\n",
       "../data/cleaned/ant/451d80e25d8f18e8a68174ff8ff... ant       bedbug   0.171935\n",
       "../data/cleaned/ant/51782d78019c7b5be5333e7bc2d... ant       bedbug   0.171627\n",
       "...                                                             ...        ...\n",
       "../data/cleaned/tick/c99e1bba324bc3b31bfab79473... tick      bedbug   0.171142\n",
       "../data/cleaned/tick/d842edcf4167941990cb0b05c8... tick      bedbug   0.170778\n",
       "../data/cleaned/tick/ebeb916d8413d0b3387c84896f... tick      bedbug   0.174221\n",
       "../data/cleaned/tick/f4beab1b01a8c5d7674b2392b2... tick      bedbug   0.171608\n",
       "../data/cleaned/tick/f82e692ff747a6f88cc6c68e97... tick      bedbug   0.172523\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.melt(\n",
    "    scores_df,\n",
    "    id_vars=[\"img_path\", \"label\"],\n",
    "    value_vars=[\"ant\", \"bedbug\", \"bee\", \"horsefly\", \"mite\", \"mosquito\" ,\"none\", \"tick\"],\n",
    "    var_name=\"pred_label\",\n",
    "    value_name=\"pred_prob\"\n",
    ").sort_values([\"img_path\", \"pred_prob\"], ascending=False).groupby([\"img_path\", \"label\"]).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249a0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613be570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88807ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biteme",
   "language": "python",
   "name": "biteme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
